refer: https://www.javatpoint.com/aws-interview-questions

https://www.interviewbit.com/aws-interview-questions/

AWS is a cloud computing service offered by Amazon. AWS lets you build, test, deploy and manage applications and services. All this is done via the data-centers and the hardware managed by Amazon. AWS provides you a combination of Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) offerings.

You can use AWS to create Virtual Machines which can be armed with processing power, storage capacity, and analytics along with networking and device management. AWS offers you a pay-as-you-go model, which helps to avoid upfront costs and pay based on the usage monthly.

Find the list of the top asked AWS Interview Questions and answers below.

Play
Crack your next tech interview with confidence!
Take a free mock interview, get instantâš¡ï¸ feedback and recommendationðŸ’¡
Attempt Now
AWS Basic Interview Questions
1. What is EC2?
EC2, a Virtual Machine in the cloud on which you have OS-level control. You can run this cloud server whenever you want and can be used when you need to deploy your own servers in the cloud, similar to your on-premises servers, and when you want to have full control over the choice of hardware and the updates on the machine.

2. What is SnowBall?
SnowBall is a small application that enables you to transfer terabytes of data inside and outside of the AWS environment.


AWS Snowball
3. What is CloudWatch?
CloudWatch helps you to monitor AWS environments like EC2, RDS Instances, and CPU utilization. It also triggers alarms depending on various metrics.


AWS Cloudwatch
You can download a PDF version of Aws Interview Questions.

Download PDF

4. What is Elastic Transcoder?
Elastic Transcoder is an AWS Service Tool that helps you in changing a videoâ€™s format and resolution to support various devices like tablets, smartphones, and laptops of different resolutions.

5. What do you understand by VPC?
VPC stands for Virtual Private Cloud. It allows you to customize your networking configuration. VPC is a network that is logically isolated from other networks in the cloud. It allows you to have your private IP Address range, internet gateways, subnets, and security groups.

6. DNS and Load Balancer Services come under which type of Cloud Service?
DNS and Load Balancer are a part of IaaS-Storage Cloud Service.

7. What are the Storage Classes available in Amazon S3?
Storage Classes available with Amazon S3 are:

Amazon S3 Standard
Amazon S3 Standard-Infrequent Access
Amazon S3 Reduced Redundancy Storage
Amazon Glacier
8. Explain what T2 instances are?
T2 Instances are designed to provide moderate baseline performance and the capability to burst to higher performance as required by the workload.

9. What are Key-Pairs in AWS?
Key-Pairs are secure login information for your Virtual Machines. To connect to the instances, you can use Key-Pairs which contain a Public Key and a Private Key.

10. How many Subnets can you have per VPC?
You can have 200 Subnets per VPC.

11. List different types of Cloud Services.
Different types of Cloud Services are:

Software as a Service (SaaS)
Data as a Service (DaaS)
Platform as a Service (PaaS)
Infrastructure as a Service (IaaS)
Advanced AWS Questions
12. Explain what S3 is?
S3 stands for Simple Storage Service. You can use the S3 interface to store and retrieve any amount of data, at any time and from anywhere on the web. For S3, the payment model is â€œpay as you goâ€.

13. How does Amazon Route 53 provide high availability and low latency?
Amazon Route 53 uses the following to provide high availability and low latency:

Globally Distributed Servers - Amazon is a global service and consequently has DNS Servers globally. Any customer creating a query from any part of the world gets to reach a DNS Server local to them that provides low latency.
Dependency - Route 53 provides a high level of dependability required by critical applications.
Optimal Locations - Route 53 serves the requests from the nearest data center to the client sending the request. AWS has data-centers across the world. The data can be cached on different data-centers located in different regions of the world depending on the requirements and the configuration chosen. Route 53 enables any server in any data-center which has the required data to respond. This way, it enables the nearest server to serve the client request, thus reducing the time taken to serve.

Amazon Route
As can be seen in the above image, the requests coming from a user in India are served from the Singapore Server, while the requests coming from a user in the US are routed to Oregon region.

14. How can you send a request to Amazon S3?
Amazon S3 is a REST Service, and you can send a request by using the REST API or the AWS SDK wrapper libraries that wrap the underlying Amazon S3 REST API.

15. What does AMI include?
An AMI includes the following things:

A template for the root volume for the instance.
Launch permissions to decide which AWS accounts can avail the AMI to launch instances.
A block device mapping that determines the volumes to attach to the instance when it is launched.
16. What are the different types of Instances?
Following are the types of instances:

Compute Optimized
Memory-Optimized
Storage Optimized
Accelerated Computing
General Purpose
17. What is the relation between the Availability Zone and Region?
An AWS Availability Zone is a physical location where an Amazon data center is located. On the other hand, an AWS Region is a collection or group of Availability Zones or Data Centers. 

This setup helps your services to be more available as you can place your VMs in different data centers within an AWS Region. If one of the data centers fails in a Region, the client requests still get served from the other data centers located in the same Region. This arrangement, thus, helps your service to be available even if a Data Center goes down.

18. How do you monitor Amazon VPC?
You can monitor Amazon VPC using:

CloudWatch
VPC Flow Logs
19. What are the different types of EC2 instances based on their costs?
The three types of EC2 instances based on the costs are:

On-Demand Instance - These instances are prepared as and when needed. Whenever you feel the need for a new EC2 instance, you can go ahead and create an on-demand instance. It is cheap for the short-time but not when taken for the long term.

Spot Instance - These types of instances can be bought through the bidding model. These are comparatively cheaper than On-Demand Instances.

Reserved Instance - On AWS, you can create instances that you can reserve for a year or so. These types of instances are especially useful when you know in advance that you will be needing an instance for the long term. In such cases, you can create a reserved instance and save heavily on costs.

20. What do you understand by stopping and terminating an EC2 Instance?
Stopping an EC2 instance means to shut it down as you would normally do on your Personal Computer. This will not delete any volumes attached to the instance and the instance can be started again when needed.

On the other hand, terminating an instance is equivalent to deleting an instance. All the volumes attached to the instance get deleted and it is not possible to restart the instance if needed at a later point in time.

21. What are the consistency models for modern DBs offered by AWS?
Eventual Consistency - It means that the data will be consistent eventually, but may not be immediate. This will serve the client requests faster, but chances are that some of the initial read requests may read the stale data. This type of consistency is preferred in systems where data need not be real-time. For example, if you donâ€™t see the recent tweets on Twitter or recent posts on Facebook for a couple of seconds, it is acceptable.

Strong Consistency - It provides an immediate consistency where the data will be consistent across all the DB Servers immediately. Accordingly. This model may take some time to make the data consistent and subsequently start serving the requests again. However, in this model, it is guaranteed that all the responses will always have consistent data.

22. What is Geo-Targeting in CloudFront?
Geo-Targeting enables the creation of customized content based on the geographic location of the user. This allows you to serve the content which is more relevant to a user. For example, using Geo-Targeting, you can show the news related to local body elections to a user sitting in India, which you may not want to show to a user sitting in the US. Similarly, the news related to Baseball Tournament can be more relevant to a user sitting in the US, and not so relevant for a user sitting in India.

23. What are the advantages of AWS IAM?
AWS IAM enables an administrator to provide granular level access to different users and groups. Different users and user groups may need different levels of access to different resources created. With IAM, you can create roles with specific access-levels and assign the roles to the users. 

It also allows you to provide access to the resources to users and applications without creating the IAM Roles, which is known as Federated Access.

24. What do you understand by a Security Group?
When you create an instance in AWS, you may or may not want that instance to be accessible from the public network. Moreover, you may want that instance to be accessible from some networks and not from others.

Security Groups are a type of rule-based Virtual Firewall using which you can control access to your instances. You can create rules defining the Port Numbers, Networks, or protocols from which you want to allow access or deny access.

25. What are Spot Instances and On-Demand Instances?
When AWS creates EC2 instances, there are some blocks of computing capacity and processing power left unused. AWS releases these blocks as Spot Instances. Spot Instances run whenever capacity is available. These are a good option if you are flexible about when your applications can run and if your applications can be interrupted.

On the other hand, On-Demand Instances can be created as and when needed. The prices of such instances are static. Such instances will always be available unless you explicitly terminate them.

26. Explain Connection Draining.
Connection Draining is a feature provided by AWS which enables your servers which are either going to be updated or removed, to serve the current requests. 

If Connection Draining is enabled, the Load Balancer will allow an outgoing instance to complete the current requests for a specific period but will not send any new request to it. Without Connection Draining, an outgoing instance will immediately go off and the requests pending on that instance will error out.

27. What is a Stateful and a Stateless Firewall?
A Stateful Firewall is the one that maintains the state of the rules defined. It requires you to define only inbound rules. Based on the inbound rules defined, it automatically allows the outbound traffic to flow. 

On the other hand, a Stateless Firewall requires you to explicitly define rules for inbound as well as outbound traffic. 

For example, if you allow inbound traffic from Port 80, a Stateful Firewall will allow outbound traffic to Port 80, but a Stateless Firewall will not do so.

28. What is a Power User Access in AWS?
An Administrator User will be similar to the owner of the AWS Resources. He can create, delete, modify or view the resources and also grant permissions to other users for the AWS Resources.

A Power User Access provides Administrator Access without the capability to manage the users and permissions. In other words, a user with Power User Access can create, delete, modify or see the resources, but he cannot grant permissions to other users.

29. What is an Instance Store Volume and an EBS Volume?
An Instance Store Volume is temporary storage that is used to store the temporary data required by an instance to function. The data is available as long as the instance is running. As soon as the instance is turned off, the Instance Store Volume gets removed and the data gets deleted.

On the other hand, an EBS Volume represents a persistent storage disk. The data stored in an EBS Volume will be available even after the instance is turned off.

30. What are Recovery Time Objective and Recovery Point Objective in AWS?
Recovery Time Objective - It is the maximum acceptable delay between the interruption of service and restoration of service. This translates to an acceptable time window when the service can be unavailable.

Recover Point Objective - It is the maximum acceptable amount of time since the last data restore point. It translates to the acceptable amount of data loss which lies between the last recovery point and the interruption of service.

31. Is there a way to upload a file that is greater than 100 Megabytes in Amazon S3?
Yes, it is possible by using the Multipart Upload Utility from AWS. With the Multipart Upload Utility, larger files can be uploaded in multiple parts that are uploaded independently. You can also decrease upload time by uploading these parts in parallel. After the upload is done, the parts are merged into a single object or file to create the original file from which the parts were created.

32. Can you change the Private IP Address of an EC2 instance while it is running or in a stopped state?
No, a Private IP Address of an EC2 instance cannot be changed. When an EC2 instance is launched, a private IP Address is assigned to that instance at the boot time. This private IP Address is attached to the instance for its entire lifetime and can never be changed.

33. What is the use of lifecycle hooks is Autoscaling?
Lifecycle hooks are used for Auto-scaling to put an additional wait time to a scale-in or a scale-out event.

34. What are the policies that you can set for your userâ€™s passwords?
Following are the policies that can be set for userâ€™s passwords:

You can set a minimum length of the password.
You can ask the users to add at least one number or special character to the password.
Assigning the requirements of particular character types, including uppercase letters, lowercase letters, numbers, and non-alphanumeric characters.
You can enforce automatic password expiration, prevent the reuse of old passwords, and request for a password reset upon their next AWS sign-in.
You can have the AWS users contact an account administrator when the user has allowed the password to expire.
Useful Resources
https://www.interviewbit.com/terraform-interview-questions/
https://www.interviewbit.com/technical-interview-questions/
AWS MCQ
1.
________ is a billing and account management service in AWS.


Amazon Mechanical Turk

Amazon Elastic MapReduce

Amazon DevPay

Multi-Factor Authentication
2.
What are the advantages of Auto Scaling?


Better Availability

Fault Tolerance

Better Cost Management

All of the above
3.
Which of the following is an edge-storage or content delivery system that caches data in different physical locations?


Amazon Relational Database Service

Amazon SimpleDB

Amazon CloudFront

Amazon Associate Web Services
4.
Which of the following is a means for accessing human researchers or consultants to help solve problems on a contractual or temporary basis?


Amazon Elastic MapReduce

Amazon Mechanical Turk

Amazon DevPay

Multi-Factor Authentication
5.
Which of the following statements is correct?


Amazon Elastic Cloud is a system for creating Virtual Disks

SimpleDB inter-operates with both Amazon EC2 and Amazon S3

EC3 is an Analytics as a Service provider

None of the above
6.
Which of the following is a structured data store that supports indexing and data queries to both EC2 and S3?


CloudWatch

Amazon SimpleDB

Amazon CloudFront

All of the above
7.
Which service performs the function of terminating an unhealthy instance and replacing it with a new one?


Sticky Sessions

Fault Tolerance

Connection Draining

None of the above
8.
Suppose a subnet is created and an EC2 instance is launched in the subnet with default settings. Which of the following options will be ready to use on the EC2 instance as soon as it is launched?


Elastic IP

Private IP

Public IP

Internet Gateway
9.
Can you change the instance type of the instances that are running in your application tier and also using auto-scaling?


Yes, by modifying the auto-scaling launch configuration

Yes, by modifying auto-scaling tags configuration

Yes, by modifying the auto-scaling policy configuration

No, it cannot be changed
10.
Where does a user specify the maximum number of instances with the auto-scaling commands?


Auto-Scaling Policy Configuration

Auto-Scaling Group

Auto-Scaling Tags Configuration

Auto-Scaling Launch Configuration


https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions

op 90+ AWS Interview Questions and Answers for 2022
Lesson 13 of 14By Simplilearn

Last updated on Sep 5, 202213937456
Top 90+ AWS Interview Questions and Answers [Updated]
PreviousNext
Table of Contents
Basic AWS Interview QuestionsAWS Questions for Amazon EC2AWS Interview Questions for S3AWS Interview Questions for VPCGeneral AWS Interview QuestionsView More
Todayâ€™s modern world is witnessing a significant change in how businesses and organizations work. Everything is getting digitized, and the introduction of cloud and cloud computing platforms have been a major driving force behind this growth. Today, most businesses are using or are planning to use cloud computing for many of their operations, which consequently has led to a massive surge in the need for cloud professionals. 

If you are interested in a career in the cloud industry, your chance has arrived. With cloud computing platforms like AWS taking the present business scenarios by storm, getting trained and certified in that particular platform can provide you with great career prospects. 

But in order to get your AWS career started, you need to set up some AWS interviews and ace them. In the spirit of doing that, here are some AWS interview questions and answers that will help you with the interview process. There are a number of different AWS-related questions covered in this article, ranging from basic to advanced, and scenario-based questions as well.

 

Basic AWS Interview Questions
1. Define and explain the three basic types of cloud services and the AWS products that are built based on them?
The three basic types of cloud services are:

Computing
Storage
Networking
Here are some of the AWS products that are built based on the three cloud service types:

Computing - These include EC2, Elastic Beanstalk, Lambda, Auto-Scaling, and Lightsat.

Storage - These include S3, Glacier, Elastic Block Storage, Elastic File System.

Networking - These include VPC, Amazon CloudFront, Route53

2. What is the relation between the Availability Zone and Region?
AWS regions are separate geographical areas, like the US-West 1 (North California) and Asia South (Mumbai). On the other hand, availability zones are the areas that are present inside the regions. These are generally isolated zones that can replicate themselves whenever required.

aws region

3. What is auto-scaling?
Auto-scaling is a function that allows you to provision and launch new instances whenever there is a demand. It allows you to automatically increase or decrease resource capacity in relation to the demand.

Become an AWS Wizard with our in-depth Cloud Architect Masterâ€™s Program. Enroll now!
4. What is geo-targeting in CloudFront?
Geo-Targeting is a concept where businesses can show personalized content to their audience based on their geographic location without changing the URL. This helps you create customized content for the audience of a specific geographical area, keeping their needs in the forefront.

5. What are the steps involved in a CloudFormation Solution?
Here are the steps involved in a CloudFormation solution:

cloud formation

Create or use an existing CloudFormation template using JSON or YAML format.
Save the code in an S3 bucket, which serves as a repository for the code.
Use AWS CloudFormation to call the bucket and create a stack on your template. 
CloudFormation reads the file and understands the services that are called, their order, the relationship between the services, and provisions the services one after the other.


Master's Program: AWS Cloud Architect
Become an Expert in Amazon Web ServicesENROLL NOWMaster's Program: AWS Cloud Architect
6. How do you upgrade or downgrade a system with near-zero downtime?
You can upgrade or downgrade a system with near-zero downtime using the following steps of migration:

Open EC2 console
Choose Operating System AMI
Launch an instance with the new instance type
Install all the updates
Install applications
Test the instance to see if itâ€™s working
If working, deploy the new instance and replace the older instance
Once itâ€™s deployed, you can upgrade or downgrade the system with near-zero downtime.
Take home these interview Q&As and get much more. Download the complete AWS Interview Guide here:

7. What are the tools and techniques that you can use in AWS to identify if you are paying more than you should be, and how to correct it?
You can know that you are paying the correct amount for the resources that you are using by employing the following resources:

Check the Top Services Table
It is a dashboard in the cost management console that shows you the top five most used services. This will let you know how much money you are spending on the resources in question.
Cost Explorer
There are cost explorer services available that will help you to view and analyze your usage costs for the last 13 months. You can also get a cost forecast for the upcoming three months.
AWS Budgets
This allows you to plan a budget for the services. Also, it will enable you to check if the current plan meets your budget and the details of how you use the services.
Cost Allocation Tags
This helps in identifying the resource that has cost more in a particular month. It lets you organize your resources and cost allocation tags to keep track of your AWS costs.
8. Is there any other alternative tool to log into the cloud environment other than console?
The that can help you log into the AWS resources are:

Putty
AWS CLI for Linux
AWS CLI for Windows
AWS CLI for Windows CMD
AWS SDK
Eclipse
9. What services can be used to create a centralized logging solution?
The essential services that you can use are Amazon CloudWatch Logs, store them in Amazon S3, and then use Amazon Elastic Search to visualize them. You can use Amazon Kinesis Firehose to move the data from Amazon S3 to Amazon ElasticSearch.

centralized logging

Free Course: Getting Started with AWS
Learn the Fundamentals of AWSENROLL NOWFree Course: Getting Started with AWS
10. What are the native AWS Security logging capabilities?
Most of the AWS services have their logging options. Also, some of them have an account level logging, like in AWS CloudTrail, AWS Config, and others. Letâ€™s take a look at two services in specific:

AWS CloudTrail
This is a service that provides a history of the AWS API calls for every account. It lets you perform security analysis, resource change tracking, and compliance auditing of your AWS environment as well. The best part about this service is that it enables you to configure it to send notifications via AWS SNS when new logs are delivered.

AWS Config 
This helps you understand the configuration changes that happen in your environment. This service provides an AWS inventory that includes configuration history, configuration change notification, and relationships between AWS resources. It can also be configured to send information via AWS SNS when new logs are delivered.

11. What is a DDoS attack, and what services can minimize them?
DDoS is a cyber-attack in which the perpetrator accesses a website and creates multiple sessions so that the other legitimate users cannot access the service. The native tools that can help you deny the DDoS attacks on your AWS services are:

AWS Shield
AWS WAF
Amazon Route53
Amazon CloudFront
ELB
VPC
DDOS attack

12. You are trying to provide a service in a particular region, but you do not see the service in that region. Why is this happening, and how do you fix it?
Not all Amazon AWS services are available in all regions. When Amazon initially launches a new service, it doesnâ€™t get immediately published in all the regions. They start small and then slowly expand to other regions. So, if you donâ€™t see a specific service in your region, chances are the service hasnâ€™t been published in your region yet. However, if you want to get the service that is not available, you can switch to the nearest region that provides the services.

13. How do you set up a system to monitor website metrics in real-time in AWS?
Amazon CloudWatch helps you to monitor the application status of various AWS services and custom events. It helps you to monitor:

State changes in Amazon EC2
Auto-scaling lifecycle events
Scheduled events
AWS API calls
Console sign-in events
amazon cloud watch

14. What are the different types of virtualization in AWS, and what are the differences between them?
The three major types of virtualization in AWS are: 

Hardware Virtual Machine (HVM)
It is a fully virtualized hardware, where all the virtual machines act separate from each other. These virtual machines boot by executing a master boot record in the root block device of your image.
Paravirtualization (PV)
Paravirtualization-GRUB is the bootloader that boots the PV AMIs. The PV-GRUB chain loads the kernel specified in the menu.
Paravirtualization on HVM
PV on HVM helps operating systems take advantage of storage and network I/O available through the host.
15. Name some of the AWS services that are not region-specific
AWS services that are not region-specific are:

IAM
Route 53
Web Application Firewall 
CloudFront
16. What are the differences between NAT Gateways and NAT Instances?
While both NAT Gateways and NAT Instances serve the same function, they still have some key differences.

Differences

17. What is CloudWatch?
The Amazon CloudWatch has the following features:

Depending on multiple metrics, it participates in triggering alarms.
Helps in monitoring the AWS environments like CPU utilization, EC2, Amazon RDS instances, Amazon SQS, S3, Load Balancer, SNS, etc.
18. What is an Elastic Transcoder?
To support multiple devices with various resolutions like laptops, tablets, and smartphones, we need to change the resolution and format of the video. This can be done easily by an AWS Service tool called the Elastic Transcoder, which is a media transcoding in the cloud that exactly lets us do the needful. It is easy to use, cost-effective, and highly scalable for businesses and developers.

AWS Questions for Amazon EC2
19. What is Amazon EC2?
EC2 is short for Elastic Compute Cloud, and it provides scalable computing capacity. Using Amazon EC2 eliminates the need to invest in hardware, leading to faster development and deployment of applications. You can use Amazon EC2 to launch as many or as few virtual servers as needed, configure security and networking, and manage storage. It can scale up or down to handle changes in requirements, reducing the need to forecast traffic. EC2 provides virtual computing environments called â€œinstances.â€

20. What Are Some of the Security Best Practices for Amazon EC2?
Security best practices for Amazon EC2 include using Identity and Access Management (IAM) to control access to AWS resources; restricting access by only allowing trusted hosts or networks to access ports on an instance; only opening up those permissions you require, and disabling password-based logins for instances launched from your AMI.

21. Can S3 Be Used with EC2 Instances, and If Yes, How?
Amazon S3 can be used for instances with root devices backed by local instance storage. That way, developers have access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of websites. To execute systems in the Amazon EC2 environment, developers load Amazon Machine Images (AMIs) into Amazon S3 and then move them between Amazon S3 and Amazon EC2.

Amazon EC2 and Amazon S3 are two of the best-known web services that make up AWS.

22. What is the difference between stopping and terminating an EC2 instance? 
While you may think that both stopping and terminating are the same, there is a difference. When you stop an EC2 instance, it performs a normal shutdown on the instance and moves to a stopped state. However, when you terminate the instance, it is transferred to a stopped state, and the EBS volumes attached to it are deleted and can never be recovered. 

23. What are the different types of EC2 instances based on their costs?
The three types of EC2 instances are:

On-demand Instance
It is cheap for a short time but not when taken for the long term
Spot Instance
It is less expensive than the on-demand instance and can be bought through bidding. 
Reserved Instance
If you are planning to use an instance for a year or more, then this is the right one for you.
24. How do you set up SSH agent forwarding so that you do not have to copy the key every time you log in?
Hereâ€™s how you accomplish this:

Go to your PuTTY Configuration
Go to the category SSH -> Auth
Enable SSH agent forwarding to your instance
Putty configuration

25. What are Solaris and AIX operating systems? Are they available with AWS?
Solaris is an operating system that uses SPARC processor architecture, which is not supported by the public cloud currently. 

AIX is an operating system that runs only on Power CPU and not on Intel, which means that you cannot create AIX instances in EC2.

Since both the operating systems have their limitations, they are not currently available with AWS.

26. How do you configure CloudWatch to recover an EC2 instance?
Hereâ€™s how you can configure them:

Create an Alarm using Amazon CloudWatch
In the Alarm, go to Define Alarm -> Actions tab
Choose Recover this instance option
create alarm

27. What are the common types of AMI designs?
There are many types of AMIs, but some of the common AMIs are:

Fully Baked AMI
Just Enough Baked AMI (JeOS AMI)
Hybrid AMI
28. What are Key-Pairs in AWS?
The Key-Pairs are password-protected login credentials for the Virtual Machines that are used to prove our identity while connecting the Amazon EC2 instances. The Key-Pairs are made up of a Private Key and a Public Key which lets us connect to the instances.

AWS Interview Questions for S3
29. What is Amazon S3? 
S3 is short for Simple Storage Service, and Amazon S3 is the most supported storage platform available. S3 is object storage that can store and retrieve any amount of data from anywhere. Despite that versatility, it is practically unlimited as well as cost-effective because it is storage available on demand. In addition to these benefits, it offers unprecedented levels of durability and availability. Amazon S3 helps to manage data for cost optimization, access control, and compliance. 

30. How can you recover/login to an EC2 instance for which you have lost the key?
Follow the steps provided below to recover an EC2 instance if you have lost the key:

Verify that the EC2Config service is running
Detach the root volume for the instance
Attach the volume to a temporary instance
Modify the configuration file
Restart the original instance
31. What are some critical differences between AWS S3 and EBS?
Here are some differences between AWS S3 and EBS

feature differences

32. How do you allow a user to gain access to a specific bucket?
You need to follow the four steps provided below to allow access. They are:

Categorize your instances
Define how authorized users can manage specific servers.
Lockdown your tags
Attach your policies to IAM users
 

33. How can you monitor S3 cross-region replication to ensure consistency without actually checking the bucket?
Follow the flow diagram provided below to monitor S3 cross-region replication:

S3 cross region

34. What is SnowBall?
To transfer terabytes of data outside and inside of the AWS environment, a small application called SnowBall is used. 

Data transferring using SnowBall is done in the following ways:

A job is created.
The SnowBall application is connected.
The data is copied into the SnowBall application.
Data is then moved to the AWS S3.
35. What are the Storage Classes available in Amazon S3?
The Storage Classes that are available in the Amazon S3 are the following:

Amazon S3 Glacier Instant Retrieval storage class
Amazon S3 Glacier Flexible Retrieval (Formerly S3 Glacier) storage class
Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive)
S3 Outposts storage class
Amazon S3 Standard-Infrequent Access (S3 Standard-IA)
Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)
Amazon S3 Standard (S3 Standard)
Amazon S3 Reduced Redundancy Storage
Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering)
AWS Interview Questions for VPC
36. What Is Amazon Virtual Private Cloud (VPC) and Why Is It Used?
A VPC is the best way of connecting to your cloud resources from your own data center. Once you connect your datacenter to the VPC in which your instances are present, each instance is assigned a private IP address that can be accessed from your data center. That way, you can access your public cloud resources as if they were on your own private network.

37. VPC is not resolving the server through DNS. What might be the issue, and how can you fix it?
To fix this problem, you need to enable the DNS hostname resolution, so that the problem resolves itself.

38. How do you connect multiple sites to a VPC?
If you have multiple VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub. Hereâ€™s a diagram that will show you how to connect various sites to a VPC:

customer gateway

39. Name and explain some security products and features available in VPC?
Here is a selection of security products and features:

Security groups - This acts as a firewall for the EC2 instances, controlling inbound and outbound traffic at the instance level.
Network access control lists - It acts as a firewall for the subnets, controlling inbound and outbound traffic at the subnet level.
Flow logs - These capture the inbound and outbound traffic from the network interfaces in your VPC.
40. How do you monitor Amazon VPC?
You can monitor VPC by using:

CloudWatch and CloudWatch logs
VPC Flow Logs
41. How many Subnets can you have per VPC?
We can have up to 200 Subnets per Amazon Virtual Private Cloud (VPC).

Do you want to upskill and become a master cloud programmer? Then enroll now in our AWS Cloud Architect Masterâ€™s Program!
General AWS Interview Questions
42. When Would You Prefer Provisioned IOPS over Standard Rds Storage?
You would use Provisioned IOPS when you have batch-oriented workloads. Provisioned IOPS delivers high IO rates, but it is also expensive. However, batch processing workloads do not require manual intervention. 

43. How Do Amazon Rds, Dynamodb, and Redshift Differ from Each Other?
Amazon RDS is a database management service for relational databases. It manages patching, upgrading, and data backups automatically. Itâ€™s a database management service for structured data only. On the other hand, DynamoDB is a NoSQL database service for dealing with unstructured data. Redshift is a data warehouse product used in data analysis.

44. What Are the Benefits of AWSâ€™s Disaster Recovery?
Businesses use cloud computing in part to enable faster disaster recovery of critical IT systems without the cost of a second physical site. The AWS cloud supports many popular disaster recovery architectures ranging from small customer workload data center failures to environments that enable rapid failover at scale. With data centers all over the world, AWS provides a set of cloud-based disaster recovery services that enable rapid recovery of your IT infrastructure and data.

45. How can you add an existing instance to a new Auto Scaling group?
Hereâ€™s how you can add an existing instance to a new Auto Scaling group:

Open EC2 console
Select your instance under Instances
Choose Actions -> Instance Settings -> Attach to Auto Scaling Group
Select a new Auto Scaling group
Attach this group to the Instance
Edit the Instance if needed
Once done, you can successfully add the instance to a new Auto Scaling group
46. What are the factors to consider while migrating to Amazon Web Services?
Here are the factors to consider during AWS migration:

Operational Costs - These include the cost of infrastructure, ability to match demand and supply, transparency, and others.
Workforce Productivity 
Cost avoidance
Operational resilience
Business agility
AWS Solutions Architect Certification Course
Your Ticket To Becoming A AWS Solutions ArchitectEXPLORE COURSEAWS Solutions Architect Certification Course
47. What is RTO and RPO in AWS?
RTO or Recovery Time Objective is the maximum time your business or organization is willing to wait for a recovery to complete in the wake of an outage. On the other hand, RPO or Recovery Point Objective is the maximum amount of data loss your company is willing to accept as measured in time.

48. If you would like to transfer vast amounts of data, which is the best option among Snowball, Snowball Edge, and Snowmobile?
AWS Snowball is basically a data transport solution for moving high volumes of data into and out of a specified AWS region. On the other hand, AWS Snowball Edge adds additional computing functions apart from providing a data transport solution. The snowmobile is an exabyte-scale migration service that allows you to transfer data up to 100 PB.

49. Explain what T2 instances are?
The T2 Instances are intended to give the ability to burst to a higher performance whenever the workload demands it and also provide a moderate baseline performance to the CPU.

The T2 instances are General Purpose instance types and are low in cost as well. They are usually used wherever workloads do not consistently or often use the CPU. 

50. What are the advantages of AWS IAM?
AWS IAM allows an administrator to provide multiple users and groups with granular access. Various user groups and users may require varying levels of access to the various resources that have been developed. We may assign roles to users and create roles with defined access levels using IAM.

It further gives us Federated Access, which allows us to grant applications and users access to resources without having to create IAM Roles.

51. Explain Connection Draining
Connection Draining is an AWS service that allows us to serve current requests on the servers that are either being decommissioned or updated.

By enabling this Connection Draining, we let the Load Balancer make an outgoing instance finish its existing requests for a set length of time before sending it any new requests. A departing instance will immediately go off if Connection Draining is not enabled, and all pending requests will fail.

52. What is Power User Access in AWS?
The AWS Resources owner is identical to an Administrator User. The Administrator User can build, change, delete, and inspect resources, as well as grant permissions to other AWS users.

Administrator Access without the ability to control users and permissions is provided to a Power User. A Power User Access user cannot provide permissions to other users but has the ability to modify, remove, view, and create resources.
AWS Questions for CloudFormation
53. How is AWS CloudFormation different from AWS Elastic Beanstalk?
Here are some differences between AWS CloudFormation and AWS Elastic Beanstalk:

AWS CloudFormation helps you provision and describe all of the infrastructure resources that are present in your cloud environment. On the other hand, AWS Elastic Beanstalk provides an environment that makes it easy to deploy and run applications in the cloud.
AWS CloudFormation supports the infrastructure needs of various types of applications, like legacy applications and existing enterprise applications. On the other hand, AWS Elastic Beanstalk is combined with the developer tools to help you manage the lifecycle of your applications.
54. What are the elements of an AWS CloudFormation template?
AWS CloudFormation templates are YAML or JSON formatted text files that are comprised of five essential elements, they are:

Template parameters
Output values
Data tables
Resources
File format version
55. What happens when one of the resources in a stack cannot be created successfully?
If the resource in the stack cannot be created, then the CloudFormation automatically rolls back and terminates all the resources that were created in the CloudFormation template. This is a handy feature when you accidentally exceed your limit of Elastic IP addresses or donâ€™t have access to an EC2 AMI.

AWS cloud formation

AWS Questions for Elastic Block Storage
56. How can you automate EC2 backup using EBS?
Use the following steps in order to automate EC2 backup using EBS:

Get the list of instances and connect to AWS through API to list the Amazon EBS volumes that are attached locally to the instance.
List the snapshots of each volume, and assign a retention period of the snapshot. Later on, create a snapshot of each volume.
Make sure to remove the snapshot if it is older than the retention period.
57. What is the difference between EBS and Instance Store?
EBS is a kind of permanent storage in which the data can be restored at a later point. When you save data in the EBS, it stays even after the lifetime of the EC2 instance. On the other hand, Instance Store is temporary storage that is physically attached to a host machine. With an Instance Store, you cannot detach one instance and attach it to another. Unlike in EBS, data in an Instance Store is lost if any instance is stopped or terminated.

58. Can you take a backup of EFS like EBS, and if yes, how?
Yes, you can use the EFS-to-EFS backup solution to recover from unintended changes or deletion in Amazon EFS. Follow these steps:

Sign in to the AWS Management Console
Click the launch EFS-to-EFS-restore button
Use the region selector in the console navigation bar to select region
Verify if you have chosen the right template on the Select Template page
Assign a name to your solution stack
Review the parameters for the template and modify them if necessary
59. How do you auto-delete old snapshots?
Hereâ€™s the procedure for auto-deleting old snapshots:

As per procedure and best practices, take snapshots of the EBS volumes on Amazon S3.
Use AWS Ops Automator to handle all the snapshots automatically.
This allows you to create, copy, and delete Amazon EBS snapshots.
S3

Take your career to the clouds with our Cloud Architect Masterâ€™s Program! Enroll now and become an expert in cloud architecture and technologies.
AWS Interview Questions for Elastic Load Balancing
60. What are the different types of load balancers in AWS?
There are three types of load balancers that are supported by Elastic Load Balancing:

Application Load Balancer
Network Load Balancer
Classic Load Balancer
61. What are the different uses of the various load balancers in AWS Elastic Load Balancing?
Application Load Balancer
Used if you need flexible application management and TLS termination.

Network Load Balancer
Used if you require extreme performance and static IPs for your applications.

Classic Load Balancer
Used if your application is built within the EC2 Classic network

AWS Interview Questions for Security
62. What Is Identity and Access Management (IAM) and How Is It Used?
Identity and Access Management (IAM) is a web service for securely controlling access to AWS services. IAM lets you manage users, security credentials such as access keys, and permissions that control which AWS resources users and applications can access.

63. How can you use AWS WAF in monitoring your AWS applications?
AWS WAF or AWS Web Application Firewall protects your web applications from web exploitations. It helps you control the traffic flow to your applications. With WAF, you can also create custom rules that block common attack patterns. It can be used for three cases: allow all requests, prevent all requests, and count all requests for a new policy.

64. What are the different AWS IAM categories that you can control?
Using AWS IAM, you can do the following:

Create and manage IAM users
Create and manage IAM groups
Manage the security credentials of the users
Create and manage policies to grant access to AWS services and resources
65. What are the policies that you can set for your usersâ€™ passwords?
Here are some of the policies that you can set:

You can set a minimum length of the password, or you can ask the users to add at least one number or special characters in it.
You can assign requirements of particular character types, including uppercase letters, lowercase letters, numbers, and non-alphanumeric characters.
You can enforce automatic password expiration, prevent reuse of old passwords, and request for a password reset upon their next AWS sign in.
You can have the AWS users contact an account administrator when the user has allowed the password to expire. 
66. What is the difference between an IAM role and an IAM user?
The two key differences between the IAM role and IAM user are:

An IAM role is an IAM entity that defines a set of permissions for making AWS service requests, while an IAM user has permanent long-term credentials and is used to interact with the AWS services directly.  
In the IAM role, trusted entities, like IAM users, applications, or an AWS service, assume roles whereas the IAM user has full access to all the AWS IAM functionalities.
67. What are the managed policies in AWS IAM?
There are two types of managed policies; one that is managed by you and one that is managed by AWS. They are IAM resources that express permissions using IAM policy language. You can create, edit, and manage them separately from the IAM users, groups, and roles to which they are attached.

68. Can you give an example of an IAM policy and a policy summary?
Hereâ€™s an example of an IAM policy to grant access to add, update, and delete objects from a specific folder.

IAM policy

Hereâ€™s an example of a policy summary:

policy summary

69. How does AWS IAM help your business?
IAM enables to:

Manage IAM users and their access - AWS IAM provides secure resource access to multiple users
Manage access for federated users â€“ AWS allows you to provide secure access to resources in your AWS account to your employees and applications without creating IAM roles
AWS Interview Questions for Route 53
70. What Is Amazon Route 53?
Amazon Route 53 is a scalable and highly available Domain Name System (DNS). The name refers to TCP or UDP port 53, where DNS server requests are addressed.

71. What Is Cloudtrail and How Do Cloudtrail and Route 53 Work Together? 
CloudTrail is a service that captures information about every request sent to the Amazon Route 53 API by an AWS account, including requests that are sent by IAM users. CloudTrail saves log files of these requests to an Amazon S3 bucket. CloudTrail captures information about all requests. You can use information in the CloudTrail log files to determine which requests were sent to Amazon Route 53, the IP address that the request was sent from, who sent the request, when it was sent, and more.

72. What is the difference between Latency Based Routing and Geo DNS?
The Geo Based DNS routing takes decisions based on the geographic location of the request. Whereas, the Latency Based Routing utilizes latency measurements between networks and AWS data centers. Latency Based Routing is used when you want to give your customers the lowest latency possible. On the other hand, Geo Based routing is used when you want to direct the customer to different websites based on the country or region they are browsing from. 

73. What is the difference between a Domain and a Hosted Zone?
Domain
A domain is a collection of data describing a self-contained administrative and technical unit. For example, www.simplilearn.com is a domain and a general DNS concept.

Hosted zone
A hosted zone is a container that holds information about how you want to route traffic on the internet for a specific domain. For example, lms.simplilearn.com is a hosted zone.

74. How does Amazon Route 53 provide high availability and low latency?
Hereâ€™s how Amazon Route 53 provides the resources in question:

Globally Distributed Servers
Amazon is a global service and consequently has DNS services globally. Any customer creating a query from any part of the world gets to reach a DNS server local to them that provides low latency. 

Dependency
Route 53 provides a high level of dependability required by critical applications

Optimal Locations
Route 53 uses a global anycast network to answer queries from the optimal position automatically. 

AWS Interview Questions for Config
75. How does AWS config work with AWS CloudTrail?
AWS CloudTrail records user API activity on your account and allows you to access information about the activity. Using CloudTrail, you can get full details about API actions such as the identity of the caller, time of the call, request parameters, and response elements. On the other hand, AWS Config records point-in-time configuration details for your AWS resources as Configuration Items (CIs). 

You can use a CI to ascertain what your AWS resource looks like at any given point in time. Whereas, by using CloudTrail, you can quickly answer who made an API call to modify the resource. You can also use Cloud Trail to detect if a security group was incorrectly configured.

76. Can AWS Config aggregate data across different AWS accounts?
Yes, you can set up AWS Config to deliver configuration updates from different accounts to one S3 bucket, once the appropriate IAM policies are applied to the S3 bucket.

AWS Interview Questions for Database
77. How are reserved instances different from on-demand DB instances?
Reserved instances and on-demand instances are the same when it comes to function. They only differ in how they are billed.

Reserved instances are purchased as one-year or three-year reservations, and in return, you get very low hourly based pricing when compared to the on-demand cases that are billed on an hourly basis.

78. Which type of scaling would you recommend for RDS and why?
There are two types of scaling - vertical scaling and horizontal scaling. Vertical scaling lets you vertically scale up your master database with the press of a button. A database can only be scaled vertically, and there are 18 different instances in which you can resize the RDS. On the other hand, horizontal scaling is good for replicas. These are read-only replicas that can only be done through Amazon Aurora.

79. What is a maintenance window in Amazon RDS? Will your DB instance be available during maintenance events?
RDS maintenance window lets you decide when DB instance modifications, database engine version upgrades, and software patching have to occur. The automatic scheduling is done only for patches that are related to security and durability. By default, there is a 30-minute value assigned as the maintenance window and the DB instance will still be available during these events though you might observe a minimal effect on performance.

Master the art of building complex and demanding apps in AWS. Understand architectural principles and services of AWS with our Cloud Architect Masterâ€™s Program.

8X higher interaction | Simplilearn JobAssist | Lifetime Access
80. What are the consistency models in DynamoDB?
There are two consistency models In DynamoDB. First, there is the Eventual Consistency Model, which maximizes your read throughput. However, it might not reflect the results of a recently completed write. Fortunately, all the copies of data usually reach consistency within a second. The second model is called the Strong Consistency Model. This model has a delay in writing the data, but it guarantees that you will always see the updated data every time you read it. 

81. What type of query functionality does DynamoDB support?
DynamoDB supports GET/PUT operations by using a user-defined primary key. It provides flexible querying by letting you query on non-primary vital attributes using global secondary indexes and local secondary indexes.

 

AWS Interview Questions - Short Answer Questions 
1. Suppose you are a game designer and want to develop a game with single-digit millisecond latency, which of the following database services would you use?
Amazon DynamoDB

2. If you need to perform real-time monitoring of AWS services and get actionable insights, which services would you use?
Amazon CloudWatch

3. As a web developer, you are developing an app, targeted primarily for the mobile platform. Which of the following lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily?
Amazon Cognito

4. You are a Machine Learning Engineer who is on the lookout for a solution that will discover sensitive information that your enterprise stores in AWS and then use NLP to classify the data and provide business-related insights. Which among the services would you choose?
AWS Macie

5. You are the system administrator in your company, which is running most of its infrastructure on AWS. You are required to track your users and keep tabs on how they are being authenticated. You wish to create and manage AWS users and use permissions to allow and deny their access to AWS resources. Which of the following services suits you best?
AWS IAM

6. Which service do you use if you want to allocate various private and public IP addresses to make them communicate with the internet and other instances?
Amazon VPC

7. This service provides you with cost-efficient and resizable capacity while automating time-consuming administration tasks
Amazon Relational Database Service

8. Which of the following is a means for accessing human researchers or consultants to help solve problems on a contractual or temporary basis?
Amazon Mechanical Turk

9. This service is used to make it easy to deploy, manage, and scale containerized applications using Kubernetes on AWS. Which of the following is this AWS service?
Amazon Elastic Container Service

10. This service lets you run code without provisioning or managing servers. Select the correct service from the below options
AWS Lambda

11. As an AWS Developer, using this pay-per-use service, you can send, store, and receive messages between software components. Which of the following is it?
Amazon Simple Queue Service

12. Which service do you use if you would like to host a real-time audio and video conferencing application on AWS, this service provides you with a secure and easy-to-use application?
Amazon Chime

13. As your company's AWS Solutions Architect, you are in charge of designing thousands of similar individual jobs. Which of the following services best meets your requirements?
AWS Batch

AWS Interview Questions - Multiple-Choice
1. Suppose you are a game designer and want to develop a game with single-digit millisecond latency, which of the following database services would you use?
Amazon RDS
Amazon Neptune
Amazon Snowball
Amazon DynamoDB
2. If you need to perform real-time monitoring of AWS services and get actionable insights, which services would you use?
Amazon Firewall Manager
Amazon GuardDuty
Amazon CloudWatch
Amazon EBS
3. As a web developer, you are developing an app, targeted especially for the mobile platform. Which of the following lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily?
AWS Shield
AWS Macie
AWS Inspector
Amazon Cognito
4. You are a Machine Learning Engineer who is on the lookout for a solution that will discover sensitive information that your enterprise stores in AWS and then use NLP to classify the data and provide business-related insights. Which among the services would you choose?
AWS Firewall Manager
AWS IAM
AWS Macie
AWS CloudHSM
5. You are the system administrator in your company, which is running most of its infrastructure on AWS. You are required to track your users and keep tabs on how they are being authenticated. You wish to create and manage AWS users and use permissions to allow and deny their access to AWS resources. Which of the following services suits you best?
AWS Firewall Manager
AWS Shield
Amazon API Gateway
AWS IAM
6. Which service do you use if you want to allocate various private and public IP addresses in order to make them communicate with the internet and other instances?
Amazon Route 53
Amazon VPC
Amazon API Gateway
Amazon CloudFront
 

7. This service provides you with cost-efficient and resizable capacity while automating time-consuming administration tasks
Amazon Relational Database Service
Amazon Elasticache
Amazon VPC
Amazon Glacier
8. Which of the following is a means for accessing human researchers or consultants to help solve problems on a contractual or temporary basis?
Amazon Mechanical Turk
Amazon Elastic Mapreduce
Amazon DevPay
Multi-Factor Authentication
9. This service is used to make it easy to deploy, manage, and scale containerized applications using Kubernetes on AWS. Which of the following is this AWS service?
Amazon Elastic Container Service
AWS Batch
AWS Elastic Beanstalk
Amazon Lightsail
10. This service lets you run code without provisioning or managing servers. Select the correct service from the below options
Amazon EC2 Auto Scaling
AWS Lambda
AWS Batch
Amazon Inspector
11. As an AWS Developer, using this pay-per-use service, you can send, store and receive messages between software components. Which of the following is it?
AWS Step Functions
Amazon MQ
Amazon Simple Queue Service
Amazon Simple Notification Service
12. Which service do you use if you would like to host real-time audio and video conferencing application on AWS, this service provides you with a secure and easy-to-use application?
Amazon Chime
Amazon WorkSpaces
Amazon MQ
Amazon AppStream
13. As your company's AWS Solutions Architect, you are in charge of designing thousands of similar individual jobs. Which of the following services best meets your requirements?
AWS EC2 Auto Scaling
AWS Snowball
AWS Fargate
AWS Batch
14. You are a Machine Learning engineer and you are looking for a service that helps you build and train Machine Learning models in AWS. Which among the following are we referring to?
Amazon SageMaker
AWS DeepLens
Amazon Comprehend
Device Farm
15. Imagine that you are working for your company's IT team. You are assigned to adjusting the capacity of AWS resources based on the incoming application and network traffic. How would you do it?
Amazon VPC
AWS IAM
Amazon Inspector
Amazon Elastic Load Balancing
16. This cross-platform video game development engine that supports PC, Xbox, Playstation, iOS, and Android platforms allows developers to build and host their games on Amazon's servers.
Amazon GameLift
AWS Greengrass
Amazon Lumberyard
Amazon Sumerian
17. You are the Project Manager of your company's Cloud Architects team. You are required to visualize, understand and manage your AWS costs and usage over time. Which of the following services works best?
AWS Budgets
AWS Cost Explorer
Amazon WorkMail
Amazon Connect
18. You are the chief Cloud Architect at your company. How can you automatically monitor and adjust computer resources to ensure maximum performance and efficiency of all scalable resources?
AWS CloudFormation 
AWS Aurora
AWS Auto Scaling
Amazon API Gateway
19. As a database administrator. you will employ a service that is used to set up and manage databases such as MySQL, MariaDB, and PostgreSQL. Which service are we referring to?
Amazon Aurora
AWS RDS
Amazon Elasticache
AWS Database Migration Service
20. A part of your marketing work requires you to push messages onto Google, Facebook, Windows, and Apple through APIs or AWS Management Console. Which of the following services do you use?
AWS CloudTrail
AWS Config
Amazon Chime
AWS Simple Notification Service
The aforementioned AWS interview questions and answers are just some of the examples of what you can come across while interviewing in the AWS domain. While these questions and answers provide you a good idea of how wide the AWS domain is, it doesnâ€™t teach you about AWS. If you want to learn AWS in detail, check out the AWS cloud architect master program. This course helps you achieve a thorough expertise in AWS solutions, and will be a valuable resource when looking for that new, rewarding career in the cloud!

Find our Cloud Architect Online Bootcamp in top cities:
Name	Date	Place	
Cloud Architect	Class starts on 8th Oct 2022,
Weekend batch	Your City	View Details
Cloud Architect	Class starts on 10th Oct 2022,
Weekdays batch	Hyderabad	View Details
Cloud Architect	Class starts on 17th Oct 2022,
Weekdays batch	Pune	View Details



https://www.javatpoint.com/aws-interview-questions
AWS Interview Questions
AWS Interview Questions
A list of top frequently asked AWS Interview Questions and answers are given below.

1) What is AWS?
AWS stands for Amazon Web Services. It is a service which is provided by the Amazon that uses distributed IT infrastructure to provide different IT resources on demand. It provides different services such as an infrastructure as a service, platform as a service, and software as a service.

2) What are the components of AWS?
The following are the main components of AWS are:

Simple Storage Service: S3 is a service of aws that stores the files. It is object-based storage, i.e., you can store the images, word files, pdf files, etc. The size of the file that can be stored in S3 is from 0 Bytes to 5 TB. It is an unlimited storage medium, i.e., you can store the data as much you want. S3 contains a bucket which stores the files. A bucket is like a folder that stores the files. It is a universal namespace, i.e., name must be unique globally. Each bucket must have a unique name to generate the unique DNS address.
Elastic Compute Cloud: Elastic Compute Cloud is a web service that provides resizable compute capacity in the cloud. You can scale the compute capacity up and down as per the computing requirement changes. It changes the economics of computing by allowing you to pay only for the resources that you actually use.
Elastic Block Store: It provides a persistent block storage volume for use with EC2 instances in aws cloud. EBS volume is automatically replicated within its availability zone to prevent the component failure. It offers high durability, availability, and low-latency performance required to run your workloads.
CloudWatch: It is a service which is used to monitor all the AWS resources and applications that you run in real time. It collects and tracks the metrics that measure your resources and applications. If you want to know about the CloudWatch in detail, then click on the below link: Click here
Identity Access Management: It is a service of aws used to manage users and their level of access to the aws management console. It is used to set users, permissions, and roles. It allows you to grant permission to the different parts of the aws platform. If you want to know about the IAM, then click the below link: Click here
Simple Email Service: Amazon Simple Email Service is a cloud-based email sending service that helps digital marketers and application developers to send marketing, notification, and transactional emails. This service is very reliable and cost-effective for the businesses of all the sizes that want to keep in touch with the customers.
Route53: It is a highly available and scalable DNS (Domain Name Service) service. It provides a reliable and cost-effective way for the developers and businesses to route end users to internet applications by translating domain names into numeric IP addresses. If you want to know more about Route53 in detail, then click on the link given below: Click here
3) What are Key-pairs?
An Amazon EC2 uses public key cryptography which is used to encrypt and decrypt the login information. In public key cryptography, the public key is used to encrypt the information while at the receiver's side, a private key is used to decrypt the information. The combination of a public key and the private key is known as key-pairs. Key-pairs allows you to access the instances securely.



4) What is S3?
S3 is a storage service in aws that allows you to store the vast amount of data. To know more about S3, click on the link given below:

Click here
5) What are the pricing models for EC2 instances?
There are four pricing models for EC2 instances:

On-Demand instance
On-Demand pricing is also known as pay-as-you-go. Pay-as-you-go is a pricing model that allows you to pay only for those resources that you use.
You need to pay for the compute capacity by per hour or per second that depends on which instances you run.
On-Demand instance does not require any upfront payments.
While using On-Demand instance, you can increase or decrease the compute capacity based on the requirements of your application.
On-Demand instances are recommended for those applications which are of short term and unpredictable workloads.
Users that want low cost and flexibility on EC2 instances with no upfront payments.
On-Demand instances are used for those applications which have been developed or tested on EC2 for the first time.
Reserved instance
Reserved instance is the second most important pricing model that reduces the overall cost of your AWS environment by making an upfront payment for those services that you know will be used in the future.
Reserved instances provide a discount of up to 75% as compared to On-Demand instance.
Reserved instances are assigned to a specific Availability zone that reserves the compute capacity for you so that you can use whenever you need.
Reserved instances are mainly recommended for those applications that have steady state and require reserve capacity.
Customers who want to use the EC2 over 1 to 3 term can use the reserved instance to reduce the overall computing costs.
Spot instance
Spot instances consist of unused capacity which is available at a highly discounted rate.
It offers up to 90% discount as compared to On-Demand instance.
Spot instances are mainly recommended for those applications which have flexible start and end times.
It is useful when applications require computing capacity at a very low price.
It is useful when applications require additional amount of computing capacity at an urgent need.
Dedicated Hosts
It is a physical EC2 server which is dedicated for your use. It reduces the overall costs by providing you a VPC that comprise of a dedicated hardware.
6) What is AWS Lambda?
AWS Lambda is a compute service that runs your code without managing servers. Lambda function runs your code whenever needed. You need to pay only when your code is running. If you want to know more about the AWS Lambda, then click on the link shown below:

Click Here
7) How many buckets can be created in S3?
By default, you can create up to 100 buckets.

8) What is Cross Region Replication?
Cross Region Replication is a service available in aws that enables to replicate the data from one bucket to another bucket which could be in a same or different region. It provides asynchronous copying of objects, i.e., objects are not copied immediately. If you want to know more about the Cross Region Replication, then click on the link shown below:

Click Here
9) What is CloudFront?
CloudFront is a computer delivery network which consists of distributed servers that delivers web pages and web content to a user based on the geographic locations of a user. If you want to know more about the CloudFront, then click on the link shown below:

Click Here
10) What are Regions and Availability Zones in aws?
Regions: A region is a geographical area which consists of 2 or more availability zones. A region is a collection of data centers which are completely isolated from other regions.

Availability zones: An Availability zone is a data center that can be somewhere in the country or city. Data center can have multiple servers, switches, firewalls, load balancing. The things through which you can interact with the cloud reside inside the Data center.


If you want to know more about the Availability zone and region, then click on the link shown below:

Click Here
11) What are edge locations in aws?
Edge locations are the endpoints in aws used for caching content. If you want to know more about the edge locations, then click on the link shown below:

Click Here
12) What is the minimum and maximum size that you can store in S3?
The minimum size of an object that you can store in S3 is 0 bytes and the maximum size of an object that you can store in S3 is 5 TB.

13) What are EBS Volumes?
Elastic Block Store is a service that provides a persistent block storage volume for use with EC2 instances in aws cloud. EBS volume is automatically replicated within its availability zone to prevent from the component failure. It offers high durability, availability, and low-latency performance required to run your workloads. . If you want to know more about the EBS Volumes, then click on the link shown below:

Click Here
14) What is Auto Scaling?
Auto Scaling is a feature in aws that automatically scales the capacity to maintain steady and predictable performance. While using auto scaling, you can scale multiple resources across multiple services in minutes. If you are already using Amazon EC2 Auto- scaling, then you can combine Amazon EC2 Auto-Scaling with the Auto-Scaling to scale additional resources for other AWS services.


Benefits of Auto Scaling

Setup Scaling Quickly
It sets the target utilization levels of multiple resources in a single interface. You can see the average utilization level of multiple resources in the same console, i.e., you do not have to move to the different console.
Make Smart Scaling Decisions
It makes the scaling plans that automate how different resources respond to the changes. It optimizes the availability and cost. It automatically creates the scaling policies and sets the targets based on your preference. It also monitors your application and automatically adds or removes the capacity based on the requirements.
Automatically maintain performance
Auto Scaling automatically optimize the application performance and availability even when the workloads are unpredictable. It continuously monitors your application to maintain the desired performance level. When demand rises, then Auto Scaling automatically scales the resources.
15) What is AMI?
AMI stands for Amazon Machine Image. It is a virtual image used to create a virtual machine within an EC2 instance. If you want to know more about the AMI, then click on the link shown below:

Click Here
16) Can a AMI be shared?
Yes, an AMI can be shared.


17) What is an EIP?
EIP (Elastic IP address) is a service provided by an EC2 instance. It is basically a static IP address attached to an EC2 instance. This address is associated with your AWS account not with an EC2 instance. You can also disassociate your EIP address from your EC2 instance and map it to another EC2 instance in your AWS account.

Let's understand the concept of EIP through an example:

AWS Interview Questions
Suppose we consider the website www.javatpoint.com
points to the instance which has a public IP address. When instance is restarted, then AWS takes another public IP address from the pool and the previous public IP address is no longer valid. Due to this reason, the original link is no longer available between the website and EC2 instance. To overcome from such situation, Elastic IP address or static address is used which does not change.

18) What are the different storage classes in S3?
Storage classes are used to assist the concurrent loss of data in one or two facilities. Each object in S3 is associated with some storage class. Amazon S3 contains some storage classes in which you can store your objects. You can choose a storage class based on your requirements and these storage classes offer high durability. To know more about the storage classes and its types, click on the link given below:

Click Here
19) How can you secure the access to your S3 bucket?
S3 bucket can be secured in two ways:

ACL (Access Control List)
ACL is used to manage the access of resources to buckets and objects. An object of each bucket is associated with ACL. It defines which AWS accounts have granted access and the type of access. When a user sends the request for a resource, then its corresponding ACL will be checked to verify whether the user has granted access to the resource or not.
When you create a bucket, then Amazon S3 creates a default ACL which provides a full control over the AWS resources.
Bucket Policies
Bucket policies are only applied to S3 bucket. Bucket policies define what actions are allowed or denied. Bucket policies are attached to the bucket not to an S3 object but the permissions define in the bucket policy are applied to all the objects in S3 bucket.
The following are the main elements of Bucket policy:

Sid
A Sid determines what the policy will do. For example, if an action that needs to be performed is adding a new user to an Access Control List (ACL), then the Sid would be AddCannedAcl. If the policy is defined to evaluate IP addresses, then the Sid would be IPAllow.
Effect: An effect defines an action after applying the policy. The action could be either to allow an action or to deny an action.
Principal
A Principal is a string that determines to whom the policy is applied. If we set the principal string as '*', then the policy is applied to everyone, but it is also possible that you can specify individual AWS account.
Action
An Action is what happens when the policy is applied. For example, s3:Getobject is an action that allows to read object data.
Resource
The Resource is a S3 bucket to which the statement is applied. You cannot enter a simply bucket name, you need to specify the bucket name in a specific format. For example, the bucket name is javatpoint-bucket, then the resource would be written as "arn:aws:s3""javatpoint-bucket/*".
20) What are policies and what are the different types of policies?
Policy is an object which is associated with a resource that defines the permissions. AWS evaluate these policies when user makes a request. Permissions in the policy determine whether to allow or to deny an action. Policies are stored in the form of a JSON documents.

AWS supports six types of policies:

Identity-based policies
Resource-based policies
Permissions boundaries
Organizations SCPs
Access Control Lists
Session policies
AWS Interview Questions
Identity-based policies
Identity-based policies are the permissions stored in the form of JSON format. This policy can be attached to an identity user, group of users or role. It determines the actions that the users can perform, on which resources, and under what conditions.
Identity-based policies are further classified into two categories:
Managed Policies: Managed Policies are the identity-based policies which can be attached to multiple users, groups or roles. There are two types of managed policies:
AWS Managed Policies
AWS Managed Policies are the policies created and managed by AWS. If you are using the policies first time, then we recommend you to use AWS Managed Policies.
Custom Managed Policies
Custom Managed Policies are the identity-based policies created by user. It provides more precise control over the policies than AWS Managed Policies.
Inline Policies
Inline Policies are the policies created and managed by user. These policies are encapsulated directly into a single user, group or a role.
Resource-Based Policies
Resource-based policies are the policies which are attached to the resource such as S3 bucket. Resource-based policies define the actions that can be performed on the resource and under what condition, these policies can be applied.
Permissions boundaries
Permissions boundaries are the maximum permissions that identity-based policy can grant to the entity.
Service Control Policies (SCPs)
Service Control Policies are the policies defined in a JSON format that specify the maximum permissions for an organization. If you enable all the features in an Organization, then you can apply Service Control Policies to any or all of your AWS accounts. SCP can limit the permission on entities in member accounts as well as AWS root user account.
Access Control Lists (ACLs)
ACL defines the control that which principals in another AWS account can access the resource. ACLs cannot be used to control the access of a principal in a different AWS account. It is the only policy type which does not have the JSON policy document format.
21) What are different types of instances?
Following are the different types of instances:


General Purpose Instance type
General purpose instances are the instances mainly used by the companies. There are two types of General Purpose instances: Fixed performance (eg. M3 and M4) and Burstable performance (eg. T2). Some of the sectors use this instance such as Development environments, build servers, code repositories, low traffic websites and web applications, micro-services, etc.

Following are the General Purpose Instances:
T2 instances: T2 instances are the instances that receive CPU credits when they are sitting idle and they use the CPU credits when they are active. These instances do not use the CPU very consistently, but it has the ability to burst to a higher level when required by the workload.
M4 instances: M4 instances are the latest version of General purpose instances. These instances are the best choice for managing memory and network resources. They are mainly used for the applications where demand for the micro-servers is high.
M3 instances: M3 instance is a prior version of M4. M4 instance is mainly used for data processing tasks which require additional memory, caching fleets, running backend servers for SAP and other enterprise applications.
Compute Optimized Instance type
Compute Optimized Instance type consists of two instance types: C4 and C3.
C3 instance: C3 instances are mainly used for those applications which require very high CPU usage. These instances are mainly recommended for those applications that require high computing power as these instances offer high performing processors.
C4 instance: C4 instance is the next version of C3 instance. C4 instance is mainly used for those applications that require high computing power. It consists of Intel E5-2666 v3 processor and use Hardware virtualization. According to the AWS specifications, C4 instances can run at a speed of 2.9 GHz, and can reach to a clock speed of 3.5 GHz.
GPU Instances
GPU instances consist of G2 instances which are mainly used for gaming applications that require heavy graphics and 3D application data streaming. It consists of a high-performance NVIDIA GPU which is suitable for audio, video, 3D imaging, and graphics streaming kinds of applications. To run the GPU instances, NVIDIA drivers must be installed.
Memory Optimized Instances
Memory Optimized Instances consists of R3 instances which are designed for memory- intensive applications. R3 instance consists of latest Intel Xeon lvy Bridge processor. R3 instance can sustain a memory bandwidth of 63000 MB/sec. R3 instance offers a high- performance databases, In memory analytics, and distributed memory caches.
Storage Optimized Instances
Storage Optimized Instances consist of two types of instances: I2 and D2 instances.
I2 instance: It provides heavy SSD which is required for the sequential read, and write access to a large data sets. It also provides random I/O operations to your applications. It is best suited for the applications such as high-frequency online transaction processing systems, relational databases, NoSQL databases, Cache for in-memory databases, Data warehousing applications and Low latency Ad- Tech serving applications.
D2 instance: D2 instance is a dense storage instance which consists of a high-frequency Intel Xeon E5-2676v3 processors, HDD storage, High disk throughput.
22) What is the default storage class in S3?
The default storage class is Standard Frequently Accessed.

23) What is a snowball?
Snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of aws cloud. If you want to know more about the Snowball, click on the link given below:

Click Here
24) Difference between Stopping and Terminating the instances?
Stopping: You can stop an EC2 instance and stopping an instance means shutting down the instance. Its corresponding EBS volume is still attached to an EC2 instance, so you can restart the instance as well.

Terminating: You can also terminate the EC2 instance and terminating an instance means you are removing the instance from your AWS account. When you terminate an instance, then its corresponding EBS is also removed. Due to this reason, you cannot restart the EC2 instance.

25) How many Elastic IPs can you create?
5 elastic IP addresses that you can create per AWS account per region.

26) What is a Load Balancer?
Load Balancer is a virtual machine that balances your web application load that could be Http or Https traffic that you are getting in. It balances a load of multiple servers so that no web server gets overwhelmed. To know more, click on the link given below:

Click Here
27) What is VPC?
VPC stands for Virtual Private Cloud. It is an isolated area of the AWS cloud where you can launch AWS resources in a virtual network that you define. It provides a complete control on your virtual networking environment such as selection of an IP address, creation of subnets, configuration of route tables and network gateways. To know more about VPC, click on the link given below:

Click Here
28) What is VPC peering connection?
A VPC peering connection is a networking connection that allows you to connect one VPC with another VPC through a direct network route using private IP addresses.
By using VPC peering connection, instances in different VPC can communicate with each other as if they were in the same network.
You can peer VPCs in the same account as well as with the different AWS account
To know more about, click on the link given below: Click Here

29) What are NAT Gateways?
NAT stands for Network Address Translation. It is an aws service that enables to connect an EC2 instance in private subnet to the internet or other AWS services. If you want to know more about NAT Gateways, click on the link shown below:

Click Here
30) How can you control the security to your VPC?
You can control the security to your VPC in two ways:

Security Groups
It acts as a virtual firewall for associated EC2 instances that control both inbound and outbound traffic at the instance level. To know more about Security Groups, click on the link given below: Click Here
Network access control lists (NACL)
It acts as a firewall for associated subnets that control both inbound and outbound traffic at the subnet level. To know more about NACL, click on the link given below: Click Here
31) What are the different database types in RDS?
Following are the different database types in RDS:

Amazon Aurora
It is a database engine developed in RDS. Aurora database can run only on AWS infrastructure not like MySQL database which can be installed on any local device. It is a MySQL compatible relational database engine that combines the speed and availability of traditional databases with the open source databases. To know more about Amazon Aurora, click on the link given below: Click Here
Postgre SQL
PostgreSQL is an open source relational database for many developers and startups.
It is easy to set up, operate, and can also scale PostgreSQL deployments in the cloud.
You can also scale PostgreSQL deployments in minutes with cost-efficient.
PostgreSQL database manages time-consuming administrative tasks such as PostgreSQL software installation, storage management, and backups for disaster recovery.
MySQL
It is an open source relational database.
It is easy to set up, operate, and can also scale MySQL deployments in the cloud.
By using Amazon RDS, you can deploy scalable MySQL servers in minutes with cost-efficient.
MariaDB
It is an open source relational database created by the developers of MySQL.
It is easy to set up, operate, and can also scale MariaDB server deployments in the cloud.
By using Amazon RDS, you can deploy scalable MariaDB servers in minutes with cost-efficient.
It frees you from managing administrative tasks such as backups, software patching, monitoring, scaling and replication.
Oracle
It is a relational database developed by Oracle.
It is easy to set up, operate, and can also scale Oracle database deployments in the cloud.
You can deploy multiple editions of Oracle in minutes with cost-efficient.
It frees you from managing administrative tasks such as backups, software patching, monitoring, scaling and replication.
You can run Oracle under two different licensing models: "License Included" and "Bring Your Own License (BYOL)". In License Included service model, you do need have to purchase the Oracle license separately as it is already licensed by AWS. In this model, pricing starts at $0.04 per hour. If you already have purchased the Oracle license, then you can use the BYOL model to run Oracle databases in Amazon RDS with pricing starts at $0.025 per hour.
SQL Server
SQL Server is a relational database developed by Microsoft.
It is easy to set up, operate, and can also scale SQL Server deployments in the cloud.
You can deploy multiple editions of SQL Server in minutes with cost-efficient.
It frees you from managing administrative tasks such as backups, software patching, monitoring, scaling and replication.
32) What is Redshift?
Redshift is a fast, powerful, scalable and fully managed data warehouse service in the cloud.
It provides ten times faster performance than other data warehouse by using machine learning, massively parallel query execution, and columnar storage on high-performance disk.
You can run petabytes of data in Redshift datawarehouse and exabytes of data in your data lake built on Amazon S3.
To know more about Amazon Redshift, click on the link given below: Click Here

33) What is SNS?
SNS stands for Simple Notification Service. It is a web service that provides highly scalable, cost-effective, and flexible capability to publish messages from an application and sends them to other applications. It is a way of sending messages. If you want to know more about SNS, click on the link given below:

Click Here
34) What are the different types of routing policies in route53?
Following are the different types of routing policies in route53:

Simple Routing Policy
Simple Routing Policy is a simple round-robin policy which is applied to a single resource doing the function for the domain, For example, web server is sending the content to a website where web server is a single resource.
It responds to DNS queries based on the values present in the resource.
Weighted Routing Policy
Weighted Routing Policy allows you to route the traffic to different resources in specified proportions. For example, 75% in one server, and 25% in another server.
Weights can be assigned in the range from 0 to 255.
Weight Routing policy is applied when there are multiple resources accessing the same function. For example, web servers accessing the same website. Each web server will be given a unique weight number.
Weighted Routing Policy associates the multiple resources to a single DNS name.
Latency-based Routing Policy
Latent-based Routing Policy allows Route53 to respond to the DNS query at which data center gives the lowest latency.
Latency-based Routing policy is used when there are multiple resources accessing the same domain. Route53 will identify the resource that provides the fastest response with lowest latency.
Failover Routing Policy
Geolocation Routing Policy
35) What is the maximum size of messages in SQS?
The maximum size of message in SQS IS 256 KB.

36) Differences between Security group and Network access control list?
Security Group	NACL (Network Access Control List)
It supports only allow rules, and by default, all the rules are denied. You cannot deny the rule for establishing a connection.	It supports both allow and deny rules, and by default, all the rules are denied. You need to add the rule which you can either allow or deny it.
It is a stateful means that any changes made in the inbound rule will be automatically reflected in the outbound rule. For example, If you are allowing an incoming port 80, then you also have to add the outbound rule explicitly.	It is a stateless means that any changes made in the inbound rule will not reflect the outbound rule, i.e., you need to add the outbound rule separately. For example, if you add an inbound rule port number 80, then you also have to explicitly add the outbound rule.
It is associated with an EC2 instance.	It is associated with a subnet.
All the rules are evaluated before deciding whether to allow the traffic.	Rules are evaluated in order, starting from the lowest number.
Security Group is applied to an instance only when you specify a security group while launching an instance.	NACL has applied automatically to all the instances which are associated with an instance.
It is the first layer of defense.	It is the second layer of defense.
37) What are the two types of access that you can provide when you are creating users?
There are two types of access:

Console Access
If the user wants to use the Console Access, a user needs to create a password to login in an AWS account.
Programmatic access
If you use the Programmatic access, an IAM user need to make an API calls. An API call can be made by using the AWS CLI. To use the AWS CLI, you need to create an access key ID and secret access key.
38) What is subnet?
When large section of IP address is divided into smaller units is known as subnet.

AWS Interview Questions
A Virtual Private Cloud (VPC) is a virtual network provided to your AWS account. When you create a virtual cloud, you need to specify the IPv4 addresses which is in the form of CIDR block. After creating a VPC, you need to create the subnets in each availability zone. Each subnet has a unique ID. When launching instances in each availability zone, it will protect your applications from the failure of a single location.

39) Differences between Amazon S3 and EC2?
S3

It is a storage service where it can store any amount of data.
It consists of a REST interface and uses secure HMAC-SHA1 authentication keys.
EC2

It is a web service used for hosting an application.
It is a virtual machine which can run either Linux or Windows and can also run the applications such as PHP, Python, Apache or other databases.
40) Can you establish a peering connection to a VPC in a different region?
No, it's not possible to establish a peering connection to a VPC in a different region. It's only possible to establish a peering connection to a VPC in the same region.

41) How many subnets can you have per VPC?
You can have 200 subnets per VPC.

42) When EC2 officially launched?
EC2 was officially launched in 2006.

43) What is Amazon Elasticache?
An Amazon Elasticache is a web service allows you to easily deploy, operate, and scale an in-memory cache in the cloud. To know more about the Amazon Elasticache, click on the link given below:

Click Here
44) What are the types of AMI provided by AWS?
There are two types of AMI provided by AWS:

Instance store backed
An instance-store backed is an EC2 instance whose root device resides on the virtual machine's hard drive.
When you create an instance, then AMI is copied to the instance.
Since "instance store-backed" instances root device is stored in the virtual machine's hard drive, so you cannot stop the instance. You can only terminate the instance, and if you do so, the instance will be deleted and cannot be recovered.
If the virtual machine's hard drive fails, then you can lose your data.
You need to leave this instance-store instance in a running state until you are completely done with it.
You will be charged from the moment when your instance is started until your instance is terminated.
EBS backed
An "EBS backed" instance is an EC2 instance that uses EBS volume as a root device
EBS volumes are not tied to a virtual hardware, but they are restricted to an availability zone. This means that EBS volume is moved from one machine to another machine within the same availability zone.
If the virtual machine's fails, then the virtual machine can be moved to another virtual machine.
The main advantage of "EBS backed" over "instance store-backed" instances is that it can be stopped. When an instance is in a stopped state, then EBS volume can be stored for a later use. The virtual machine is used for some other instance. In stopped state, you are not charged for the EBS storage.
45) What is Amazon EMR?
An Amazon EMR stands for Amazon Elastic MapReduce. It is a web service used to process the large amounts of data in a cost-effective manner. The central component of an Amazon EMR is a cluster. Each cluster is a collection of EC2 instances and an instance in a cluster is known as node. Each node has a specified role attached to it known as a node type, and an Amazon EMR installs the software components on node type.


Following are the node types:

AWS Interview Questions
Master node
A master node runs the software components to distribute the tasks among other nodes in a cluster. It tracks the status of all the tasks and monitors the health of a cluster.
Core node
A core node runs the software components to process the tasks and stores the data in Hadoop Distributed File System (HDFS). Multi-node clusters will have at least one core node.
Task node
A task node with software components processes the task but does not store the data in HDFS. Task nodes are optional.
46) How to connect EBS volume to multiple instances?
You cannot connect the EBS volume to multiple instances. But, you can connect multiple EBS volumes to a single instance.

47) What is the use of lifecycle hooks in Autoscaling?
Lifecycle hooks perform custom actions by pausing instances when Autoscaling group launches or terminates an instance. When instance is paused, an instance moves in a wait state. By default, an instance remains in a wait state for 1 hour. For example, when you launch a new instance, lifecycle hooks pauses an instance. When you pause an instance, you can install a software on it or make sure that an instance is completely ready to receive the traffic.

48) What is Amazon Kinesis Firehose?
An Amazon Kinesis Firehose is a web service used to deliver real-time streaming data to destinations such as Amazon Simple Storage Service, Amazon Redshift, etc. To know more about Amazon Kinesis Firehose, click on the link given below:

Click Here
49) What is the use of Amazon Transfer Acceleration Service?
An Amazon Transfer Acceleration Service is a service that enables fast and secure transfer of data between your client and S3 bucket. To know more about Amazon Transfer Acceleration Service, click on the link given below:

Click Here
50) How will you access the data on EBS in AWS?
EBS stands for Elastic Block Store. It is a virtual disk in a cloud that creates the storage volume and attach it to the EC2 instances. It can run the databases as well as can store the files. All the files that it store can be mounted as a file system which can be accessed directly. To know more about EBS, click on the link given below:

Click Here
51) Differences between horizontal scaling and vertical scaling?
Vertical scaling means scaling the compute power such as CPU, RAM to your existing machine while horizontal scaling means adding more machines to your server or database. Horizontal scaling means increasing the number of nodes, and distributing the tasks among different nodes.



https://intellipaat.com/blog/interview-question/amazon-aws-interview-questions/
Top Answers to AWS Interview Questions
Amazon AWS comes under the top 15 certifications that individuals enroll in. It is also among the most popular and high-paying IT jobs in the world. Most professionals are also looking to upskill themselves in this field since major companies have either already transferred their data to the cloud or they are on the verge of doing so. In this blog on Amazon AWS Interview Questions and answers, our aim is to cover all the significant interview questions that are generally asked in the field of the cloud, Amazon AWS, and other related technologies:

Q1. What is AWS?
Q2. Give the comparison between AWS and OpenStack.
Q3. What is the importance of buffer in Amazon Web Services?
Q4. How are Spot Instance, On-demand Instance, and Reserved Instance different from one another?
Q5. Why do we make subnets?
Q6. Is there a way to upload a file that is greater than 100 megabytes in Amazon S3?
Q7. What is the maximum number of S3 buckets you can create?
Q8. How can you save the data on root volume on an EBS-backed machine?
Q9. When should you use the classic load balancer and the application load balancer?
Q10. How many total VPCs per account/region and subnets per VPC can you have?

We have categorized the Top Amazon AWS cloud interview questions into the following three parts:
1. Basic

2. Intermediate

3. Advanced

4. AWS Scenario Based Questions

Watch this video on AWS Interview Questions for Beginners:
Ã—


AWS Basic Interview Questions
1. What is AWS?
AWS (Amazon Web Services) is a platform to provide secure cloud services, database storage, offerings to compute power, content delivery, and other services to help business level and develop.

Take up the AWS Masters Certification Course by Intellipaat and upgrade your skillset.

2. Give the comparison between AWS and OpenStack.
Criteria	AWS	OpenStack
License	Amazon proprietary	Open-source
Operating system	Provided as per the cloud administrator	AMIs provided by AWS
Performing repeatable operations	Through templates	Through text files
3. What is the importance of buffer in Amazon Web Services?
An Elastic Load Balancer ensures that the incoming traffic is distributed optimally across various AWS instances. A buffer will synchronize different components and makes the arrangement additionally elastic to a burst of load or traffic. The components are prone to work in an unstable way of receiving and processing requests. The buffer creates an equilibrium linking various apparatus and crafts them to work at an identical rate to supply more rapid services.

4. How are Spot Instance, On-demand Instance, and Reserved Instance different from one another?
Both Spot Instance and On-demand Instance are models for pricing.

Spot Instance	On-demand Instance
With Spot Instance, customers can purchase compute capacity with no upfront commitment at all.	With On-demand Instance, users can launch instances at any time based on the demand.
Spot Instances are spare Amazon instances that you can bid for.	On-demand Instances are suitable for the high-availability needs of applications.
When the bidding price exceeds the spot price, the instance is automatically launched, and the spot price fluctuates based on supply and demand for instances.	On-demand Instances are launched by users only with the pay-as-you-go model.
When the bidding price is less than the spot price, the instance is immediately taken away by Amazon.	On-demand Instances will remain persistent without any automatic termination from Amazon.
Spot Instances are charged on an hourly basis.	On-demand Instances are charged on a per-second basis
5. Why do we make subnets?
Creating subnets means dividing a large network into smaller ones. These subnets can be created for several reasons. For example, creating and using subnets can help reduce congestion by making sure that the traffic destined for a subnet stays in that subnet. This helps in efficiently routing the traffic coming to the network that reduces the networkâ€™s load.

Learn more about AWS from this AWS Training in New York to get ahead in your career!

6. Is there a way to upload a file that is greater than 100 megabytes in Amazon S3?
Yes, it is possible by using the multipart upload utility from AWS. With the multipart upload utility, larger files can be uploaded in multiple parts that are uploaded independently. You can also decrease upload time by uploading these parts in parallel. After the upload is done, the parts will be merged into a single object or file to create the original file from which the parts were created.

To learn more about the Amazon S3 bucket, read the blog.
7. What is the maximum number of S3 buckets you can create?
The maximum number of S3 buckets that can be created is 100.

Get 100% Hike!

Master Most in Demand Skills Now !

Email Address

+91  IN          INDIA
Phone Number
8. How can you save the data on root volume on an EBS-backed machine?
We can save the data by overriding the terminate option

9. When should you use the classic load balancer and the application load balancer?
The classic load balancer is used for simple load balancing of traffic across multiple EC2 instances.

Classic Load Balancer
While, the application load balancing is used for more intelligent load balancing, based on the multi-tier architecture or container-based architecture of the application. Application load balancing is mostly used when there is a need to route traffic to multiple services.

Classic Load Balancer
Want to learn about AWS DevOps! Check out our blog on What is AWS DevOps.
10. How many total VPCs per account/region and subnets per VPC can you have?
We can have a total of 5 VPCs for every account/region and 200 subnets for every VPC that you have.

11. Your organization has decided to have all their workload on the public cloud. But, due to certain security concerns, your organization decides to distribute some of the workload on private servers. You are asked to suggest a cloud architecture for your organization. What will be your suggestion?
A hybrid cloud. The hybrid cloud architecture is where an organization can use the public cloud for shared resources and the private cloud for its confidential workloads.

Career Transition

12. Which one of the storage solutions offered by AWS would you use if you need extremely low pricing and data archiving?
AWS Glacier is an extremely low-cost storage service offered by Amazon that is used for data archiving and backup purposes. The longer you store data in Glacier, the lesser it will cost you.

Go through the AWS Course in London to get a clear understanding of AWS!

13. You have connected four instances to ELB. To automatically terminate your unhealthy instances and replace them with new ones, which functionality would you use?
Auto-scaling groups

14. The data on the root volumes of store-backed and EBS-backed instances get deleted by default when they are terminated. If you want to prevent that from happening, which instance would you use?
EBS-backed instances. EBS-backed instances use EBS volume as their root volume. EBS volume consists of virtual drives that can be easily backed up and duplicated by snapshots.

EBS Backed Instances
The biggest advantage of EBS-backed volumes is that the data can be configured to be stored for later retrieval even if the virtual machine or the instances are shut down.

15. How will you configure an Amazon S3 bucket to serve static assets for your public web application?
By configuring the bucket policy to provide public read access to all objects

That is all we have in our section on basic Amazon Web Services interview questions section. Letâ€™s move onto the next section on AWS interview questions for experienced professionals.

Intermediate AWS Interview Questions
16. Your organization wants to send and receive compliance emails to its clients using its own email address and domain. What service would you suggest for achieving the same in an easy and cost-effective way?
Amazon Simple Email Service (Amazon SES), which is a cloud-based email sending service, can be used for this purpose.

17. Can you launch Amazon Elastic Compute Cloud (EC2) instances with predetermined private IP addresses? If yes, then with which Amazon service it is possible?
Yes. It is possible by using VPC (Virtual Private Cloud).

Looking for a Perfect Job Interview Attire? Worry Not. Read our perfect guide on Interview Outfits to land your dream job.

18. If you launched a standby RDS, will it be launched in the same availability zone as your primary?
No, standby instances are automatically launched in different availability zones than the primary, making them physically independent infrastructures. This is because the whole purpose of standby instances is to prevent infrastructure failure. So, in case the primary goes down, the standby instance will help recover all of the data.

19. What is the name of Amazon's Content Delivery Network ?
Amazon CloudFront

20. Which Amazon solution will you use if you want to accelerate moving petabytes of data in and out of AWS, using storage devices that are designed to be secure for data transfer?
Amazon Snowball. AWS Snowball is the data transport solution for large amounts of data that need to be moved into and out of AWS using physical storage devices.

Courses you may like

IIT RoorkeeCloud Architect MasterAWS Master
21. If you are running your DB instance as Multi-AZ deployment, can you use standby DB instances along with your primary DB instance?
No, the standby DB instance cannot be used along with the primary DB instances since the standby DB instances are supposed to be used only if the primary instance goes down.

Interested in learning AWS? Enroll in our AWS Training in Sydney!

22. Your organization is developing a new multi-tier web application in AWS. Being a fairly new and small organization, thereâ€™s limited staff. But, the organization requires high availability. This new application comprises complex queries and table joins. Which Amazon service will be the best solution for your organizationâ€™s requirements?
DynamoDB will be the right choice here since it is designed to be highly scalable, more than RDS or any other relational database service.

23. You accidently stopped an EC2 instance in a VPC with an associated Elastic IP. If you start the instance again, what will be the result?
Elastic IP will be only disassociated from the instance if itâ€™s terminated. If itâ€™s stopped and started, there wonâ€™t be any change to instance and no data will be lost.

24. Your organization has around 50 IAM users. Now, it wants to introduce a new policy that will affect the access permissions of an IAM user. How can it implement this without having to apply the policy at the individual user level?
It is possible using AWS IAM groups, by adding users in the groups as per their roles and by simply applying the policy to the groups.

Get certified from the top AWS Course in Singapore now!

Advanced AWS Interview Questions
25. Your organization is using DynamoDB for its application. This application collects data from its users every 10 minutes and stores it in DynamoDB. Then every day, after a particular time interval, the data (respective to each user) is extracted from DynamoDB and sent to S3. Then, the application visualizes this data to the users. You are asked to propose a solution to help optimize the backend of the application for latency at lower cost. What would you recommend?
ElastiCache. Amazon ElastiCache is a caching solution offered by Amazon.

Elastic Cache
It can be used to store a cached version of the application in a region closer to users so that when requests are made by the users the cached version of the application can respond, and hence latency will be reduced.

Become a master of AWS by going through this online AWS Course in Toronto!

26. I created a web application with autoscaling. I observed that the traffic on my application is the highest on Wednesdays and Fridays between 9 AM and 7 PM. What would be the best solution for me to handle the scaling?
Configure a policy in autoscaling to scale as per the predictable traffic patterns.

27. How would you handle a situation where the relational database engine crashes often whenever the traffic to your RDS instances increases, given that the replica of RDS instance is not promoted as the master instance?
A bigger RDS instance type needs to be opted for handling large amounts of traffic, creating manual or automated snapshots to recover data in case the RDS instance goes down.

Learn more about Amazon Web Services from our AWS Tutorial!

28. You have an application running on your Amazon EC2 instance. You want to reduce the load on your instance as soon as the CPU utilization reaches 100 percent. How will you do that?
It can be done by creating an autoscaling group to deploy more instances when the CPU utilization exceeds 100 percent and distributing traffic among instances by creating a load balancer and registering the Amazon EC2 instances with it.

Watch this video on Free AWS Full Course:


29. What would I have to do if I want to access Amazon Simple Storage buckets and use the information for access audits?
AWS CloudTrail can be used in this case as it is designed for logging and tracking API calls, and it has also been made available for storage solutions.

Learn the complete concepts of AWS at Hyderabad in 26 hours!

30. I created a key in North Virginia region to encrypt my data in Oregon region. I also added three users to the key and an external AWS account. Then, to encrypt an object in S3, when I tried to use the same key, it was not listed. Where did I go wrong?
The data and the key should be in the same region. That is, the data that has to be encrypted should be in the same region as the one in which the key was created. In this case, the data is in Oregon region, whereas the key is created in North Virginia region.

31. Suppose, you hosted an application on AWS that lets the users render images and do some general computing. Which of the below listed services can you use to route the incoming user traffic?
Classic Load Balancer
Application Load Balancer
Network Load balancer
Application Load Balancer: It supports path-based routing of the traffic and hence helps in enhancing the performance of the application structured as smaller services.

Application Load Balancer
Using application load balancer, the traffic can be routed based on the requests made. In this case scenario, the traffic where requests are made for rendering images can be directed to the servers only deployed for rendering images and the traffic where the requests are made for computing can be directed to the servers deployed only for general computing purposes.

32. Suppose, I created a subnet and launched an EC2 instance in the subnet with default settings. Which of the following options will be ready to use on the EC2 instance as soon as it is launched?
Elastic IP
Private IP
Public IP
Internet Gateway
Private IP. Private IP is automatically assigned to the instance as soon as it is launched. While elastic IP has to be set manually, Public IP needs an Internet Gateway which again has to be created since itâ€™s a new VPC.

Certification in Cloud & Devops

33. Your organization has four instances for production and another four for testing. You are asked to set up a group of IAM users that can only access the four production instances and not the other four testing instances. How will you achieve this?
We can achieve this by defining tags on the test and production instances and then adding a condition to the IAM policy that allows access to specific tags.

34. Your organization wants to monitor the read and write IOPS for its AWS MySQL RDS instance and then send real-time alerts to its internal operations team. Which service offered by Amazon can help your organization achieve this scenario?
Amazon CloudWatch would help us achieve this. Since Amazon CloudWatch is a monitoring tool offered by Amazon, itâ€™s the right service to use in the above-mentioned scenario.

35. Which of the following services can be used if you want to capture client connection information from your load balancer at a particular time interval?
Enabling access logs on your load balancer
Enabling CloudTrail for your load balancer
Enabling CloudWatch metrics for your load balancer
Enabling CloudTrail for your load balancer. AWS CloudTrail is an inexpensive log monitoring solution provided by Amazon. It can provide logging information for load balancers or any other AWS resources. The provided information can further be used for analysis.

Learn more about AWS CloudWatch in the blog by Intellipaat.

36. You have created a VPC with private and public subnets. In what kind of subnet would you launch the database servers?
Database servers should be ideally launched in private subnets. Private subnets are ideal for the backend services and databases of all applications since they are not meant to be accessed by the users of the applications, and private subnets are not routable from the Internet.

37. Is it possible to switch from an Instance-backed root volume to an EBS-backed root volume at any time?
No, it is not possible.

38. Can you change the instance type of the instances that are running in your application tier and are also using autoscaling? If yes, then how? (Choose one of the following)
Yes, by modifying autoscaling launch configuration
Yes, by modifying autoscaling tags configuration
Yes, by modifying autoscaling policy configuration
No, it cannot be changed
Yes, the instance type of such instances can be changed by modifying the autoscaling launch configuration. The tags configuration is used to add metadata to the instances.

Do you know about the different types of AWS Certifications? Read the Blog to find out.

39. Can you name the additional network interface that can be created and attached to your Amazon EC2 instance launched in your VPC?
Elastic Network Interface

40. Out of the following options, where does the user specify the maximum number of instances with the autoscaling commands?
Autoscaling policy configuration
Autoscaling group
Autoscaling tags configuration
Autoscaling launch configuration
Autoscaling launch configuration

41. Which service provided by AWS can you use to transfer objects from your data center, when you are using Amazon CloudFront?
Amazon Direct Connect. It is an AWS networking service that acts as an alternative to using the Internet to connect customers in on-premise sites with AWS.

42. You have deployed multiple EC2 instances across multiple availability zones to run your website. You have also deployed a Multi-AZ RDS MySQL Extra Large DB Instance. The site performs a high number of small read and write operations per second. After some time, you observed that there is read contention on RDS MySQL. What would be your approach to resolve the contention and optimize your website?
We can deploy ElastiCache in-memory cache running in every availability zone. This will help in creating a cached version of the website for faster access in each availability zone. We can also add an RDS MySQL read replica in each availability zone that can help in efficient and better performance for read operations. So, there will not be any increased workload on the RDS MySQL instance, hence resolving the contention issue.

43. Your company wants you to propose a solution so that the companyâ€™s data center can be connected to Amazon cloud network. What would be your proposal?
The data center can be connected to the Amazon cloud network by establishing a virtual private network (VPN) between the VPC and the data center. A virtual private network lets you establish a secure pathway or tunnel from your premise or device to AWS global network.

Are you interested in learning AWS from experts? Enroll in our AWS Course in Bangalore and be a master of it!

44. Which of the following Amazon Services would you choose if you want complex querying capabilities but not a whole data warehouse?
RDS
Redshift
ElastiCache
DynamoDB
Amazon RDS

45. You want to modify the security group rules while it is being used by multiple EC2 instances. Will you be able to do that? If yes, will the new rules be implemented on all previously running EC2 instances that were using that security group?
Yes, the security group that is being used by multiple EC2 instances can be modified. The changes will be implemented immediately and be applied to all the previously running EC2 instances without restarting the instances.

Become a Cloud and DevOps Architect

46. Which one of the following is a structured data store that supports indexing and data queries to both EC2 and S3?
DynamoDB
MySQL
Aurora
SimpleDB
SimpleDB

47. Which service offered by Amazon will you choose if you want to collect and process e-commerce data for near real-time analysis? (Choose any two)
DynamoDB
Redshift
Aurora
SimpleDB
DynamoDB. DynamoDB is a fully managed NoSQL database service that can be fed any type of unstructured data. Hence, DynamoDB is the aptest choice for collecting data from e-commerce websites. For near-real-time analysis, we can use Amazon Redshift.

48. If in CloudFront the content is not present at an edge location, what will happen when a request is made for that content?
CloudFront will deliver the content directly from the origin server. It will also store the content in the cache of the edge location where the content was missing.

49. Can you change the private IP address of an EC2 instance while it is in running or in a stopped state?
No, it cannot be changed. When an EC2 instance is launched, a private IP address is assigned to that instance at the boot time. This private IP address is attached to the instance for its entire lifetime and can never be changed.

50. Which of the following options will you use if you have to move data over long distances using the Internet, from instances that are spread across countries to your Amazon S3 bucket?
Amazon CloudFront
Amazon Transfer Acceleration
Amazon Snowball
Amazon Glacier
Amazon Transfer Acceleration. It throttles the data transfer up to 300 percent using optimized network paths and Amazon Content Delivery Network. Snowball cannot be used here as this service does not support cross-region data transfer.

Watch this AWS Certification Tutorial for Beginners video:


Youtube subscribe
51. Which of the following services is a data storage system that also has REST API interface and uses secure HMAC-SHA1 authentication keys?
Amazon Elastic Block Store
Amazon Snapshot
Amazon S3
Amazon S3. It gets various requests from applications, and it has to identify which requests are to be allowed and which are to be denied. Amazon S3 REST API uses a custom HTTP scheme based on a keyed HMAC for authentication of requests.

52. What is EC2?
Launched in 2006, EC2 is a virtual machine that you can use to deploy your own servers in the cloud, giving you OS-level control. It helps you have control over the hardware and updates, similar to the case of on-premise servers. EC2 can run on either of these operating systems- Microsoft and Linux. It can also support applications like Python, PHP, Apache, and more.

Learn more about AWS Secrets Manager in the blog by Intellipaat.

53. What is Snowball?
Snowball is an application designed for transferring terabytes of data into and outside of the AWS cloud. It uses secured physical storage to transfer the data. Snowball is considered as a petabyte-scale data transport solution that helps in cost and time-saving.

54. What is CloudWatch?
The Amazon CloudWatch is used for monitoring and managing data and getting actionable insights for AWS, on-premise applications, etc. It helps you to monitor your entire task stack that includes the applications, infrastructure, and services. Apart from this, CloudWatch also assists you in optimizing your resource utilization and cost by providing analytics-driven insights.

55. What is Elastic Transcoder?
In the AWS cloud, the Elastic Transcoder is used for converting media files into versions that can be run/played on devices such as Tablets, PCs, Smartphones, etc. It consists of advanced transcoding features with conversion rates starting from $ 0.0075 per minute.

Learn more about Amazon systems manager in the blog by intellipaat.

56. What do you understand by VPC?
VPC is the abbreviated form of Virtual Private Cloud. It allows you to launch AWS resources that can be defined by you and fully customize the network configurations. Through VPC, you can define and take full control of your virtual network environment. For example- you can have a private address range, internet gateways, subnets, etc.

57. What does an AMI include?
AMI stands for Amazon Machine Images. It includes the following:

Single or multiple Amazon Elastic Block Store (Amazon EBS) snapshots. Basically, templates for the root volume of the instance.
Launch permissions that let AWS accounts use AMI to launch instances.
A block device mapping to specify what volumes to be attached to the instance during its launch.
58. What are the Storage Classes available in Amazon S3?
The following storage classes are available in Amazon S3:

S3 Standard- It is by and large the default storage class. In cases where no specification about the storage class is provided while uploading the object, Amazon S3 assigns the S3 Standard storage class by default.
Reduced Redundancy- It is assigned when non-critical, reproducible data needs to be stored. The Reduced Redundancy Storage class is designed in a way that the above data categories can be stored with less redundancy. 
However, it is always advisable to go ahead with the S3 Standard storage class.

59. What are the native AWS security logging capabilities?
The native AWS security logging capabilities include AWS CloudTrail, AWS Config, AWS detailed billing reports, Amazon S3 access logs, Elastic load balancing Access logs, Amazon CloudFront access logs, Amazon VPC Flow logs, etc. To know about native AWS security logging capabilities in detail, click here.

60. What are key pairs?
When connecting to an Amazon EC2 instance, you need to prove your identity. Key pairs are used to execute this. Basically, a  key pair is a set of security credentials that are used during identity proof. It consists of a public key and a private key.

61. What are policies and what are the different types of policies?
Policies define the permissions required to execute an operation irrespective of the method used to perform it. AWS supports six types of policies:

Identity-based policies
Resource-based policies
Permissions boundaries
Organizations SCPs
ACLs
Session policies
1- Identity-based policies- They are JSON permissions policy documents that control what actions an identity can perform, under what conditions, and on which resources. These policies are further classified into 2 categories:

Managed Policiesâ€“ These policies are standalone identity-based policies that can be attached to different users, groups in your AWS environment.
Inline policies- These policies are directly attached to a single user, group, or role. In situations where inline policies are used, a strict one-to-one relationship between a policy and an identity is maintained. 
2- Resource-based policies- These policies are the ones attached to a resource such as an Amazon S3 bucket. They define which actions can be performed on the particular resource and under what circumstances.

3- IAM permissions boundaries- They actually refer to the maximum level of permissions that identity-based policies can grant to the specific entity.

4- Service Control Policies (SCPs)- SCPs are the maximum level of permissions for an organization or organizational unit. 

5- Access Control lists- They define and control which principals in another AWS account can access the particular resource.

6- Session policies- They are advanced policies that are passed as a parameter when a temporary session is programmatically created for a role or federated user.

62. What kind of IP address can you use for your customer gateway (CGW) address?
We can use the Internet routable IP address, which is a public IP address of your NAT device.

If you have any doubts or queries related to AWS, get them clarified from AWS experts on our AWS Community!

63. Which of the following is not an option in security groups?
List of users
Ports
IP addresses
List of protocols
List of users
List of Users

Hope these top AWS Interview questions and answers for freshers and the experienced, helps you in preparing for top AWS jobs in the Cloud market.

AWS Scenario Based Questions
64. A Company has a running Web Application Server in the N. Virginia region and the server has a large size EBS volume of approximately 500 GB, and to see the demand of business, the company needs to migrate the server from the current region to another AWS accountâ€™s Mumbai location. Which is the best way to migrate the server from the current location to the Mumbai region? And what information AWS administrator does require about AWS A/C?
Create an AMI of the server running in the North Virginia region. Once the AMI is created, The administrator would need the 12 digit account number of the #2 AWS account. This is required for copying the AMI which we have created.

Once the AMI is successfully copied into the Mumbai region, you can launch the instance using copied AMI in the Mumbai region. Once the instance is running and if itâ€™s completely operational, the server in the North Virginia region could be terminated. This is the best way to migrate a server to a different account without any hassle.


65. Unable to ping Instance We launched a Windows 2019 IIS server in the Ohio region and deployed a dynamic website in this server, in addition, the webserver also connected with a backend MS-SQL server to store and access data related to the application. Our users were able to access the website over the Internet. The next day our client informed us that they were able to access the website, but werenâ€™t able to ping the server from the Internet. To ensure ICMP rule in Security Group, we checked, and the Security Group had allowed rule from 0.0.0.0/0. Would you try to help troubleshoot the issue?
If the client is able to access the website from his/her end, it means the connection is perfect and no issue with connectivity and the Security Group configuration also seems correct.

We can check the internal firewall of the Windows 2019 IIS server. If it is blocking ICMP traffic, we should enable it.

66. A start-up company has a web application based in the us-east-1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company's user base grows in the us-west-1 region, the company needs a solution with low latency and improved high availability. What should a solutions architect do to achieve it.?
You need to notice here, currently, the web application is in us-ease-1, and the user base grows in the us-east-1 region. The very first step, provision multiple EC2 instances (web application servers) and configure an Application Load Balancer in us-west-1. Now, create Global Accelerator in AWS Global Accelerator which uses an endpoint group that includes the load balancer endpoints in both Regions.

Read this blog about AWS services to know more.

67. A company currently operates a web application backed by an Amazon RDS MySQL database. It has automated backups that are run daily and are not encrypted. A security audit requires future backups to be encrypted and unencrypted backups to be destroyed. The company will make at least one encrypted backup before destroying the old backups. What should be done to enable encryption for future backups?
Create a snapshot of the database.
Copy it to an encrypted snapshot.
Restore the database from the encrypted snapshot.
68. A company is going to launch one branch in the UK and need to continue with its existing main branch in the USA. The company has almost 15 GB of data which is stored in an S3 Bucket in the Ohio region and data is stored with the default storage class. The Company also wants to provide its updated & stored data in the London S3 bucket using one zone accessibility storage class to save storage costs. In addition, the company also wants that the data must be updated automatically in S3â€™s London bucket; if any data is modified or written in the S3 bucket in Ohio.
Configure Cross Region Replication Rule in Ohio region bucket and select destination bucket in the London region to replicate the data and store it in destination using one zone IA storage class to save cost.

69. You are an AWS Architect in your company, and you are asked to create a new VPC in the N.Virginia Region with two Public and two Private subnets using the following CIDR blocks:
VPC CIDR = 10.10.10.0/24

Public Subnet

Subnet01 : 10.10.10.0/26
Subnet02 : 10.10.10.64/26

Private Subnet

Subnet03: 10.10.10.128/26
Subnet04: 10.10.10.192/26

Using the above CIDRs you created a new VPC, and you launched EC2 instances in all subnets as per the need.

Now, you are facing an issue in private instances that you are unable to update operating systems from the internet. So, what architectural changes and configurations will you suggest to resolve the issue?

NAT G/W to be installed in one public subnet and will configure the route-table associated with private subnets to add NAT G/W entry to provide internet access to private instances.

70. The data on the root volumes of store-backed and EBS-backed instances get deleted by default when they are terminated. If you want to prevent that from happening, which instance would you use? And ensure if the EC2 instance is restarted, the data or configuration in the EC2 instance should not be lost.
EBS-backed instances or instances with EBS Volume. EBS-backed instances use EBS volume as their root volume. These volumes contain Operating Systems, Applications, and Data. We can create Snapshots from these volumes or AMI from Snapshots.

The main advantage of EBS-backed volume is that the data can be configured to be stored for later retrieval even if the virtual machine or the instances are shut down.

71. You have an application running on an EC2 instance. You need to reduce the load on your instance as soon as the CPU utilization reaches 80 percent. How will you accomplish the job?
It can be done by creating an autoscaling group to deploy more instances when the CPU utilization of the EC2 instance exceeds 80 percent and distributing traffic among instances by creating an application load balancer and registering EC2 instances as target instances.

Watch this Video on AWS Training



Youtube subscribe
72. In AWS, three different storage services are available, such as EFS, S3, and EBS. When should I use Amazon EFS vs. Amazon S3 vs. Amazon Elastic Block Store (EBS)?
Amazon Web Services (AWS) offers cloud storage services to support a wide range of storage workloads.

Amazon EFS is a file storage service for use with Amazon compute (EC2, containers, serverless) and on-premises servers. Amazon EFS provides a file system interface, file system access semantics (such as strong consistency and file locking), and concurrently accessible storage for up to thousands of Amazon EC2 instances.

Amazon EBS is a block-level storage service for use with Amazon EC2. Amazon EBS can deliver performance for workloads that require the lowest latency access to data from a single EC2 instance.

Amazon S3 is an object storage service. Amazon S3 makes data available through an Internet API that can be accessed anywhere

73. A company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID). What should a solutions architect do to meet these requirements?
Create an Application Load Balancer with AWS Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.

74. An application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database. When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database. What should the solutions architect do to separate the read requests from the write requests?
Create a read replica and modify the application to use the appropriate endpoint.

75. A client reports that they wanted to see an audit log of any changes made to AWS resources in their account. What can the client do to achieve this?
Enable AWS CloudTrail logs to be delivered to an Amazon S3 bucket

76. Usually, you have noticed that one EBS volume can be connected with one EC2 instance, our company wants to run a business-critical application on multiple instances in a single region and need to store all instances output in single storage within the VPC. Instead of using EFS, our company is recommending the use of multi-attach volume with instances. As an architect, you need to suggest them what instance type and EBS volumes they should use.
The instance type should be EC2 Nitro-based instances and Provisioned IOPs io1 multi-attach EBS volumes.

77. A company is using a VPC peering connection option to connect its multiple VPCs in a single region to allow for cross VPC communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site-to-site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts and VPNs. Which networking solution would you recommend to resolve it?
Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.

78. An organization has multiple facilities in various continents such as North America, Europe, and the Asia Pacific. The organization is designing a new distributed application to manage and optimize its global supply chain and its manufacturing process. It needs to design the process in such a way that the booked order in one continent should be able to support data failover with a short Recovery Time Objective (RTO). The uptime of the application should not impact manufacturing, what kind of solution would you recommend as a solution architect?
Use Amazon DynamoDB global tables feature for the database

https://mindmajix.com/aws-interview-questions

Amazon Web Services (AWS) is known as the cloud computing platform widely used by a range of enterprises across the globe. AWS services consist of more than 200+ features to meet the multiple requirements of users on the cloud applications. It has many functionalities, including Machine Learning and Artificial Intelligence. Customers prefer AWS services because of their secure, flexible and faster environment. Additionally, AWS services help users reduce costs and let applications and systems be more agile.

Before we start Amazon Web Services interview questions, let's have a look at a few crazy facts about Amazon Web Services:

AWS is the most significant market player among cloud providers with 47.8% of the IaaS public cloud services market share.
The average monthly salary of an AWS Solution Architect is the USA  $155,005 and â‚¹ 20,50,000 /year in India.
AWS Certification is regarded as one of the highest-paid certification categories in the USA.
The above points clearly show that the professionals who are capable of handling AWS applications are having high demand and employment opportunities in the market.

| Want to become a Certified AWS Solution Architect?  Visit here to learn AWS Certification Training

We have categorized AWS Interview Questions - 2022 (Updated) into 4 levels they are:

For Freshers
Experienced
Advanced Level
FAQs
aws interview questions

Top AWS Interview Questions and Answers
Below are the Frequently Asked Questions:

Does Amazon support region base services on all services? 
What is EBS in AWS?
How many AWS services are there in 2022?
Which AWS region is the cheapest?
What is the maximum size of an S3 bucket?
What are the most popular AWS services?
Is AWS RDS free?
What is the difference between EBS and S3?
Is Amazon S3 a global service?
What are the benefits of AWS?
AWS Interview Questions - For Freshers
1. What is Cloud Computing?
Cloud computing provides access to IT resources such as computing power, applications, and storage to users as per their demands. Here, users do not need to maintain their physical resources on their premises. In cloud computing, you can pay only for the resources you have used, so there are no investment costs. This service provides greater flexibility and scaling on resources according to your changing workloads.

| Explore Cloud Computing Platform here

2. What are the featured services of AWS?
The Key Components of AWS are:  

Elastic compute cloud( EC2): It acts as an on-demand computing resource for hosting applications. EC2 is very helpful in times of uncertain workloads. 
Route 53: Itâ€™s a DNS web service.
Simple Storage Device S3: It is a widely used storage device service in AWS Identity and Access Management.
Elastic Block Store: It allows you to store constant volumes of data which is integrated with EC2 and enables you to data persist. 
Cloud watch: It allows you to watch the critical areas of the AWS with which you can even set a reminder for troubleshooting.
Simple Email Service: It allows you to send emails with the help of regular SMTP or by using a restful API call.
| Explore AWS Tutorial here

3. What are the top product categories of AWS?
The top product categories of AWS are:

Compute
Storage
Database
Networking and Content Delivery
Analytics
Machine Learning
Security
Identity
Compliance
4. What is a Data lake?
It is a centralized data repository to store all your structured and unstructured data at any volume. The core aspect of Data lake is that you can apply various analytical tools to data, derive analytics, and uncover useful insights without structuring the data. Also, Data lake stores data coming from various sources such as business applications, mobile applications, and IoT devices.

 

 MindMajix YouTube Channel

5. What is Serverless Computing? 
AWS offers a serverless computing facility to run codes and manage data and applications without managing servers. Serverless computing eliminates infrastructure management tasks like capacity provisioning, patching, etc. It reduces the operating costs significantly. As this technology scales in response to the demands for resources automatically, it ensures quick service to users.

6. What is Amazon EC2? 
Amazon EC2 is known as Amazon Elastic Cloud Computing Platform. It provides a robust computing platform to handle any workload with the latest processors, storage, Operating Systems, and networking capabilities. It simplifies the computing process for developers. And this service reduces time by allowing quick scaling as per the requirements.


7. What is Amazon EC2 Auto Scaling?
This AWS service automatically adds or removes EC2 instances as per the changing demands in workloads. Also, this service detects the unhealthy EC2 instances in the cloud infrastructure and replaces them with new instances, consequently. In this service, scaling is achieved in dynamic scaling and Predictive scaling. They can be used separately as well as together to manage the workloads. 

8. What is fleet management in Amazon EC2 Auto Scaling?
Amazon EC2 auto-scaling service continuously monitors the health of Amazon EC2 instances and other applications. When EC2 auto-scaling identifies unhealthy instances, it automatically replaces the unhealthy EC2 instances with new EC2 instances. Also, this service ensures the seamless running of applications and balances EC2 instances across the zones in the cloud.

| Explore AWS Big Data here

9. What is Amazon S3?
Amazon S3 is known as Amazon Simple Storage Service, which allows storing any volume of data and retrieving data at any time. It reduces costs significantly, eliminating the requirement for investments. Amazon S3 offers effective scalability, data availability, data protection, and performance. Using this service, you can uncover insights from the stored data by analyzing it with various analytical tools such as Big Data analytics, Machine Learning, and Artificial Intelligence.

10. What is Amazon CloudFront?
Amazon CloudFront is known as the Content Delivery Network (CDN) service. This service provides high security and performance and is a developer-friendly tool. Amazon CloudFront uses a global network with 310+ Points of Presence (PoPs) across the globe, which helps to reduce latency effectively. And this service uses automated mapping and intelligent routing mechanisms to reduce latency. Amazon CloudFront secures data by applying traffic encryption and controlling access to data.

11. What is Amazon VPC?
Amazon VPC is known as Amazon Virtual Private Cloud (VPC), allowing you to control your virtual private cloud. Using this service, you can design your VPC right from resource placement and connectivity to security. And you can add Amazon EC2 instances and Amazon Relational Database Service (RDS) instances according to your needs. Also, you can define the communication between other VPCs, regions, and availability zones in the cloud.

VPC peering connection

12. What is Amazon SQS?
Amazon Simple Queuing Service (SQS) is a fully managed message queuing service. Using this service, you can send, receive and store any quantity of messages between the applications. This service helps to reduce complexity and eliminate administrative overhead. In addition to that, it provides high protection to messages through the encryption method and delivers them to destinations without losing any message.

13. What are the two types of queues in SQS?
There are two types of queues known

Standard Queues: It is a default queue type. It provides an unlimited number of transactions per second and at least one message delivery option. 

FIFO Queues: FIFO queues are designed to ensure that the order of messages is received and sent is strictly preserved as in the exact order that they sent.

14. What is Amazon DynamoDB?
Amazon DynamoDB is a fully managed, serverless, key-value No SQL database service. This service has many essential features such as built-in security, in-memory caching, continuous back-ups, data export tools, and automated multi-region replication. Mainly, you can run high-performance applications at any scale using this service. For instance, it extensively supports internet-scale applications that require high concurrency and connections for many users with millions of requests per second.

| Explore AWS SQS Tutorial here

15. What is Amazon S3 Glacier?
It is a storage class built for data archiving, which helps retrieve data with high flexibility and performance. So, data can be accessed faster in milliseconds, and S3 Glacier offers a low-cost service. There are three S3 glacier storage classes â€“ Glacier instant retrieval storage, S3 Glacier flexible retrieval, and S3 Glacier deep archive.

16. What is Amazon Redshift?
Amazon Redshift helps analyze data stored in data warehouses, databases, and data lakes using Machine Learning (ML) and AWS-designed hardware. It uses SQL to analyze structured and semi-structured data to yield the best performance from the analysis. This service automatically creates, trains, and deploys Machine Learning models to create predictive insights.

| Explore Redshift Tutorial here

17.  What are Elastic Load Balancing (ELB) and its types?
Elastic Load Balancing (ELB) automatically directs incoming application traffic to various destinations and virtual appliances. In fact, the destinations and virtual appliances may be in one or more availability zones. In this service, you can secure your applications using tools such as integrated certificate management, SSL/TLS decryption methods, and user authentication.

There are three types of load balancers such as Application Load Balancer, Gateway Load Balancer, and Network Load Balancer.

18. What are sticky sessions in ELB?
A sticky session is also known as session affinity. During sticky sessions, load balancers connect a user's session with a specific target. So, all the user's requests during that session will be directed to the same target. It will provide a continuous experience to users. Here, the cookie AWSELB is used to define the sticky session duration to the instance.

19. What is AWS Elastic Beanstalk?
This AWS service helps deploy and manage applications in the cloud quickly and easily. Here, developers need to upload the codes; after that, Elastic Beanstalk will manage other requirements automatically. Simply put, Elastic Beanstalk manages right from capacity provisioning, auto-scaling, load balancing up to application health monitoring.

20. What are the benefits of AWS Elastic Beanstalk?
In a way, it is faster and simpler to deploy applications

The auto-scaling facility of Elastic Beanstalk supports to scale applications up and down based on the demands.

This AWS service manages application platforms by updating with the latest patches and updates.

When they use this service, developers could achieve enough freedom to choose the type of EC2 instance, processors, etc.
 

Benefits of the Elastic beanstalk

Following are the few benefits of the Elastic Beanstalk:

Easy and simple: Elastic Beanstalk enables you to manage and deploy the application easily and quickly.

Autoscaling: Beanstalk scales up or down automatically when your application traffic increases or decreases.

Developer productivity: Developers can easily deploy the application without any knowledge, but they need to maintain the application securely and be user-friendly.

Cost-effective: No charge for Beanstalk. Charges are applied for the AWS service resources which you are using for your application.

Customization: Elastic Beanstalk allows users to select the configurations of AWS services that users want to use for application development.

Management and updates: It updates the application automatically when it changes the platform. Platform updates and infrastructure management are taken care of by AWS professionals.
21. What is Amazon CloudWatch?
Amazon CloudWatch is a monitoring service that would help IT professionals, extensively by providing actionable insights. The tool provides complete visibility on AWS resources and applications running on AWS and on-premises. In addition, it tracks the status of applications, which would help to apply suitable response actions and optimize the performance of applications.

22.  What is AWS Snowball?
AWS Snowball is an edge computing and storage service. There are two features available in this service: Snowball edge storage optimized devices and Snowball edge computes optimized devices. The snowball storage devices offer block storage and Amazon S3 object storage. Snowball edge computing devices provide 52 vCPUs and an optional GPU, and it is suitable for handling advanced Machine Learning and full-motion video analysis.  

Classic Load Balancer: Classic load balancer is designed to make routing decisions either at the application layer or transport layer. It requires a fixed relationship between the container instance port and the load balancer port.

23. What is AWS CloudTrail?
This AWS service monitors user activities on AWS infrastructure and records their activities. And this service identifies suspicious activities on AWS resources through CloudTrail insights and Amazon EventBridge features. So, you can get reasonable control over your resources and response activities. In addition to that, it analyses the log files with Amazon Athena. 

24. What is Amazon ElastiCache?
It is an in-memory caching service. It acts as a data store that can be used as a database, cache, message broker, and queue. This caching service accelerates the performance of applications and databases. For instance, you can access data in microseconds using this caching service. Not only that, it helps to reduce the load on the backend database.

25.  What is AWS Lambda?
It is a serverless and event-driven computing service. It allows running codes virtually for applications without any provisioning or managing servers. Most AWS services and SaaS applications can trigger AWS Lambda. This service can execute any code volume due to its scaling properties. Also, decoupled services can be communicated through the event-driven functions of AWS Lambda.

26.  What is Amazon Lightsail?
Amazon Lightsail is a service that helps to build and manage websites and applications faster and with ease. It provides easy-to-use virtual private server instances, storage, and databases cost-effectively. Not just that, you can create and delete development sandboxes using this service, which will help to test new ideas without taking any risk.

27. What is Amazon ECS?
It is known as Amazon Elastic Container Registry (ECR). It provides high-performance hosting so that you can store your application images securely in ECR. Amazon ECS compresses and encrypts images and controls access to images. The images can be simply stored in containers; also, they can be accessed from the containers without the support of any management tools.

28. What is Amazon EFS?
Amazon EFS is a simple and serverless Elastic File System. It allows adding or removing files on the file system without provisioning and management. This service creates file systems using EC2 launch instance wizard, EFS Console, CLI, and API. You can reduce costs significantly since accessed files will be moved automatically over a period.

29. What is the AWS Snow Family?
AWS Snow family allows transferring data in and out of the cloud using physical devices very simply. It doesnâ€™t require the need for networks. AWS Snow Family helps transfer a large volume of data such as cloud migration, data center relocation, disaster recovery, and remote data collection projects. With the help of this service, many AWS services can be used to analyze, archive, and file data.

30. What is AWS Elastic Disaster Recovery?
This AWS service reduces application downtime on a greater scale by quickly recovering applications both on-premises and on the cloud if there is an application failure. It needs minimal computing power and storage and achieves point-in-time recovery. It helps recover applications within a few minutes in the same state when they failed. Mainly, it reduces recovery costs considerably, unlike the typical recovery methods.

31. What is Amazon Aurora, and mention its features?
Amazon Aurora is the MySQL and PostgreSQL relational database. It performs similar-like traditional databases and has simplicity and cost-effectiveness of open source databases. Amazon Aurora is fully managed by Amazon RDS and automates the processes, such as hardware provisioning, database setup, back-ups, and patching. Also, it has a self-healing storage system that can scale up to 128 TB per database instance.

32. What is Amazon RDS?
Amazon RDS is known as Relational Database Service that allows easy setup, operation, and scaling of relational databases in the cloud. And it automates administrative tasks such as provisioning, database setup, and back-ups. Amazon RDS offers six familiar database engines, such as Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL server.

33. What is Amazon Neptune?
It is a purpose-built graph database that helps execute queries with easy navigation on datasets. Here, you can use graph query languages to execute queries, which will perform effectively on connected datasets. Moreover, Amazon Neptuneâ€™s graph database engine can store billions of relationships and query the graph with milliseconds latency. This service is mainly used in fraud detection, knowledge graphs, and network security.

34. What is Amazon Route 53?
It is the highly scalable Cloud Domain Name System (DNS) web service. It connects users to AWS infrastructures such as Amazon EC2 instances, Elastic load balancing, and Amazon S3 buckets. It connects users outside of AWS infrastructure as well. Using this service, you can configure DNS health checks and monitor applications continuously for their ability to recover from failures. Amazon Route 53 can work alongside Amazon IAM, thereby controlling the access to DNS data.

35. What is AWS Shield?
AWS Shield is the service that protects against DDoS (Distributed Denial of Service) attacks on AWS applications. There are two types of AWS Shields: AWS Shield Standard and AWS Shield Advanced. AWS Shield Standard supports to protect applications from common and frequently occurring DDoS attacks. At the same time, AWS Shield advanced offers higher level protection for the applications running on Amazon EC2, ELB, Amazon CloudFront, AWS Global Accelerator, and Route 53.

36. What is Amazon Network Firewall?
This AWS service helps to protect VPCs (Virtual Private Cloud) against attacks. In this service, scaling is carried out automatically as per the traffic flow in the network. You can define your firewall rules using Network Firewall's flexible rules engine; therefore, you can get reasonable control over the network traffic. Network Firewall can work alongside AWS firewall manager to build and apply security policies on all VPCs and accounts.

37. What is Amazon EBS?
It is known as Amazon Elastic Block Store, and it is a high-performance block storage service. And it is designed to support Amazon EC2 instances. Amazon EBS could scale quicker with respect to the workload demands of high-level applications such as SAP, Oracle, and Microsoft products. Using this service, you can resize the clusters by attaching and detaching storage volumes; therefore, it can be analyzed by big data analytics engines such as Hadoop and Spark.

38. What is Amazon Sagemaker? 
It is a managed AWS service, which builds, trains, and deploys Machine Learning models. It consists of the needed infrastructure, tools, and workflow to support any use case. You could manage a large volume of structured as well as unstructured data using this service; as a result, you can build ML models quickly.

Visit here to learn AWS Training in Hyderabad

39.  What is Amazon EMR? 
Amazon EMR is nothing but it is a cloud Big Data platform. This AWS service helps run large-scale distributed data processing tasks, Machine Learning applications, and interactive SQL queries. Also, you can run and scale big data workloads using open-source frameworks such as Apache Spark, Hive, and Presto. Amazon EMR uncovers hidden patterns, correlations, and market trends through large-scale data processing.

40. What is Amazon Kinesis?  
This AWS service collects, processes, and analyses real-time streaming data and generates useful insights. Here, the real-time data will be video, audio, application logs, IoT telemetry data, and website clickstreams. And you can take the right actions at the right time based on these insights. Especially, data is processed and analyzed once received rather than waiting for the arrival of the whole data.

41. What are the Snow family members? 
AWS Snowcone
AWS Snowball
AWS Snowmobile
 
42.  What are the attacks that AWS Shield can prevent?
AWS Shield protects websites from the following DDoS attacks

UDP floods
TCP SYN floods
HTTP GET and POST floods
43. What do you mean by AMI? 
AMI is nothing but Amazon Machine Images. It provides the necessary information to launch an instance. Please note that a single AMI can launch multiple instances with the same configuration, whereas different AMIs are required to launch instances with different configurations.

| Explore tutorial of What is AWS AMI here

Amazon Web Services Interview Questions - For Experienced
44. What are the security practices followed in Amazon EC2? 
Accounts are managed by two-factor authentication based on Amazon IAM
User requests must be signed with access key ID along with secret access key
Data security is ensured by setting up API and user activity logging with AWS CloudTrail.
Customers are supposed to use transport-layer security 1.0 or later
They have to use cipher suites with Perfect Forward Secrecy (PFS)
45. What is Amazon EC2 root device volume? 
The root device volume contains the image that will be used to boot an EC2 instance. It happens while Amazon AMI launches a new EC2 instance. And this root device volume is backed by either EBS or instance store. Generally, the root device data on Amazon EBS is independent of the lifetime of an EC2 instance.

46. Define regions and availability zones in Amazon EC2?  
Availability zones are the locations that are isolated distinctively. Therefore, failure in a particular zone wouldnâ€™t affect the EC2 instances in other zones. As far as regions are considered, they may have one or more availability zones. This setup helps to reduce latency and costs as well.

47. What are the various types of Amazon EC2 instances and their essential features?
1. General Purpose Instances: They are used to compute various workloads and help to balance computing, memory, and networking resources.

2. Compute Optimised Instances: They are suitable for compute-bound applications. They support computing batch processing workloads, high-performance web servers, machine learning inference, and many more.

3. Memory Optimised: They process the workloads that handle large datasets in memory with quick delivery.

4. Accelerated Computing: It helps execute floating-point number calculations, data pattern matching, and graphics processing. It uses hardware accelerators to perform these functions.

5. Storage Optimised: They handle the workloads that demand sequential read and write access to large data sets on local storage.

 

48. What are Throughput Optimised HDD and Cold HDD volume types?
Throughput optimized HDDs are magnetic type storage that defines performance based on throughput. It is suitable for frequently accessed, large and sequential workloads.

Cold HDD volumes are also magnetic-type storages where performance is calculated based on throughput. These storages are inexpensive and best suitable for infrequent sequential and large cold workloads.

49. What are the benefits of EC2 Autoscaling?  
It detects unhealthy EC2 instances in the cloud infrastructure and replaces them with new instances.

It ensures whether applications have the right amount of computing power and provisions capacity based on predictive scaling.

It provisions instances only when demanded, thereby optimizing cost and performance.
 
Visit here to learn AWS Training in New York

50. Explain the advantages of auto-scaling? 
With the help of automation capabilities, Amazon EC2 auto-scaling predicts the demands of EC2 instances in advance. Here, the Machine Learning (ML) algorithms identify the variations in the demand patterns in regular intervals. It helps to add or remove EC2 instances in the cloud infrastructure proactively, which in turn increases the productivity of applications and reduces cost significantly.

51. What are the uses of load balancers in Amazon Lightsail?
Load balancers automatically route the web traffic to instances so that traffic variations will be managed effectively. As a result, seamless use of applications is ensured in this service.
Using round-robin algorithms, it directs the web traffic only to healthy instances.
Amazon Lightsail supports both HTTP and HTTPS connections
It also makes integrated certificate management to provide free SSL/TLS certificates.
52. What do you mean by the Amazon Lightsail instance plan?
As per this plan, account holders will be provided with a Virtual Private Server, RAMs, CPUs, SSD-based storage, along with data transfer allowance. It also provides five static IP addresses and three domain zones of DNS management per account. This plan helps save costs significantly since customers need to pay on-demand.

53. What are DNS records in Amazon Lightsail?
Generally, DNS is a globally distributed service that supports connecting computers using IP addresses. DNS records in Amazon LightSail convert the human-readable domain names into public IP addresses of LightSail instances. When you type domain names in browsers, Amazon Lightsail translates the domain names into IP addresses of the instances you want to access.

54. What is AWS Copilot CLI?
AWS Copilot CLI is known as â€˜Copilot Command-Line Interfaceâ€™, which helps users deploy and manage containerized applications. Here, each step in the deployment lifecycle is automated; the steps include pushing to a registry, creating a task definition, and clustering. Therefore, it saves time for planning the necessary infrastructure to run applications.

Learn AWS Training in Delhi  

55. What are the differences between Amazon Beanstalk and Amazon ECS?
Amazon Beanstalk deploys and scales web applications and services efficiently. Also, it carries out tasks such as provisioning of various features, deployment, and health monitoring of applications by reducing the burden of developers. Whereas Amazon ECS is a container management service that helps quickly deploy, manage, and scale containerized applications. And it also helps to achieve fine-grained control over the applications.

56. What do you mean by the AWS Lambda function?
AWS Lambda function is nothing but a code that we run on the AWS Lambda. Here, the code is uploaded as a lambda function. This Lambda will have configuration information such as name, description, entry point, and resource requirements. Basically, Lambda functions are stateless, and they include libraries also.

57. Mention the differences between AWS Lambda and Amazon ECS?
AWS Lambda is a serverless and event-driven computing service that helps run codes without provisioning or managing servers. At the same time, Amazon manages servers, unlike Amazon Lambda.

AWS Lambda can support selective languages; on the other hand, ECS can support any language to run codes on containers.

AWS Lambda will be helpful to run easy and quick functions, whereas ECS can be used to run any size of codes and complexity

In AWS Lambda scaling can be carried out automatically; on the other hand, ECS container service requires managing servers and infrastructure according to the demands.
      
58. How does AWS Lambda achieve integrated security control? 
AWS Lambda integrates with AWS IAM so that other AWS services can access Lambda functions securely. By default, AWS Lambda runs codes in Amazon VPC. So, AWS Lambda functions can be accessed only within VPC, securely. Also, you can configure a secured AWS Lambda resource access, by which you can leverage custom security groups and network access control lists. 

59. What platform branches support the graviton instances on AWS Elastic Beanstalk?
Docker running on 64-bit Amazon Linux 2
Node.js 14 running on 64-bit Amazon Linux 2
Node.js 12 running on 64-bit Amazon Linux 2
Python 3.8 running on 64-bit Amazon Linux 2
Python 3.7 running on 64-bit Amazon Linux 2
 
60. What is the use of the ELB gateway load balancer endpoint?
ELB gateway load balancer endpoints make private connectivity between the virtual appliances in the Virtual Private Cloud (VPC) and the application servers in the service consumer VPC.

61. What are the different storage classes of Amazon S3?
S3 Intelligent -Tiering
S3 Standard
S3 Standard-infrequent access (S3 Standard â€“ A)
S3 One Zone-infrequent access (S3 One Zone â€“IA)
S3 Glacier instant retrieval
S3 Glacier flexible retrieval
S3 Glacier deep archive
S3 Outposts
62. What is EFS Intelligent -Tiering? 
With the support of EFS lifecycle management, Amazon Elastic File System (EFS) monitors the access patterns in workloads. According to lifecycle policy, the inaccessed files are identified from performance-optimized storage classes and then moved to infrequent access cost-optimized storage classes saving costs significantly. If suppose, the access patterns change, and the inaccessed files are reaccessed, then EFS lifecycle management moves back the files to the performance-optimized storage classes again.
  

63. What do you mean by Amazon EBS snapshots?
Amazon Elastic Block Store (EBS) snapshots are the point-in-time copy of data, which can be used for enabling disaster recovery, data migration, and backup compliance. This data protection system protects block storage such as EBS volumes, boot volumes, and on-premises block data.  

64.  Mention the difference between Backup and Disaster Recovery
Back up is the process of copying data locally or in a remote location. The data can be accessed whenever it is needed. For instance, if a file is damaged or lost, it can be accessed from backups.

Disaster recovery helps regain applications, data, and other resources if there is an outage. It is the process of moving to the redundant servers and storage systems until the source applications and data are recovered. Simply put, it helps to continue business processes as quickly as possible, even if there is a failover in the IT resources.

65. What is the function of DynamoDB Accelerator?
The fully managed in-memory cache improves data accessing performance up to 10 times higher than usual. Also, it allows to access data within microseconds and manages millions of requests per second; and it helps to lower the operational costs.  

66. How does Amazon ElastiCache function?
It is the fully managed and in-memory cache that supports real-time use cases. It functions as a fast in-memory data store and acts as a database, cache, message broker, and queue. Moreover, this service will support real-time transactions, Business Intelligence tools, session stores, and gaming leaderboards.

67. What is the connection between Amazon Neptune and RDS permissions?
Amazon Neptune is a high-performance graph database engine. Amazon Neptune connects with technologies shared with Amazon RDS while managing instance lifecycle management, encryption-at-rest with Amazon KMS keys, and security group management.

Learn AWS Online Training in Bangalore

68.  How does Amazon CloudFront speed up content delivery?
Speed in content delivery is achieved with the support of a global network infrastructure that consists of 300+ Points of Presence (PoPs). This global network optimizes content delivery through edge termination and WebSockets. Above all, content delivery is performed within milliseconds with built-in data compression, edge compute capabilities, and field-level encryption.

69.  What do you mean by the latency-based routing feature of Amazon Route 53?
This feature supports improving your applicationâ€™s performance globally. Amazon Route 53 uses edge locations across the world, by which it routes end users to Amazon regions efficiently. In addition, you can run applications on various Amazon regions and Amazon route 53, so you can achieve effective routing with low latency.

70.  How does AWS Network Firewall protect a VPC?
AWS Network firewallâ€™s stateful firewall prevents your Virtual Private Cloud (VPC) from unauthorized access via tracking connections and protocol identification. The intrusion prevention program of this service carries out active flow inspection to identify and block vulnerability through single-based detection. This service uses web filtering that will prevent known bad URLs.

71.  Mention the difference between Stateful and Stateless Firewalls?
With Stateful Firewalls, you can apply effective policy enforcement using complete network traffic details since it tracks all the aspects of a traffic flow. Stateful firewalls allow integrating encryption, packet states, TCP stages, and many more.
On the other hand, stateless firewalls focus only on the individual data packets with pre-set rules, so it helps filter traffic. Stateless firewalls cannot identify the threats in the traffic apart from the content in the header of packets.

72. Compare: RTO and RPO in AWS?
RPO is the Recovery Point Objective of AWS Elastic Disaster Recovery, usually measured in the sub-second range. RPO indicates how much data loss or time you can afford after a disaster in the service.

On the other hand, RTO is the Recovery Time Objective of AWS Elastic Disaster Recovery, usually measured in minutes. RTO is the recovery time taken by resources to return to their regular operations after a disaster in the service.

73.  What do you mean by Provisioned IOPS, and how is it used?
Provisioned IOPS represents the EBS volume type to deliver high performance for I/O intensive workloads. For example, database applications may leverage provisioned IOPS as they demand consistent and fast response times. Here, the volume size and volume performance will be specified for EBS volumes to provide consistent performance throughout the lifetime of the volume.

74.  Distinguish between storage in EBS and storage in an instance store?
An Instance store is temporary storage. The data stored in an instance store may be lost due to instance stops, terminations, and hardware failures.
On the other hand, data in EBS storage would be kept for longer periods, and data may not be lost due to instance stops and terminations. You can back up this data with EBS Snapshots, attach it with another instance, and make full-volume encryption.


AWS Interview Questions - Advanced Level
75.  Distinguish between Spot Instance, On-demand Instance, and Reserved Instance?
Spot instances are unused EC2 instances that customers can use at discount rates.

We need to pay for the compute capacity without long-term commitments when you use on-demand instances.

On the other hand, you can set attributes such as instance type, platform, tenancy, region, and availability zone using reserved instances. Reserved instances provide discounts significantly and offer capacity reservations when the instances in the specific availability zones are used.

76.  What is the role of EFA in Amazon EC2 interfacing?
Elastic Fabric Advisor (EFA) devices provide a new OS bypass hardware interface that can be interfaced with Amazon EC2 instances in order to boost High-Performance Computing (HPC). EFA also supports Machine Learning (ML) applications. And it provides consistent latency and higher throughput. Especially, it improves inter-instance communication, which is essential in HPC and ML applications.

77.  What do you mean by â€˜changingâ€™ in Amazon EC2?
In order to simplify the limit management experience of customers, Amazon EC2 provides the option to change the instance limits from the current â€˜instance count-based limitsâ€™ to the new â€˜vCPU Based limitsâ€™. So, the usage is measured in terms of the number of vCPUs when launching a combination of instance types based on demands.

78.  What functions in Amazon Autoscaling automate fleet management of Amazon EC2?
Monitors the health of the running EC2 instances in the cloud infrastructure

Replaces malfunctioning EC2 instances with new instances

Balances the capacity across various availability zones
79.  What do you mean by Snapshots in Amazon Lightsail?
Snapshots are the point-in-time backups of EC2 instances, block storage disks, and databases. They can be created at any time, either manually or automatically. Snapshots will restore your resources at any time, right from when they are created. And these resources will function as the original resource where the snapshots are taken.

80.  What is the role of tags in Amazon Lightsail?
Tags will be helpful when there are many resources of the same type. You can group and filter the resources in the Lightsail console or API based on the tags assigned to them.
Tags help to track and allocate costs for various resources and users. Billing can be split based on â€˜projectsâ€™ as well as â€˜usersâ€™ with the help of â€˜cost allocation tagsâ€™
With the help of tags, you can manage your AWS resources by providing access control to users. So, users can manage data on the resources only within their limits.

81.  What are lifecycle hooks in Amazon EC2 Auto Scaling?
Lifecycle hooks help to take proactive actions before instances get terminated. For example, launch hooks allow configuring an instance before it is connected with load balancers by the Amazon Auto Scaling service. This is achieved by connecting Amazon Lambda with launch hooks. Similarly, terminate hooks collect important data from an instance before it gets terminated.

82.  What do you mean by launch configuration in Amazon EC2 Auto Scaling?
It is the template that Amazon EC2 Auto Scaling uses to launch EC2 instances. When you make a launch configuration, you need to specify information such as Amazon Machine Image (AMI), the instance type, security groups, a key pair, and block device mapping. Whenever an EC2 instance is launched, you must specify the launch configuration in detail.

83.  What are the uses of Amazonâ€™s Lightsailâ€™s container services?
It allows running containerized applications in the cloud
Various applications right from web apps to multi-tiered microservices can be run on container services
Container services will be run without bothering the underlying infrastructure since they will be taken care of by Amazon Lightsail.

84.  How does Amazon ECS support Dynamic Port Mapping?
If a dynamic port is specified during ECS task definition, then the container will be given by an unused port. It will occur when the container is scheduled on the EC2 instance. Then, the ECS scheduler will allocate tasks to Application Load Balancerâ€™s target groups through this port automatically.

85.  Why does the AWS Lambda function suppose to be stateless?
When incoming events create a need for scaling, AWS lambda functions have to make many copies of functions to cope with the scaling. At that time, AWS functions have to be stateless; only then AWS lambda functions can create copies of functions. Also, it allows accessing stateful data from Amazon S3 and Amazon dynamoDB.

86.  What do you mean by AWS Lambda Runtime Interface Emulator (RIE)?
AWS Lambda RIE is a lightweight web server. It helps to convert HTTP requests to JSON events. Lambda RIE emulates runtime API and acts as the proxy for the Lambda runtime API. Also, Lambda RIE is open-sourced on runtime GitHub. And it helps to test the lambda functions using Curl and DOCKER CLI tools.

87.  What are S3 Object Lambda and its uses?
S3 Object Lambda allows modifying or processing data before it is returned to applications. The lambda functions can process data by filtering, masking, redacting, compressing, and many more. This is achieved with the support of S3 GET requests. You donâ€™t need to create copies of codes in this feature, and you can run the codes on the infrastructure that is fully managed by AWS S3 and AWS Lambda. 

88.  What do you mean by Amazon EFS Provisioned Throughput?
This feature of Amazon EFS allows the file systemâ€™s throughput to be independent of the amount of data storage. Therefore, file system throughput is matched with the requirements of applications. This feature is mainly applied to applications that require high throughput to storage (MB/second per TB) ratio.

89.  How does EBS manage the storage contention issues?
Amazon EBS is a multi-tenant block storage service. The rate-limiting mechanism helps to resolve storage contention issues. It is achieved by fixing defined performance levels for all types of volumes in terms of IOPS and throughput. Here, metrics are used to track the performance of EBS instances and infrastructure to volumes. Alarms will indicate any deviation from the defined performance levels of instances and volumes from the expected ones. It will help allocate suitable EBS instances and infrastructure to the volumes.

90.  How do Amazon Kinesis data streams function?
Amazon Kinesis captures data from AWS services, microservices, Logs, and mobile apps and sensors, which can be of any quantity. Then, it easily streams the data to AWS Lambda, Amazon kinesis data analytics, and data firehose. And  Amazon kinesis builds data streaming applications using the mentioned AWS services, open-source framework, and custom applications.

91.  How does data transfer occur in AWS Snowcone and AWS storage devices?
Data is collected and processed at the source level after receiving it from sensors and other devices with the AWS Snowcone service. Then, the data is moved into AWS storage devices such as S3 buckets, either online or offline. And you can transfer data continuously to the AWS sources through Data sync options. Moreover, data is processed using Amazon EC2 instances, and then it is moved to AWS storage devices in the AWS Snowcone service.

92.  How are AWS Elastic Disaster Recovery and Cloud Endure Disaster Recovery related?
Generally, AWS Elastic Disaster Recovery is built on Cloud Endure Disaster Recovery; therefore, both services have similar capabilities. They help you to:

Ease the setup, operation, and recovery processes for many applications
Perform non-disruptive disaster recovery testing and drills
Recover RPOs in seconds and TROs in minutes
Recover from a previous point-in-time
93.  How does Amazon VPC work with Amazon RDS?
The Amazon EC2 instances, EC2-VPC and EC2- Classic, can host Amazon DB instances. Amazon VPC can launch Amazon DB instances into a virtual private cloud. It also helps to control the virtual networking environment. On the other hand, Amazon RDS manages backups, software patching, and automatic failure detection and recovery. You can save costs significantly when running your DB instances in an Amazon VPC.

94.  How does Amazon Redshift perform workload isolation and changeability?
The data in the ETL cluster is shared with isolated BI and analytics clusters in order to provide read workload isolation. It also allows making optional charges so that costs can be saved. Here, the analytic clusters can be arranged as per the price requirements. Also, it helps to onboard the new workloads very simply.

95.  How is caching efficiency increased in Amazon ElastiCache?
The in-memory caching provision of Amazon ElastiCache helps to reduce latency and throughput. Especially, high workload applications such as social networking, gaming, and media sharing use in-memory caching to improve data access efficiency. Moreover, critical data pieces can be stored in-memory, which will reduce latency significantly.

96.  Compare Amazon VPC Traffic Mirroring and Amazon VPC Flow Logs?
With Amazon VPC traffic mirroring, you can get actionable insights about network traffic, which will help you analyze the traffic content, payloads, the root cause for issues, and control data misuse.           
On the other hand, Amazon VPC flow logs provide information about traffic acceptance and rejections, source and destination IP addresses, packet, and byte counts, and ports details. It helps to troubleshoot security and connectivity issues to optimize network performance.

97.  Why is Amazon CloudFront considered DevOps friendly?
CloudFront offers fast change propagation and invalidations, for instance, within two minutes.
It provides a full-featured API by which CloudFront distributions can be created, configured, and maintained
You can customize the CloudFront behaviors such as caching, communication, headers and metadata forwarded, compression modes, and many more.
CloudFront can detect device types and forward this information to applications; as a result, content variants and other responses can be easily adapted by the applications.

98.  What is the advantage of the Amazon Route 53 Resolver DNS Firewall over other AWS firewalls?
By providing visibility and control for the entire VPC, Route 53 Resolver DNS firewall ensures the security of applications and networks on AWS. This DNS firewall can be used along with AWS Network Firewall, Amazon VPC security groups, AWS web application firewall rules, and AWS Marketplace appliances to ensure the security of networks and applications.

99.  Mention the difference between Amazon Athena, Amazon Redshift, and Amazon EMR?
Amazon Athena is a query service. It allows running ad-hoc queries for the data in Amazon S3 without the support of servers.
Amazon Redshift is a data warehouse. It provides the fastest query performance for enterprise reporting and BI workloads.
Amazon EMR is the data processing framework. It helps run distributed processing frameworks like Hadoop, Spark, and Presto.

100. What are instance stopping and instance termination?
When you stop an instance, all the operations of the instance are stopped at the moment it is stopped. However, its EBS volume will be connected with the instance so that it can be restarted at any time.
On the other hand, you can no longer use that instance when you terminate an instance. After that, you cannot start or connect that instance as its EBS volume is also removed while terminating the instance.

 

Most Frequently Asked AWS Interview Questions - FAQs
1. Does Amazon support region base services on all services?
No, it is not providing region-specific usage on all its services. But most of the services are region-based. 

2. What is EBS in AWS?
Elastic block storage (EBS) is a storage system that is used to store persistent data. EBS is designed to provide block-level storage volumes and to use EC2 instances for both transactions and throughput-intensive workloads at any scale. 

3. How many regions are available in AWS?
As of September 2021, the AWS Serverless Application repository is available in the AWS GovCloud (US-East) region. With this service, the availability of services is increased to a total of 18 AWS regions across North America, South America, the EU, and the Asia Pacific.

4. Which AWS region is the cheapest?
The US standard is the cheapest region; it is also the most established AWS region. 

5. What is the maximum size of an S3 bucket?
The maximum size of an S3 bucket is 5 TB.

6. What are the most popular AWS Services?
Following are the most popular AWS Services:

Amazon S3
AWS Lambda
Amazon Glacier
Amazon EC2
Amazon SNS
Amazon CloudFront
Amazon EBS
Amazon Kinesis
Amazon VPC
Amazon SQ 
Explore AWS Sample Resumes! Download & Edit, Get Noticed by Top Employers!
7. Is AWS RDS free?
Yes, AWS RDS is a free tier. RDS helps the AWS customers to get started with the management database service in the cloud for free.  

8. What is the difference between EBS and S3?
Difference between EBS and S3

EBS	S3
Highly scalable	Less scalable
It is a block storage	It is an object storage
EBS is faster than S3	S3 is slower than EBS
Users can access EBS only via the given EC2 instance	Anyone can access S3; it is a public instance.
It supports the File system interface	It supports Web interface
9. Is Amazon S3 a global service?
Yes, Amazon S3 is a global service. It provides object storage through the web interface and it uses the Amazon scalable storage infrastructure to run its global e-commerce network.

10. What are the benefits of AWS?
AWS provides services to its users at a low cost. Amazon web services are easy to use and the user should not worry about security, servers, and databases. Amazon web services have several benefits which make users rely on them.  

Conclusion:

No matter how much information you gather to learn a concept, it matters only when you concise it. Here, in this blog, we have tried to concise AWS services into Top 100 AWS questions and answers. Hope that all these questions and answers might have been useful to understand and gain more insights about different AWS services. If you find any related question that is not present here, please share that in the comment section and we will add it at the earliest.

 

AWS Quiz Questions

Warm up your Interview preparation with us. Take a quiz and break the buzz.

1. You plan to design an application by encrypting all the data in an Amazon Redshift cluster. How will you encrypt the data at rest?
 Using the AWS KMS Default Customer master key
 Placing the Redshift cluster in a private subnet
 Encrypting the data using SSL/TLS
 Encrypt the Amazon EBS volumes
2. An organization decides to build an Amazon Redshift cluster to host sensitive data in their shared services VPC. What control does the organization implement for networks accessing the cluster?
 Providing access to networks that connect with share services through VPN.
 Operating cluster in different VPC and join through VPC peering.
 For users on the network, creating a database user inside the Amazon Redshift cluster.
 Defining a cluster security group for the cluster allowing access from the allowed networks.
3. An application saves the logs to an S3 bucket. A user needs to keep the logs for one month for troubleshooting purposes and then clear the logs. What action will enable this?
 Configuring lifecycle configuration rules on the S3 bucket.
 Creating an IAM policy for the S3 bucket.
 Enabling CORS on the S3 bucket.
 Adding a bucket policy on the S3 bucket.
4. A website experiences inconstant traffic, and the database cannot keep up with the write requests during peak traffic times. What AWS Service helps to decouple the web application from the database?
 AWS Lambda
 Amazon S3
 Amazon EFS
 Amazon SQS
5. A solution architect is designing a new web application on AWS. To make the application very popular, the architect focuses on software development and new features without managing or provisioning instances. Which solution is best suited for that?
 AWS Lambda and Amazon CloudFront
 AWS Lambda and Amazon API Gateway
 Amazon EC2 and Amazon API gateway
 Elastic Load Balancing with Amazon EC2 and Auto Scaling groups
SUBMIT



https://www.fita.in/aws-interview-questions-and-answers/
Cloud Computing is going to be the future of IT and many other industries as well. AWS is the most commonly used cloud platform at present. Various companies have adopted AWS to build their infrastructure and store data. Whether you are a Fresher or an experienced professional, equipping yourself with these AWS Interview Questions and Answers will help you guaranteed success in your AWS Interview!

AWS Training at FITA Academy is the right place to learn briefly about AWS and its application professionally.

1. What is AWS?

Amazon Web Services (AWS) is a Comprehensive Cloud platform that offers more than 165 services such as database storage, content delivery, security infrastructure, etc., from data centers worldwide. The robust infrastructure and agility at low costs are important reasons for its adoption from startups to large scale enterprises.

2. What is Cloud Computing?

Cloud computing provides various features of a computer in a comprehensive platform via the internet. Cloud computing offers computing power, database, software, storage, applications, security, etc. at reduced costs and improves performance. With Cloud computing, huge investments in hardware and software are reduced drastically and pay only for the services utilized.

3. What is a Container?

Containers help to package softwareâ€™s code and configuration into an object. Containers utilize the OS installed on the server and ensures stable, consistent and speedy deployment independent of the environment.

AWS Cloud provides the resources to run containers and also offers orchestration services for building and operating applications that are packed in containers.

This is predominantly useful in DevOps based processes supported by AWS.

DevOps training in Chennai at FITA Academy helps the learners to understand the in-depth concepts in DevOps. Interested candidates can also join AWS Training at FITA Academy.

4. What is a Data lake?

Data Lake is a repository to store structured and unstructured data of any scale. They are mainly utilized in Big Data and Data Science since we can store data in its original form without any need to structure the Data and it is possible to perform various analysis to arrive at better solutions.

Big Data Training in Chennai at FITA Academy helps aspirants to excel in their careers with the knowledge acquired from experienced professional tutors.

5. What is the difference between Data Warehouse and Data Lake?

Data Warehouse	Data Lake
Data is relational from transactional systems and operational databases.	Data is both non-relational and relational from various sources such as IoT devices, mobile apps, websites, and social media.
Provides fastest query results at high cost of storage.	Provides faster query results at low storage cost.
Used by Business analysts.	Used by Data scientists, Data developers, and Business analysts.
Helps in Batch reporting, BI and visualizations	Helps to perform various analytics such as Machine Learning, Predictive analytics, data discovery and profiling
6. What are the main components of AWS?

The key components of AWS are:

Simple Email service
Route 53
Simple Storage Device S3
Elastic compute cloud( EC2)
Elastic Block Store
Cloud watch
7. What is S3?

S3 implies the Simple Storage Service. S3 refers to a storage service capable of storing volumes of data from anywhere around the globe. For utilising S3 one can pay only for the usage in the Pay-as-you-go model of payment. AWS Course helps students to clearly understand key components of AWS such as S3.

8. What is the importance of buffer in AWS?

A buffer helps to integrate and synchronize various components in AWS and helps to maintain equilibrium by linking multiple apparatus to deliver quick services at a uniform rate.

9. Explain the various storage classes available in S3?

The various storage classes available in S3 are listed below.

Standard frequency accessed
RRS â€“ reduced redundancy storage
Standard infrequency accessed
One-zone infrequency accessed
Glacier.
AWS Training provides comprehensive knowledge on AWS and its components to make a career in AWS based jobs.

10. What is Snowball?

Snowball is a transporting option available in AWS to transport the data in and out of AWS. Snowball helps to transfer immense data at low networking cost.

AWS Online Training helps you to develop industry-relevant skills to become an AWS Engineer.

11. What are key-pairs?

Key Pairs are used to connect to the virtual machines. The secure login credentials used to connect to virtual machines are known as Key pairs. Key-pairs in AWS is the commonly asked AWS interview question.

12. What are the types of volumes in EBS?

Various types of Volumes in EBS are listed below.

General-purpose
Magnetic
Provisioned IOPS
Cold HDD
Throughput optimized
13. What is the total number of buckets that can be created in AWS by default ?

One Hundred(100) buckets can be created in each AWS account by default. We can also increase the number of buckets by submitting a request form to Amazon.

14. List some important features of a classic load balancer in EC2.

Distributes traffic among various EC2 instances evenly and ensures high scalability for the incoming traffic.

Load balancer decides on routing the traffic by accessing the health of the systems.

Load Balancer can route traffic from a user to the same Virtual Machine for any number of instances for a hasslefree experience.

15. Can we use Amazon Transfer acceleration and Snowball to transfer data across countries?

Amazon Transfer Acceleration can accelerate Data Transfer by 300% with the help of amazon content delivery network and optimised networks. Whereas Snowball is not compatible to support Cross Region data transfer.

16. List various connection issues faced while connecting to an EC2 instance.

Server refusing Key
Connection timeout
unprotected Private Key
Host Key missing
User Key unrecognised
17. What is an AMI?

Amazon Machine Image contains various software configurations, block device mapping for allocating volumes to the virtual machine and launch permissions.

18. What is an EIP?

An elastic IP address is useful for dynamic cloud computing where we can stop and restart the instances multiple times.

19. What is Cloudwatch?

Cloudwatch is helpful to monitor various features of the AWS such as networks, storage, applications, the health of the systems, etc.

20. What are the types in cloudwatch?

Basic- Free service

Detailed â€“ Charged service

21. List the cloudwatch metrics that are available for EC2 instances.

Various Cloudwatch metrics available for EC2 instances are mentioned below.

CPU utilisation
CPU credit usage
CPU credit balance
networkIn
networkOut
Diskreads
Diskwrites
22. What are the different storage classes in S3?

Different types of storage classes in S3 are listed below.

Glacier
One-zone infrequently accessed.
Standard infrequently accessed
Standard frequently accessed
RRS â€“ reduced redundancy storage
22. List various parameters involved in S3 pricing.

The parameters determining the S3 pricing are listed below.

Data transfer
Storage utilised
Transfer acceleration
Storage management
Number of requests
Types of Storage Classes in S3 is the basic question asked in the AWS interview.

24. Methods to encrypt data in S3.

Various methods used to encrypt data in S3 are listed below.

C (Client-Side)
S3 (AES 256 encryption)
KMS (Key Management Service)
25. What is the prerequisite for Cross-region replication in S3?

The source and destination buckets should be in different regions and versioning must be enabled at both the source and destination. We also have a set of Python Interview Questions that are asked frequently to the freshers. You can find those questions on clicking the preceding link.

26. Explain Policies.

Policies refer to permissions attached to the created users to access AWS account.

27. List the Types of Policies

Inline policies
Managed policies
28. What is CloudFront?

Cloudfront refers to an AWS service that can effectively distribute the content of businesses and app developers with low latency at high-speed.

29. What are the Roles?

Roles are users with different accounts who help to permit trustable entities to an AWS account. There is no necessity to create login credentials for Roles to work on the resources.

30. What are the Edge locations?

Edge Location refers to the location where the contents are cached and can be useful when users access the content. If the searched content is unavailable in edge locations, the content will be created from an origin location and a copy of it will be saved in the edge locations.

31. What is archive storage capacity in Glacier?

Individual archives can be stored up to a maximum of 40 TB in Glacier.

32. What is VPC?

Virtual Private Cloud(VPC) helps the users to customise and configure networks easily. VPC permits users to have their internet gateways, Subnets, Nat Gateways and IP address range; isolated from other networks in the cloud.

33. What is a VPC peering connection?

VPC peering connection allows users to connect two or more Virtual Private Clouds and the instances in the connected VPC function coherently.

34. How the security of VPC can be controlled?

Security groups and Network Access Control List (NACL) can be utilised to regulate the security of a Virtual Private Cloud.

35. What are NAT gateways?

Network Address Translation gateways help the instances to be connected to the internet. NAT Gateways serve as a one-way traffic regulator since they prevent any initiation of a connection from the Internet to the instances.

36. What are the different types of storage gateway?

Various types of Storage Gateways are listed below.

Tape gateway
Volume gateway
File gateway
It is the basic interview question that should be known by any fresher before taking the AWS Interview.

37. What is a redshift?

Redshift is a data warehouse product of Amazon that provides fast and powerful services; completely manageable petabyte-scale warehouse.

38. What are the database types in RDS?

The Database types in RDS are listed below:

MYSQL server
Oracle
SQL server
Postgresql
Aurora
MariaDB
39. What are the various Routing Policies in route53?

List of various Routing Policies in route53.

Simple routing
Multivalue answer
Geolocation routing
Latency routing
Weighted routing
Failover routing
40. What is SNS?

Simple Notification Service(SNS) is a web service under AWS that notifies the user of any activity in the cloud that requires attention through mail or messages as desired by the user. Get access to Common  Selenium Interview Questions on clicking the following link.

41. What is multi-AZ RDS?

Multi-AZ RDS is helpful to make a replica of the production database to be available in other availability zones. They come handy in case of disaster recovery and primary database shutdown, to have a complete set of database as a backup.

42. What are the types of backups in the RDS database?

Types of backups in the RDS database.

Automated
Manual (also known as snapshots)
43. Explain the usage of Classic Load Balancer and Application Load Balancer.

Classic Load Balancer is designed for simple load balancing of traffic whereas Application Load Balancer helps in intelligent load balancing of traffic across various EC2 instances.

Application Load Balancer is utilised to route traffic to multiple instances.

44. Is there a way to upload a file greater than 100 MB in Amazon S3?

Larger files can be uploaded using the Multipart Upload Utility in AWS, where the large files are uploaded in parts independently and parallel to decrease the upload time. The parts will be merged and converted into a single file once the upload is completed.

45. What are some of the key best practices for security in Amazon EC2?

Some of the best security practices in Amazon EC2 are listed below:

Securing the AWS account and the access key.
Creating separate Identity and Access Management(IAM) credentials to each user who has access to AWS resources.
Disable unimportant services and applications in EC2 instances.
Grant permissions to perform specified tasks and deny access for irrelevant resources.
Review security infrastructure regularly.
46. Differentiate between vertical and horizontal scaling in AWS.

Vertical Scaling refers to the process of increasing the power and performance of an existing machine by adding up resources to the infrastructure.

Horizontal Scaling refers to the scenario where the power and performance are augmented by adding new machines to the infrastructure.

Vertical Scaling is restricted to handle a limited number of users and Horizontal Scaling comes to the rescue when the users are increasing in large numbers with clustering, load balancing and distributed file system.

47. How will you access the data on EBS in AWS?

Elastic Block Storage provides highly functional block-level storage that can be connected to any EC2 instance and accessed easily.

This question is basically asked to the freshers to test their understanding on Elastic Block Storage in AWS.

48. How can you speed up data transfer in Snowball?

The data transfer can be increased in the following way:

Performing multiple copy operations from different terminals, on the same Snowball device.
Reducing encryption by Transferring large files or batches of small files.
Prioritising activities on the source and snowball machine can improve the speed of data transfer.
49. List the network performance parameters while launching instances in a cluster placement group?

If Instances are launched in a cluster placement group, one can expect the performance parameters to be as mentioned below.

20 Gbps in full-duplex (Multi-flow).
10 Gbps in a single flow.
Outside the group, network traffic will be restricted to 5 Gbps
50. What is the difference between Scalability and Elasticity?

Scalability refers to the ability of a system to increase the hardware requirements or processing nodes to tackle increasing demand.

The elasticity of a system refers to the capability of the system to add resources for improving the performance when required and returning to the original configuration when resources are not required.

This feature helps a lot in cloud computing since the resources are bought in the pay-as-you-go pricing.

51. How to reduce the load on the Amazon EC2 instance?

Attaching a load balancer to an autoscaling group will distribute the load effectively among various instances.

52. Explain the purpose of Connection Draining

Connection Draining will reroute the traffic from non-updated and health check failed instances.

53. What is the purpose of lifecycle hooks in AutoScaling?

Lifecycle hooks help to add wait time before launch or termination of an instance for extraction of log files or installation of necessary software respectively.

AWS Training in Bangalore at FITA Academy helps aspirants to make a wonderful career with the skills and knowledge acquired through FITA Academy.

54. What is Lambda?

Lambda helps to run server-less applications and to deploy various functions that are triggered by events. Lambda cannot be used for developing applications that are accessible publicly.

55. How does Elastic Beanstalk update?

Elastic Beanstalk creates a replica of an instance and routes the traffic to the duplicate instance before updating an instance. In case the update fails, it will roll back to the original instance providing a hassle-free user experience.

56. What is the use of tags?

Tags are helpful to identify and group various AWS resources. AWS Training in Hyderabad at FITA Academy provides the students with the necessary training to understand the concepts of AWS and its application. Tutors at FITA Academy train the students with market-relevant skills and help the students in achieving their professional career.

57. List the advantages of Cloud Computing.

Elasticity
Scalability
Speed and Agility
pay-as-you-use model
Worldwide launch in unnoticeable time
58. What is the Availability Zone?

Availability Zone is also known as Data Centre that is designed as an independent failure zone with high-speed connectivity and low latency.

59. What is Region?

The Region is similar to a geographical location where there are independent collections of AWS resources connected in higher bandwidth.

60. Explain Auto scaling and its components.

Auto Scaling is an important feature that permits to increase or decrease the instances based on CPU or Memory utilisation. the components in Auto Scaling are Launch configuration and Auto-scaling groups.

61. Explain Security Groups.

Security Groups are enhanced security features that hold the traffic of the instances and serve as a firewall. One can frame rules to security groups to permit traffic among various instances for better monitoring of the security infrastructure. Security Groups is the frequently asked question in AWS Interview questions for freshers.

62..Explain Amazon EBS-Optimized instances

Amazon EBS-Optimized Instances utilises an optimized stack configuration and has additional capacity for Amazon EBS that can be selected by paying hourly charges based on usage.

63. Which Automation Gears helps in Spinup Services?

API tools such as API Fortress, Scripting languages like Perl and hybrid cloud management tools like Scarl are few such automation gears helpful for Spin Up Services.

64. Explain Amazon EMR.

Amazon Elastic Map Reduce is an administrative feature that can completely monitor Hadoop system on the Amazon EC2 instance.

65. List the virtualization types in AWS.

Hardware-Assisted Virtualisation
Para Virtualization
66. Explain Stateful and Stateless firewall.

Any security group that regulates traffic among instances and various AWS resources is a Stateful firewall.

A Stateless firewall is an Access Control List on a network at the subnet level and can allow or deny traffic based on rules.

67. What do you know about Amazon Kinesis Firehose?

It is a Data Firehouse that can help in stacking information in Information Stores or devices without the need for a continuous organization.

68. What is Amazon DynamoDB?

DynamoDB is a product of Amazon that provides fast and reliable Database services with increased performance and scalability for storage of humongous data at low costs.

69. What is the association between AMI and Instance?

AMI refers to Amazon Machine Image that acts as a template containing software configurations such as OS, server and applications. AMI can be used to launch an instance that replicates the AMI functioning as a virtual server and can be used to launch multiple instances also.

70. What is the purpose of the cradle in AWS?
Cradle serves the purpose of monitoring the synchronisation of a stack with different parts to maintain a robust framework. Cradle acts as a cushion to make the segments work efficiently enabling administration easier.

71. What are the DB engines which can be used in AWS RDS?

Various DB engines used in AWS RDS are listed below.

MariaDB
MS SQL DB
MYSQL DB
Oracle DB
Postgre DB
Different types of DB Engines that can be used in AWS RDS is also one of the commonly asked AWS interview questions for experienced.

72. Explain the difference between the Service Role and SAML Federated Role.

Service Role is used to specify a task in AWS services on the basis of various policies attached to it.

Federated Roles are useful for providing access to AWS based on the designed Role.

73. How a Root AWS user differs from an IAM User.

Root AWS User is granted complete access to AWS services without any policy attached whereas an IAM User can access based on the policies attached to it.

74. What is the benefit of creating a group in IAM

Group Creation in IAM aids in managing the users with similar kind of policies attached and by changing the policies access to AWS can be easily managed for all the users in the Group.

75. Explain the benefits of the Security Token Service( STS).

STS helps to secure the AWS environment since the credentials are temporary and there is no necessity to revoke or rotate them. Click the following link to Know the Basic Java Interview questions that are asked to freshers in an Interview.

76. What is the distinction between Amazon S3 and EC2?

S3 refers to Simple Storage Service where bulk volumes of data can be stored and retrieved easily along with a REST interface and secure validation keys (HMAC_SHA1).

EC2 refers to Elastic Compute Cloud is utilised for developing applications and run servers and various languages & tools such as Python, Ruby, Apache, Linux, PHP, HTML, etc.

77. Explain Amazon CloudSearch.

Amazon CloudSearch helps to incorporate various seek and fetch abilities on numerous applications. They support AWS ENgineers by reducing the time taken to perform changes or updates on various applications.

78. Explain the AWS Certificate Manager.

AWS Certificate Manager is an administrative feature for various activities using Secure Socket Layers to arrange interchanges and setting up of the character of various sites over the internet.

79. What is an Auto Scaling group?

Auto Scaling group contains various Amazon EC2 instances administered by Auto Scaling Services with each group containing various configuration options to decide launch or termination of instances. These are the most important Interview Questions on AWS.

80. What is SES?

Simple Email Service(SES) is a service provided by Amazon to send bulk Email to customers instantly reducing the cost of the service.

81. What is SQS?

Simple Queue Service (SQS) by Amazon provides quick and reliable message queuing service in which messages are queued temporarily until the user wish to send them to consumers. Basic Amazon Web Services Interview Questions for both freshers and experienced.

82. Explain SNS.

Simple Notification Service is an Amazon web service to coordinate the delivery of messages or emails to the recipients.

This question is put forth to the freshers & experienced in the AWS Interview to test their understanding of AWS.

83. What are the routing policies available in Amazon Route53?

Various Routing Policies in Route53 are listed below.

Simple
Failover
Weighted
Geolocation
Latency Based
84. What is Lightsail?

Amazonâ€™s Lightsail helps to launch and control any virtual Private Server with AWS by providing various facilities like storage, data transfer, static IP, etc.

85. Differentiate Basic and Detailed monitoring.

Basic Monitoring interacts with Amazon Cloud watch at an interval of 5 minutes on a set of predetermined metrics at no cost.

Detailed Monitoring interacts with Amazon Cloud watch round the clock and permits aggregation of data as a charged service.

86. What is IaaS?

IaaS refers to the cloud service that helps in running various services in the cloud platform on a pay-as-you-go basis.

87. Explain Amazon ElastiCache.

Amazon ElastiCache denotes the web service that helps in the management of memory caching environment.

Benefits of ElastiCache are listed below.

Scalable Caching Environment
High Performance
Cost-effectiveness
88. What Is Lambda edge?

Lambda Edge can perform various functions that run as a response to CloudFront events for executing various functions in AWS locations without a managing server.

89. What is PaaS?

PaaS helps to run various cloud platforms predominantly to develop, test and monitor the functioning of the software.

90. List various layers of Cloud Architecture in AWS.

Various layers of AWS Cloud architecture is listed below.

Node Controller
Cloud controller
Cluster controller
Storage Controller
Join AWS Training in Coimbatore at FITA Academy to explore more about AWS.

91. List some important features of Amazon cloud search.

A few important features of Amazon Cloud search are listed below.

Range searches
Prefix Searches
Entire text search
Boolean searches
AutoComplete advice
92. How the instance type of the instances that are running in an application tier along with Auto Scaling can be changed?

auto scaling launch configuration
auto scaling tags configuration
auto scaling policy configuration
None of the above
93. Where does the user specify the maximum number of instances using the auto scaling commands?

Auto scaling tags configuration
Auto Scaling group
Auto Scaling launch configuration
Auto scaling policy configuration
94. Which among the below mentioned is a structured data store that can support indexing and data queries for EC2 and S3?

DynamoDB
Aurora
SimpleDB
MySQL
95. The maximum permissible VPCs per account/region and subnets per VPC in AWS.

4, 100
5, 200
7, 40
3, 150
96. Which among the following should be chosen for complex querying capabilities without whole data warehouse?

RDS
ElastiCache
Redshift
DynamoDB
97. Which among the following should be chosen for collecting and processing e-commerce data with real-time analysis?

DynamoDB
Aurora
Redshift
SimpleDB
98. Which among the following is used to transfer data among instances spread across countries to your Amazon S3 bucket?

Amazon CloudFront
Amazon Transfer Acceleration
Amazon Snowball
Amazon Glacier
This is the Basic AWS interview questions that are asked to the freshers in an interview.

99. Which among the below services is a data storage system that uses secure HMAC-SHA1 authentication keys?

Amazon Elastic Block Store
Amazon S3
Amazon Snapshot
100. Which Value should be set in the instanceâ€™s tenancy attribute for running single-tenant hardware?

One
Dedicated
Reserved
Isolated
101. When costs are incurred in an Elastic IP address?

EIP is allocated.
EIP is allocated and associated with a running instance.
EIP is allocated and associated with a stopped instance.
None of the Above
Join FITA Academy to undergo the best AWS Training in Chennai.

Also, we will update more AWS Interview Questions for both experienced and freshers in this blog in the coming days.  Follow this blog regularly to get more relevant updates of AWS.

https://career.guru99.com/top-15-aws-interview-questions/
1) Explain what AWS is?
AWS stands for Amazon Web Service; it is a collection of remote computing services also known as a cloud computing platform.  This new realm of cloud computing is also known as IaaS or Infrastructure as a Service.

2) Mention what the key components of AWS are?
The key components of AWS are

Route 53: A DNS web service
Simple E-mail Service: It allows sending e-mail using RESTFUL API call or via regular SMTP
Identity and Access Management: It provides enhanced security and identity management for your AWS account
Simple Storage Device or (S3): It is a storage device and the most widely used AWS service
Elastic Compute Cloud (EC2): It provides on-demand computing resources for hosting applications. It is handy in case of unpredictable workloads
Elastic Block Store (EBS): It offers persistent storage volumes that attach to EC2 to allow you to persist data past the lifespan of a single Amazon EC2 instance
CloudWatch: To monitor AWS resources, It allows administrators to view and collect keys. Also, one can set a notification alarm in case of trouble.
ðŸ‘‰ Free PDF Download: AWS Interview Questions & Answers

3) Explain what S3 is?
S3 stands for Simple Storage Service. You can use the S3 interface to store and retrieve any amount of data, at any time and from anywhere on the web.  For S3, the payment model is â€œpay as you go.â€

4) What is AMI?
AMI stands for Amazon Machine Image.  Itâ€™s a template that provides the information (an operating system, an application server, and applications) required to launch an instance, which is a copy of the AMI running as a virtual server in the cloud.  You can launch instances from as many different AMIs as you need.

5) Mention what the relationship between an instance and AMI is?
From a single AMI, you can launch multiple types of instances.  An instance type defines the hardware of the host computer used for your instance. Each instance type provides different computer and memory capabilities.  Once you launch an instance, it looks like a traditional host, and we can interact with it as we would with any computer.

6) What does an AMI include?
An AMI includes the following things






EXPLORE MORE

Top 10 Behavioral Interview Questions and Answers
04:00

Top 10 Interview Do's and Don'ts in a Job Interview
02:11

Top 5 Powerpoint Interview Questions and Answers
02:11

What to bring to a JOB Interview: Interview Tips
01:50

What to wear in interview for Women | Working women
01:44

How To Dress for an Job Interview for Men
01:36

10 Most Common Interview Questions and Answers ðŸ”
03:54

5 Secrets Tips to Win an Interview
01:42
A template for the root volume for the instance
Launch permissions decide which AWS accounts can avail the AMI to launch instances
A block device mapping that determines the volumes to attach to the instance when it is launched
7) How can you send a request to Amazon S3?
Amazon S3 is a REST service, and you can send a request by using the REST API or the AWS SDK wrapper libraries that wrap the underlying Amazon S3 REST API.

8) Mention what the difference between Amazon S3 and EC2 is?
The difference between EC2 and Amazon S3 is that

EC2	S3
It is a cloud web service used for hosting your application	It is a data storage system where any amount of data can be stored
It is like a huge computer machine which can run either Linux or Windows and can handle applications like PHP, Python, Apache, or any databases	It has a REST interface and uses secure HMAC-SHA1 authentication keys
9) How many buckets can you create in AWS by default?
By default, you can create up to 100 buckets in each of your AWS accounts.

10) Explain can you vertically scale an Amazon instance? How?
Yes, you can vertically scale on the Amazon instance. For that

Spin up a new larger instance than the one you are currently running
Pause that instance and detach the root webs volume from the server and discard
Then stop your live instance and detach its root volume
Note the unique device ID and attach that root volume to your new server
And start it again
11) Explain what T2 instances is?
T2 instances are designed to provide moderate baseline performance and the capability to burst to higher performance as required by the workload.

12) In VPC with private and public subnets, database servers should ideally be launched into which subnet?
With private and public subnets in VPC, database servers should ideally launch into private subnets.

13) Mention what the security best practices for Amazon EC2 are?
For secure Amazon EC2 best practices, follow the following steps

Use AWS identity and access management to control access to your AWS resources
Restrict access by allowing only trusted hosts or networks to access ports on your instance
Review the rules in your security groups regularly
Only open up permissions that you require
Disable password-based login, for example, launched from your AMI
14) Explain how the buffer is used in Amazon web services?
The buffer is used to make the system more robust to manage traffic or load by synchronizing different components.  Usually, components receive and process the requests in an unbalanced way. With the help of a buffer, the components will be balanced and will work at the same speed to provide faster services.

15) While connecting to your instance what are the possible connection issues one might face?
The possible connection errors one might encounter while connecting instances are

Connection timed out
User key not recognized by the server
Host key not found, permission denied
An unprotected private key file
Server refused our key or No supported authentication method available
Error using MindTerm on Safari Browser
Error using Mac OS X RDP Client
16) What are key-pairs in AWS?
Key-pairs are secure login information for your virtual machines. To connect to the instances, you can use key-pairs which contain a public-key and private-key.

17)  What are the different types of instances?
Following are the types of instances:

General purpose
Computer Optimized
Memory Optimized
Storage Optimized
Accelerated Computing
18) Is the property of broadcast or multicast supported by Amazon VPC?
No, currently Amazon VPI does not provide support for broadcast or multicast.

19) How many Elastic IPs are allowed to be created by AWS?
5 VPC Elastic IP addresses are allowed for each AWS account.

20) Explain default storage class in S3
The default storage class is a Standard frequently accessed.

21) What are the Roles?
Roles are used to provide permissions to entities which you can trust within your AWS account. Roles are very similar to users. However,  with roles, you do not require to create any username and password to work with the resources.

22) What are the edge locations?
Edge location is the area where the contents will be cached. So, when a user is trying to access any content, the content will automatically be searched in the edge location.

23) What is VPC?
aws-logoVPC stands for Virtual Private Cloud. It allows you to customize your networking configuration. It is a network which is logically isolated from another network in the cloud. It allows you to have your IP address range,  internet gateways, subnet, and security groups.


24) Explain snowball
Snowball is a data transport option. It used source appliances to a large amount of data into and out of AWS. With the help of snowball, you can transfer a massive amount of data from one place to another. It helps you to reduce networking costs.

25) What is a redshift?
Redshift is a big data warehouse product. It is a fast and powerful, fully managed data warehouse service in the cloud.

26) What are the advantages of auto-scaling?
Following are the advantages of autoscaling

Offers fault tolerance
Better availability
Better cost management
27) What is meant by subnet?
A large section of IP Addresses divided into chunks is known as subnets.

28) Can you establish a Peering connection to a VPC in a different region?
Yes, we can establish a peering connection to a VPC in a different region. It is called inter-region VPC peering connection.

29) What is SQS?
Simple Queue Service is also known as SQS. It is distributed queuing service which acts as a mediator for two controllers.

30) How many subnets can you have per VPC?
You can have 200 subnets per VPC.

31) DNS  and Load Balancer service comes under which type of cloud service?
DNS and Load Balancer and DNS services come under IAAS-storage cloud service.

32) What is the role of AWS CloudTrail?
CloudTrail is a specially designed tool for logging and tracking API calls. It helps to audit all S3 bucket accesses.

33) When was EC2 officially launched?
EC2 officially launched in the year 2006.

34) What is SimpleDB?
SimpleDB is a data repository of structure record which encourages data doubts and indexing both S3 and EC2are called SimpleDB.

35) Explain Amazon ElasticCache
Amazon Elasticcache is a web service which makes it easy to deploy, scale and store data in the cloud.

36) What is AWS Lambda?
Lambda is an Amazon compute service which allows you to run code in the  AWS Cloud without managing servers.

37) Name the types of AMI provided by AWS
The types of AMI provided by AWS are:

Instance store backed
EBS backed
38) Name the AWS service that exists only to redundantly cache data and images?
AWS Edge locations are services that redundantly cache data and images.

39) Explain Geo Restriction in CloudFront
A Geo-restriction feature helps you to prevent users of specific geographic locations from accessing content which youâ€™re distributing through a CloudFront web distribution.

40) What is Amazon EMR?
EMR is a survived cluster stage which helps you to interpret the working of data structures before the intimation.  Apache Hadoop and Apache Spark on the Amazon Web Services help you to investigate a large amount of data. You can prepare data for the analytics goals and marketing intellect workloads using Apache Hive and using other relevant open-source designs.

41) What is the boot time taken for the instance stored backed AMI?
The boot time for an Amazon instance store-backend AMI is less than 5 minutes.

42) Do you need an internet gateway to use peering connections?
Yes, the Internet gateway is needed to use VPC (virtual private cloud peering) connections.

43) How to connect EBS volume to multiple instances?
We canâ€™t be able to connect EBS volume to multiple instances.  However, you can connect various EBS Volumes to a single instance.

44) List different types of cloud services
Various types of cloud services are:

Software as a Service (SaaS),
Data as a Service (DaaS)
Platform as a Service (PaaS)
Infrastructure as a Service (IaaS).
45) State the difference between An Instance  and AMI
AMI is a template consisting of software configuration part. For example Operating systems, applications, application servers if you start an instance, a duplicate of the AMI in a row as an attendant in the cloud.

46) What are the different types of Load Balancers in AWS services?
Two types of Load balancers are:

Application Load Balancer
Classic Load Balancer
47) In which situation you will select provisioned IOPS over Standard RDS storage?
You should select provisioned IOPS storage over standard RDS storage if you want to perform batch-related workloads.

48) What are the important features of Amazon cloud search?
Important features of the Amazon cloud are:


Boolean searches
Prefix Searches
Range searches
Entire text search
AutoComplete advice
49) Can vertically scaling is allowed in  Amazon Instance?
Yes, you can vertically estimate one Amazon instance.

50) What is the use of lifecycle hooks in Autoscaling?
Lifecycle hooks are used for autoscaling to put an additional wait time to a scale in or scale out event.

51) What are the various layers of Cloud Architecture explained in AWS training?
Different layers of cloud architecture are:

Cloud controller
Cluster controller
Storage Controller
Node Controller
52) What are the storage class available in Amazon s3?
Storage classes available with Amazon s3 are:

Amazon S3 standard
Amazon S3 standard-infrequent Access
Amazon S3 Reduced Redundancy Storage
Amazon Glacier
53) Name some of the DB engines which can be used in AWS RDS
MS-SQL DB
MariaDB
MYSQL DB
OracleDB
PostgreDB


https://www.softwaretestinghelp.com/aws-interview-questions/

TOP 30 AWS Interview Questions And Answers (LATEST 2022)
Last Updated:August 7, 2022

In this Tutorial, we have provided the Most Frequently Asked AWS (Amazon Web Services) Interview Questions & Answers with Explanation:

In constantly uncertain economic situations prevailing globally, many organizations are considering moving to public cloud computing and storage services offered by Amazon.

In startup software industries, it is essential for the DevOps team, to be familiar with Amazon Web Services (AWS) cloud storage and computing, where companies have to pay only for the computing power and storage that are used per month.


AWS Interview Questions




In case you are trying to move to a more challenging role to handle AWS cloud setup and utilities, we have come up with 30 most frequently asked AWS interview questions and their appropriate answers.

Letâ€™s Explore!!

What You Will Learn: [hide]

Amazon Web Services Overview
Most Frequently Asked AWS Interview Questions
Conclusion
Recommended Reading
Amazon Web Services Overview
AWS offers cloud computing and storage services that comprise of computing power, analytics, content delivery, database storage, deployment to other companies on pay per use basis for the storage and computing on their servers along with maintaining and infrastructures being looked after by Amazon.

Cloud computing offers scalability, technical support during migration and installation of applications, reduces costs and time due to downtime, advanced secured systems for data security, mobile access for the installed applications round the clock, and disaster recovery in case of in power outages or natural disasters.

Most Frequently Asked AWS Interview Questions
Q #1) What is the Amazon Web Service?

Answer: Amazon Web Service (AWS) is a public cloud or a server farm managed and maintained by Amazon. The storage and computing power of these servers are offered on a lease as a managed service for pay per use basis.

Q #2) What is cloud computing?

Answer: Cloud computing is IT resources such as infrastructure, platform, or software as their services are used over the Internet with a pay-per-use basis. Cloud service providers are the companies that have public cloud or data centers who offer services like compute, storage, database, operations, migration, messaging, and analytics services.

The leading cloud service providers are AWS, Microsoft Azure, Google Cloud Platform, IBM Cloud, Rackspace, Verizon Cloud.

Cloud service providers

Q #3) What are the different types of cloud computing?

Answer: There are three main types of cloud computing offered as services by the service providers.

These are as follows:

Infrastructure as a Service (IaaS) provides basic building blocks such as virtual or dedicated hardware in the form of computers, data storage space as well as networking access in the form of IT infrastructure on a pay as per use basis to customers eliminating initial and ongoing expenses after purchasing infrastructure, space, and maintenance, but only to focus on business improvement and improving applications built by these companies.
Platform as a Service (PaaS) offers managing hardware and operating systems for the customers and focusing on deploying their products, eliminating initial and ongoing expenses after purchasing infrastructure, space, and maintenance.
Software as a Service (SaaS) offers complete management of end-user applications along with management of infrastructure supporting these applications, for the companies as their service offerings.
Q #4) What benefits organizations will have in moving to cloud computing?

Answer: Organizations moving their infrastructure and applications to the public cloud will have the following benefits:

Scalability: Cloud allows scale up or down based on usage, you only need to pay per use for the computing and storage perspective.
Reliability: Cloud providers offer the reliability of their infrastructure up to 99.999999%, with provision for multiple levels of redundancy and backups in case it is needed.
Security: Most cloud providers are compliant with industry-level security protocols like HIPAA, PCI, offer access restrictions to applications and systems at multiple levels and monitoring services at a very granular level to trigger alarms.
Cost Efficiency: Moving to the cloud for startup companies offers benefits of cost savings by differing from investing in expensive servers, managing, and maintaining them. Every month, companies have to pay only for the computing power and storage that are utilized by them during the month.
Q #5) What are the main features of Amazon Web Services (AWS)?

Answer: Main features of AWS are listed below:

Data Management and Data Transfer
Compute & Networking
Storage
Automation and Orchestration
Operations and Management
Visualization
Security and Compliance
Q #6) Explain the main components of Amazon Web Services.

Answer: Main components of AWS are described below:

Route 53: It is a highly scalable Domain Name System (DNS) web service. It helps to route end users to Internet applications by masking names like www.portalname.com to its numeric IP address like 192.168.0.1.
Simple Storage Service (S3): It is a highly scalable, fast, inexpensive, and reliable data storage interface from Amazon web services used by many large organizations.
Simple E-mail Service (SES): This is a hosted email service that uses Restful API call or via SMTP, for sending the notification, marketing, and transaction-related messages.
Identity and Access Management (IAM): It is Identity and security management services for AWS account holders. It allows us to create and manage users, user groups thereby allow or deny access to AWS resources.
Elastic Compute Cloud (EC2): It is the central ecosystem of AWS, responsible for on-demand and flexible computing resources. EC2 will help to configure security, networking, and storage and launch virtual servers as per need.
Elastic Block Store (EBS): It offers a continuous storage system, which can be viewed in the instance as a hard drive. EBS helps create storage volumes and attach to Amazon EC2 instances.
CloudWatch: It gathers key metrics and sets a series of alarms to inform users, in case there is trouble. Using CloudWatch, administrators can monitor multiple resources and instances from a single console such as virtual instances in EC2, Databases in RDS, Data stored in S3, Elastic Load Balancer, and Auto Scaling groups.
AWS_components

Q #7) What are the differences between Amazon S3 and EC2?

Answer: Differences between Amazon S3 and EC2 are described in the below table:

Elastic Compute Cloud (Amazon EC2)	Simple Storage Services (Amazon S3)
EC2 is a cloud hosting tool	S3 is a cloud storage tool
EC2 is pay per use web service that deploys applications on Amazon public cloud servers for their compute power.	S3 is a storage with massive capacity to store anything from documents, movies, applications, images, objects (BLOB)
Amazon EC2 allow selection of multiple instances, operating system, software, configuration of memory, CPU, storage and boot partition as well as commissioning of thousands of server instances within minutes if required to scale up or scale down the application load.	Amazon S3 allows storage of objects. Objects are stored in a bucket that can be retrieved by developer-assigned key; This bucket can be stored in one of several regions across the globe.
Q #8) What are the main features of the Amazon EC2 instance?

Answer: Various Amazon EC2 features are described below:

Elastic Compute Cloud (EC2) provides virtual computing environments in the form of a virtual server known as instances, requested in the form of a web server for computing in AWS public cloud.
EC2 allows pre-configured templates, Amazon Machine Images (AMIs) for instances, that allow package information needed like operating system and additional software for configuring your cloud server.
Various instance types like CPU, memory, storage, and networking capabilities can be configured with EC2.
EC2 offers secured login information in key pair form, where AWS stores public key as an identity for customers, whereas customers will save the private key for securely logging in the AWS cloud server.
Instance store volumes for temporary data, which gets deleted when an instance is stopped or terminated.
Persistent storage volume for our data for storage and computing purpose using Elastic Block Store by Amazon known as Amazon EBS volume.
Regions and Availability zones give multiple physical locations for resources such as instances and Amazon EBS volumes.
Protocols, ports, and source IP ranges to reach the instances can be configured in the form of a firewall.
Elastic IP addresses are static IPv4 addresses for dynamic cloud computing.
Metadata can be created and assigned to Amazon EC2 resources.
Virtual Private Clouds (VPCs) are virtual networks isolated from the rest of the AWS cloud and can be connected to our private network if needed.
Q #9) List possible storage options for Amazon EC2 instance.

Answer: Storage options for Elastic Compute Cloud (EC2) are listed below:

Amazon Elastic Block Store (EBS)
Amazon EC2 Instance Store
Amazon Elastic File System (EFS)
Amazon Simple Storage Service (S3)
Amazon Glacier
EC2 Storage options

Q #10) What security practices should be followed for Amazon EC2 instance?

Answer: Following security practices are followed for Amazon EC2 instance:

Least Access: Managing access to AWS resources and APIs using identity federation, IAM users, and IAM roles.
Least Privilege: Implementation of least permissive rules for security groups.
Configuration Management: Patch, update, and secure the operating system and applications on an instance regularly.
Q #11) What are the components of AWS Databases?

Answer: AWS Database is mainly composed of the following components:

Amazon Relational Database Service (RDS) is a managed service to set up, operate, and scale a relational database in the cloud server. Relation database services have Aurora, PostgreSQL, MySQL, Oracle, SQL Server, and MariaDB as database engines for cloud customers to select as their database. RDS also provides AWS database migration services to migrate and replicate the existing database to Amazon RDS.
Amazon Aurora is a distributed, fault-tolerant, self-healing storage system managed by Amazon RDS.
Amazon ElasticCache allows seamless setup, run, and scale open source in-memory data stores in the cloud. The features offered by ElasticCache are Caching, Session Stores, Gaming, Geospatial Services, Real-Time Analytic, and Queuing.
Amazon DocumentDB: With Amazon DocumentDB it becomes easy to store, query, and index data in JSON format.
Amazon DynamoDB is a key-value document database, selected for mobile, web, gaming, ad tech, IoT, and low-latency data access at any scale, for mission-critical workloads.
Amazon Keyspaces is database services compatible with Apache Cassandra, scalable, highly available, and serverless.
Redshift: It is a cloud data warehouse.
Neptune: It is fully managed, highly available, point-in-time recovery graph database services with continuous backup with Amazon S3.
Quantum Ledger Database: It is a fully managed ledger database SQL-like API, flexible document data model, with full support for transactions. It is serverless similar to a keyspace.
AWS database component

Q #12) Explain AWS DevOps tools to build and deploy software in the cloud.

Answer: To build and deploy software in the AWS cloud DevOps team uses the following tools:

AWS Cloud Development Kit: It is an open-source software development framework for modeling and provisioning cloud application resources with popular programming languages.
AWS CodeBuild: It is a continuous integration service that processes multiple builds and tests code with continuous scaling.
AWS CodeDeploy: It helps to automate software deployments to any of the on-premises servers to choose from such as Amazon EC2, AWS Fargate, AWS Lambda, etc.
AWS CodePipeline: It automates code received through continuous delivery for rapid and accurate updates.
AWS CodeStar: It is a user interface that helps the DevOps team to develop, build, and deploy applications on AWS.
AWS Device Farm: It works as a testing platform to test applications on different mobile devices and browsers.
AWS DevOps tools

Q #13) What is Amazon CloudFront and what does it offer?

Answer: Amazon CloudFront is a highly scaled and globally distributed Content Delivery Network service (CDN), which securely delivers APIs, applications, data, and videos to customers globally. To utilize CDN, various AWS tools such as APIs, AWS management console, AWS CloudFormation, CLIs, and SDKs are used.

Q #14) What do you mean by AWS Global Cloud Infrastructure?

Answer: AWS offers cloud infrastructure to customers across the globe. It is popularly called IaaS (Infrastructure as a service) which offers the customer to use services such as compute, networking, storage, and virtualization services over Amazonâ€™s servers on pay per use basis.

The terms used in global cloud infrastructure are Region, Availability zones, and Edge location. These are explained below:


Region: It is geographical subcontinent or region where Amazon has two or more than two availability zones that offer its resources to customers. Customers located across that particular region can avail of Amazonâ€™s cloud services.
Availability Zones: These are the city or locations in the region where Amazon has their fully operational, data center(s) that offer all offerings and cloud services to its customers in these zones.
Edge Location: This is the location where networking and content delivery resources are available along with other services to the Amazon cloud services such as compute, storage, database, and other services to the customers.
Q #15) What are Amazonâ€™s offerings under AWS Network and Content Delivery Services?

Answer: Under AWS networking and content delivery, it helps connect privately AWS global network by isolating resources and encrypting data thereby delivers customerâ€™s contents with high throughput, lowest latency, or delays.

Amazon offerings in networking and content delivery are listed below:

VPC or Virtual Private Cloud is a logically isolated section of Amazon web service, allowing clients to launch AWS resources in a virtual network, select their IP address range, configure subnet with access to Amazon EC2 instances in each subnet, route table, and network gateways.
Direct connect helps establish a private connection between the clientâ€™s data center and AWS, thereby providing the best bandwidth throughput, better network at reduced charges.
Route 53 is a highly scalable Domain Name System (DNS) web service. It helps the developer to set route end users to Internet applications by switching website names to corresponding IP addresses.
Q #16) What Amazon offers under its Compute services?

Answer: AWS compute is a feature of utilizing resources of computing power offered by Amazon in terms of a physical server within their data center by installing and running customerâ€™s applications on a pay per use basis by accessing these resources over the Internet. There are various compute services offered by Amazon based on performance and benefits along with the consumption of these resources over a period.

These offerings are listed below:

Amazonâ€™s Elastic Cloud Compute (EC2) allows deploying virtual server instances within the AWS environment. EC2 services can be further categorized based on Amazon Machine Images (AMI), User data, storage options, and security, Instance types, Instance purchasing options, and Tenancy.
EC2 Container Service (ECS) are the services that allow running applications that are packaged in the container by Docker (a tool that creates, deploy and run applications by using Linux containers) across a group of EC2 instances, with the help of AWS Fargate â€“ the engine that enables ECS to run applications packed in containers.
AWS elastic beanstalk is a managed service that automatically deploys the required resources within AWS once web application code has been uploaded, making web application operational. It includes resources such as EC2, Autoscaling, elastic load balancing, and applicationâ€™s health monitoring.
AWS Lambda is serverless compute service that runs the application without managing EC2 instances.
Amazon Lightsail is a web hosting service for simple and small applications or blogs. It can also be connected to other AWS resources as well as existing Virtual Private Cloud (VPC).
Amazon Compute Services

Q #17) Please elaborate on Analytics services offered by Amazon.

Answer: Amazon Analytics provides insights and analytical solutions from different data types that traditional data warehouses cannot provide.

Various analytics solutions offered by Amazon are listed as below:

Amazon Athena is an interactive query service that is serverless with no infrastructure to manage for analyzing data present in Amazon S3.
Amazon EMR is managed Hadoop framework for big data across Amazon EC2 instances along with other frameworks like Spark, HBase, Presto to interact with data stores such as S3 and DynamoDB.
Amazon data pipeline is web services for moving and processing data between computing and storage services of AWS.
Amazon Cloud Search is managed service for search, manage and scale searching feature such as highlighting, auto-complete and geospatial search for the web applications,
Amazon Elasticsearch services search, analyze, and visualize data in real-time by deploying elastic search API and analytics and integration with open source tools Kibana and Logstash for data ingestion and visualization for Amazon Elastic Search services.
Amazon kinesis collection, processing, and analyzing of streaming data such as video and audio, application logs, IoT telemetry data, etc. is done with Amazon Kinesis.
Amazon QuickSight is business intelligence services to publish interactive dashboards via browsers or mobile devices giving insights across the organization.
AWS analytics Services

Q #18) What is offered under Migration services by Amazon?

Answer: Amazon migration services customers can make an exact copy of their data from their database system to Amazonâ€™s databases by streaming data to Amazon S3, Aurora, DynamoDB, DocumentDB, or Redshift.

Amazon Database Migration Service (DMS) is a tool for migrating data extremely fast from an on-premise database to Amazon Web Services cloud. DMS supports RDBMS systems like Oracle, SQL Server, MySQL, and PostgreSQL in on-premises and the cloud.
Amazon Server Migration Services (SMS) helps in migrating on-premises workloads to Amazon web services cloud. SMS migrates clientâ€™s server VMware to cloud-based Amazon Machine Images (AMIs),
Amazon Snowball is a data transport solution for data collection, machine learning, and processing, and storage in low connectivity environments.
AWS migration services

Q #19) What are the different service offerings provided by Amazon under Security Identity and compliance services?

Answer: Amazon Security Identity and compliance services help DevOps team members to have a single point of checkpoint for configuring and prioritizing security alerts, findings.

With Identity and Access Management, Amazon grants or restricts user permission, assign security credentials to individuals.

Amazon Identity and Access Management (IAM) help to create and manage secured access to AWS services and resources, granting or restricting user permission to AWS cloud services.
Amazon inspector improves security and compliance of applications deployed on Amazon web services on their cloud environment, provide automated security assessment services of any vulnerabilities.
AWS WAF is a firewall that allows monitoring (Allow, Block as well verify) HTTP and HTTPS requests sent to Amazon API Gateway API, CloudFront, or Application Load Balancer.
AWS certificate manager manages, deploys and provides public and private Secure Sockets Layer (SSL) and Transport Layer Security (TLS) certificates for use with AWS and internal connected resources.
AWS security identity compliances

Q #20) List AWS management tools used while using Amazon cloud services?

Answer: There are mainly four categories of management tools available to AWS cloud consumers.

These are:

Provisioning tools like Terraform, CloudFormation, RightScale.
Operations Management tools like Juju, Ansible, Rex.
Monitoring and Logging tools like CFEngine, Sumo Logic, CloudWatch.
Managed Services and Configuration tools like Chef, Puppet, NixOS.
Q #21) What is offered under Messaging services by Amazon?

Answer: Amazon messaging services allow cloud customers to communicate between their teams regarding notification, marketing messaging via the SMTP interface of Amazon messaging services.

Different offerings from Amazon include the following:

Amazon Simple Notification Service (SNS) is fully managed, secured, available messaging services by AWS that help decouple serverless applications, micro-services, and distributed systems. SNS can be started within minutes from either AWS management console, command-line interface, or software development kit.
Amazon Simple Queue Service (SQS) is a fully managed message queues for serverless applications, micro-services, and distributed systems. The advantage of SQS FIFO guarantees single time processing and exact order sent by this kind of messaging service.
Amazon Simple Email Service (SES) offers sending and receiving email services for informal, notify, and marketing correspondence via email for their cloud customers through SMTP interface.
Q #22) What facilities are provided under the AWS customer enablement program?

Answer: Various offerings from Amazon are provided under the customer enablement program.

These are explained below:

AWS Support offers technical help, guidance on configuration, and assist during installation and implementation thereby improve their performance, save time installing their applications on the cloud.
AWS Professional Services assist customers and discuss plans with them to fulfill their business outcomes with the AWS cloud move.
AWS IQ is a platform to build technical support from Amazon certified third-party experts for on-demand consultation during their project work.
AWS Training and Certification provide training on AWS and cloud-related skills as well as provide a learning platform to achieve the AWS certification program.
AWS Managed services operate customerâ€™s cloud infrastructure on behalf of their enterprise customers and partners.
Q #23) What are Amazon Cloud solutions?

Answer: Amazon Cloud solutions are guidance or help to resolve common installation and commissioning difficulties or roadblocks that are encountered using the AWS platform by DevOps teams from Client. AWS team of experts provide deployment guide and instructions on manual as well as the automated deployment of their applications on Amazonâ€™s cloud services.

Q #24) Startup company wishes to move to AWS cloud, has confidential and sensitive client data, for investigation in the application, what do you suggest to manage cloud architecture?

Answer: The company can go for hybrid cloud architecture, which is a combination of public cloud for shared resources and private cloud/server for confidential workloads.

Q #25) You are running on very low project budgets, what would you select as AWS storage solutions?

Answer: Amazon Glacier is of extremely low-cost storage and data archiving and backup services. So, it can be selected.

Q #26) A web application has been created with auto-scaling, the web traffic is highest on Wednesdays and Fridays between 9 AM and 7 PM, as there is the best deal offered on the portal. How would you handle the scaling?

Answer: The Auto-scaling policy can be configured to scale as per the predictable traffic patterns. Further AWS will scale in response to the traffic.

Q #27) Web application to assist the designer of clothing and apparel line is hosted on AWS, which allows users to render images and process computing to predict the number of clothes required. To route incoming user traffic, which one of the following services should you use?

Classic Load Balancer
Application Load Balancer
Network Load Balancer
Answer: The best choice to route incoming user traffic would be Application Load Balancer, as it supports

Path-based routing, thereby enhancing the performance of an application.
Requests made for rendering images can be directed to the servers whereas requests made for computing to the servers that are deployed for general computing such as EC2.
Q #28) What management tool you would use if you wish to access Amazon Simple storage buckets and utilize the information for access audits?

Answer: AWS Cloud Trail, designed for logging and tracking API calls can be used for such cases.

Q #29) What is the purpose of making subnets?

Answer: Subnets are designed to divide a large network into smaller networks. It will help reduce congestion by routing traffic which increases substantially.

Q #30) Subnet is created and an EC2 instance launched in the subnet with default settings, Explain, which options would be ready to use on EC2 instance as soon as it is launched?

Elastic IP
Private IP
Public IP OR
Internet Gateway
Answer: The best option would be Private IP which gets assigned as soon as it is launched.

Public IP needs Internet Gateway and for new VPC, Gateway should be designed. Elastic IP will require manual set up.

Conclusion
Amazon web services offer scalable, reliable, highly secured, and cost-efficient compute and storage solutions. AWS is mainly used for transfer and manage data, compute & networking services, storage, operations, visualization, and security.

AWS consists of various components such as Route 53, Simple Storage Service (S3), Simple Email Service (SES), Identity & Access Management (IAM), Elastic Compute Cloud (EC2), Elastic Block Store (EBS), and CloudWatch.

We have attempted to cover most of the frequently asked AWS interview questions and it will benefit you in satisfactorily answering questions on AWS during the interview.

Best of luck with the interview!!


https://www.jigsawacademy.com/blogs/cloud-computing/aws-interview-questions/
[2022]AWS Interview Questions And Answers For Experienced & Freshers
img 
Team UNext
Editorial
 25 Aug 2022
Share  
INTRODUCTION
In the era of digitization, Cloud Computing platforms are being used by various businesses/firms around the globe. AWS (Amazon Web Services) is a popular Cloud Computing platform and is widely used in India. AWS has the largest market share in the global Cloud Computing market, i.e., around 32.4%. There is a need for expert Cloud Computing professionals in India to fill the talent gap and help in pacing fast with the technology revolution. IT professionals who are fluent in using AWS are in high demand by the firms. If you are preparing for AWS interview questions, read this blog to know some of the popular questions and answers.

We can categorize AWS interview questions into several types depending upon the job role one is applying for. Some of the common types of AWS interview questions asked based on various job roles are AWS scenario-based interview questions, Amazon interview questions for freshers, Amazon technical interview questions, AWS cloud interview questions, etc. Below are some of the trending AWS interview questions.

 What do you mean by AWS?
AWS provides Cloud Computing solutions and APIs to firms and individuals around the globe. Besides cloud services, AWS also offers other facilities for organizations/individuals like computation power, database services, content delivery, etc. Organizations have to pay for the AWS services used on a metered basis. 

An organization can build a distributed computing environment with the help of AWS tools and services. Launched in 2002 (web services) and 2006 (Cloud Computing), AWS is widely used in India by many organizations, businesses, and individuals. Some government organizations in India also use it. 

There are many Cloud Computing platforms in the market. But AWSâ€™s flexibility and cost-effective cloud computing solutions set it apart from the other platforms. Currently, there are more than 200 services and products offered by AWS in various fields like IoT (Internet of Things), mobile development, data analytics, networking, etc. 

Many of their services are not directly accessible to the end-users as AWS offers developer APIs for it. The web services provided by AWS are also widely used over HTTP for business purposes.

What is Amazon Elastic Compute Cloud (EC2), and also explain its features?
EC2 is part of the AWS services and enables users to rent virtual computers and run their programs. One can deploy applications on a large scale with the help of EC2. EC2 helps users to boot an AMI (Amazon Machine Language) to access a virtual machine. Amazonâ€™s configuration of a virtual machine via AMI is called an â€˜instanceâ€™. You can launch, create, and stop many server instances with the help of EC2 for your business/organization. You will have to pay per second for the number of active servers while using EC2 for your business/firm. 

Besides offering various virtual operating systems, EC2 also provides persistent storage and elastic IP addresses. Amazon CloudWatch is another service widely used by EC2 customers as it helps them monitor resource utilization. You can monitor the usage of CPU, network, etc., of RDS database replicas using Amazon CloudWatch. The auto-scaling feature of EC2 helps in adapting according to the traffic. For example, if someone uses EC2 for their e-commerce site, it will automatically scale up if the traffic on the site increases.

Discuss the pricing models for the Amazon EC2 instance
This is one of the important AWS interview questions for experienced posts. Read on to know more AWS interview questions and answers for experienced/senior posts.

There are four types of pricing models for Amazon EC2 instances that are as follows:

On-demand instance â€“ On-demand pricing or pay-as-you-go model allows you to pay only for the resources used till now. Depending on the instances, you will have to pay by second/hour for the resources. The on-demand pricing model is good if the work hours are short and unpredictable as they do not require any upfront payment.
Reserved instance â€“ It is the best model to use if you have a prerequisite for your upcoming requirements. Firms calculate their future EC2 requirements and pay upfront to get a discount of up to 75%. Reserved instances will save computing capacity for you, and you can use them wherever required.
Spot Instance â€“ If some extra amount of computing capacity is required immediately, one can opt for spot instances at up to a 90% discount. The unused computing capacity is sold at a heavily discounted rate via the spot instance pricing model.
Dedicated hosts â€“ A customer can reserve a physical EC2 server by opting for the dedicated hosts pricing model.
4. What is Amazon S3? Elaborate.

S3 (Simple Storage Service) provides scalable object storage space to firms and IT professionals. It is one of the earliest services introduced by AWS. The easy-to-use web services interface of S3 allows users to store and retrieve data from remote locations. S3 contains buckets to store files/data.

Users create a bucket in the S3 and name it as if it is a universal namespace. An HTTP 200 code is received on successful uploading of a file to the assigned S3 bucket. A unique name is given to each bucket to generate the DNS address (unique).

You can also download the data from a bucket in S3 and permit other users to download it. The authentication mechanism of S3 helps in securing the data from any possible breaches.

5. Your organization has decided to transfer its business processes to the public cloud. However, they want some of their information/data to be accessed only by the management team. The rest of the resources will be shared among the employees of the firm. You must suggest a suitable cloud architecture for your firm and the reason of choice.

This question is one of the critical AWS interview questions. Scenario-based AWS interview questions highlight the candidateâ€™s experimental knowledge and industry approach.

I will suggest hybrid cloud architecture for my organization. Hybrid cloud architecture has the perfect blend of private and public clouds. One can use the public cloud in the hybrid architecture for the shared resources in my firm. The confidential resources can only be shared with the management team using a private cloud.

We can enjoy the services of both private and public clouds by installing a hybrid cloud architecture in our firm. Depending on the data security requirements, a hybrid cloud allows data to be accessed at different levels in an organization/firm. It will help our firm in cutting costs in the long run.

6. Explain various types of cloud service models in brief.

There are three types of cloud services models that are:

IaaS â€“ Infrastructure as a Service (IaaS) allows users to access virtual computing resources with the help of the internet. A service provider hosts servers, storage, hardware, etc., on behalf of the users via IaaS. IaaS platforms offer high scalability and can adapt according to the workload. IaaS providers also manage tasks of their users like system maintenance, backup, resilience, etc.
PaaS â€“ Platform as a Service (PaaS) helps service providers to deliver software and hardware tools to their users. It is especially used for the application development process, and one can receive applications from the service provider via the internet using PaaS. Users do not have to own in-house software/hardware for application development/testing as they can do it with the help of PaaS.
SaaS â€“ Software as a Service (SaaS) is a widely sold model by service providers for software distribution. On-demand computing software can be delivered using SaaS to the users/customers. The SaaS model is preferred as it is easy to administer and manage patches.
7. Describe RTO & RPO from AWS perspective?

RTO (Recovery Time Objective) refers to the maximum waiting time for AWS services/operations resumption during an outage/disaster. Due to unexpected failure, firms have to wait for the recovery process, and the maximum waiting time for an organization is defined as the RTO. When an organization starts using AWS, they have to set its RTO, which can also be called a metric. It defines the time firms can wait during disaster recovery of applications and business processes on AWS. Organizations calculate their RTO as part of their BIA (Business Impact Analysis).

Like RTO, RPO (Recovery Point Objective) is also a business metric calculated by a business as part of its BIA. RPO defines the amount of data a firm can afford to lose during an outage or disaster. It is measured in a particular time frame within the recovery period. RPO also defines the frequency of data backup in a firm/organization. For example, if a firm uses AWS services and its RPO is 3 hours, then it implies that all its data/disk volumes will be backed up every three hours.

8. Explain the auto-scaling feature of EC2 along with its benefits.

The auto-scaling feature in AWS EC2 automatically scales up the computing capacity according to the need. It helps in maintaining a steady performance of business processes. Auto Scaling can help scale multiple AWS resources within a few minutes. Besides EC2, one can also choose to automatically scale other AWS resources and tools as and when needed. The benefits of the EC2 auto-scaling feature are as follows:

The auto-scaling feature of AWS EC2 is easy to set up. The utilization levels of various resources can be found under the same interface. You do not have to move to different consoles to check the utilization level of multiple resources.
The auto-scaling feature is innovative and automates the scaling processes. It also monitors the response of various resources to changes and scales them automatically. Besides adding computing capacity, the auto-scaling feature also removes/lessens the computing capacity if needed.
Even if the workload is unpredictable, the auto-scaling feature optimizes the applicationâ€™s performance. The optimum performance level of an application is maintained with the help of auto-scaling.
9. What are S3 storage classes, and explain various types of S3 storage classes?

S3 storage classes are used for data integrity and assisting concurrent data loss. Whatever object you store in S3 will be associated with a respective storage class. It is also involved in maintaining the object lifecycle, which helps in automatic migration and thus saves cost. The four types of S3 storage classes are as follows:

S3 Standard â€“ The data is duplicated and stored across multiple devices in various facilities via the S3 Standard storage class. A loss of a maximum of 2 facilities simultaneously can be coped up via the S3 standard. Its low latency and high throughput provide increased durability and availability.
 S3 Standard IA â€“ â€˜S3 Standard Infrequently Accessedâ€™ is used for conditions when data is not accessed regularly, but it should be fast when there is a need to access data. Like S3 Standard, it can also sustain the loss of data at a maximum of 2 facilities concurrently. 
S3 One Zone Infrequent Access â€“ Many of its features are similar to that of S3 Standard IA. The primary difference between S3, one zone infrequent access, and the rest of the storage class is that its availability is low, i.e., 99.5%. The availability of S3 standard and standard IA is 99.99%.
S3 Glacier â€“ S3 glacier provides the cheapest storage class as compared to other storage classes. One can only use the data stored in the S3 glacier for the archive.
10. Suppose your firm is hosting an application on AWS that helps users render images and perform general computation tasks. Your firmâ€™s management team has suggested using an application load balancer for routing the incoming traffic on the hosted application. Explain how an application load balancer is a good choice for routing the incoming traffic.

This question is an example of scenario-based AWS interview questions. Besides having theoretical knowledge, a candidate should also know about the industry uses and working of various AWS services. 

The userâ€™s requests regarding image rendering can only be directed to the image rendering servers, while the general computing users can be directed to the computing servers. This will help balance the load on various servers and access them when needed.

11. What is a policy in AWS? Explain various types of AWS policies in brief.

A policy is an object in AWS that is associated with a respective resource and defines whether the user request is to be granted or not. The six different types of policies in AWS are as follows:

 Identity-based policies â€“ These policies are concerned with an identity user, multiple users, or any particular role. Identity-based policies store permissions in the JSON format. They are also further divided into managed and inline policies.
Resource-based policies â€“ The policies that are concerned with resources in AWS are called resource-based policies. An example of a resource in AWS is the S3 bucket.
Permissions boundaries â€“ Permissions boundaries define the maximum number of permissions that can be granted to an object/entity by identity-based policies.
 SCP â€“ SCP (Service Control Policies) are also stored in JSON format and define the maximum number of permissions concerning a firm/organization.
ACL â€“ ACL (Access Control Lists) defines the principles in some other AWS account that can access the resources. It is also the only AWS policy that is not stored in the JSON format.
Session policies â€“ Session policies limit the number of permissions granted by a userâ€™s identity-based policies.
12. Explain in detail about AWS VPC.

Amazon VPC (Virtual Private Cloud) lets a user launch AWS resources into a virtual network defined by the user only. Since the user defines the virtual network, various aspects of the virtual network can be controlled by the user, like subnet creation, IP address, etc.

Firms can install a virtual network within their organization and use all the AWS benefits for that network. Users can also create a routing table for their virtual network using VPC. A routing table is a set of rules that defines the direction of the incoming traffic.

The communication between your virtual network and the internet can also be established using the internet gateway offered by AWS VPC. One can access the VPC offered by Amazon via various interfaces that are AWS management console, AWS CLI (Command Line Interface), AWS SDKs, and Query API. Users can pay for additional VPC components if required like NAT gateway, traffic mirroring, private link, etc.

13. You have recently assigned various EC2 instances for your business website across different availability zones. Since your website performs a large number of reading/writing operations per minute, you have also used a Multi-AZ RDS DB instance (extra-large). It was going smoothly as per your plans until you discovered read contention on RDS MySQL. How are you going to solve this issue to enhance the performance of your website?

This question is one of the prominent technical AWS interview questions asked. Besides knowing about the cloud deployment services of AWS, candidates should also focus on the database services offered by Amazon.

I will install/deploy ElastiCache in the various availability zones of EC2 instances. Deploying ElastiCache in the memory cache of different availability zones will create a cached version of my website in various zones. RDS MySQL read replica will then be added to each availability zone for faster performance of the website. Since the â€˜RDS MySQL read replicaâ€™ is added to each availability zone, it will not further load on the RDS MySQL instance, thus solving the read contention issue. Users can also access my website quickly in various availability zones as a cached version is created in each zone.

14. Your firm wants to connect the data center of its organization to the Amazon cloud environment for faster accessibility and performance. What course of action will you suggest for the stated scenario?

AWS data engineer interview questions can be asked if a candidate is applying for data scientist/engineer. The data center of my firm can be connected to the Amazon cloud environment with the help of VPC (Virtual Private Cloud). I suggest my firm establish a virtual private network and connect VPC and the data center. My firm can then launch AWS resources in the virtual private network using VPC. A virtual private network will establish a secure connection between the firmâ€™s data center and the AWS global network. Adding cloud services to our organization will help us do more work in less time while successfully slashing costs in the long run.

I would also suggest creating multiple backups of the company data before moving it successfully to the cloud. AWS offers affordable backup plans, and one can also automate backups after a fixed interval.

15. Explain various types of elastic load balancers in AWS.

Elastic load balancing in AWS supports three different types of load balancers. The load balancers are used to route the incoming traffic in AWS. The three types of load balancers in AWS are as follows:

Application load balancer â€“ The application load balancer is concerned with the routing decisions made at the application layer. It does path-based routing at the HTTP/HTTPS (layer 7). It also helps in routing requests to various container instances. Using the application load balancer, you can route a request to more than one port in the container instances.
Network load balancer â€“ The network load balancer is concerned with routing decisions made at the transport layer (SSL/TCP). It uses a flow hash routing algorithm to determine the target on the port from the group of targets. Once the target is selected, a TCP connection is established with the chosen target based on the known listener configuration.
Classic load balancer â€“ A classic load balancer can decide on either the application or transport layer. One can map a load balancer port to only one container instance (fixed mapping) via the classic load balancer.
16. What do you know about NAT gateways in AWS?

NAT (Network Address Translation) is an AWS service that helps in connecting an EC2 instance to the internet. The EC2 instance used via NAT should be in a private subnet. The internet and NAT can also help connect an EC2 instance to other AWS services.

Since we are using the EC2 instance in a private subnet, connecting to the internet via any other means would make it public. NAT helps in retaining the private subnet while establishing a connection between the EC2 instance and the internet. Users can create NAT gateways or NAT instances for establishing a connection between EC2 instances and internet/AWS services.

NAT instances are single EC2 instances, while NAT gateways can be used across various availability zones. If you are creating a NAT instance, it will support a fixed amount of traffic decided by the instanceâ€™s size.

17. Explain various AWS RDS database types in brief.

Various types of AWS RDS database types are as follows:

Amazon Aurora â€“ Aurora database is strictly developed in AWS RDS, which means it cannot run on any local device with an AWS infrastructure. This relational database is preferred for its enhanced availability and speed.
PostgreSQL â€“ PostgreSQL is a relational database that is developed especially for start-ups and AWS developers. This easy-to-use and open-source database help users in scaling deployments in the cloud environment. Not only the PostgreSQL deployments are fast, but they are also cost-effective (economical).
MySQL â€“ It is also an open-source database used for its high scalability during deployments in the cloud.
MariaDB â€“ MariaDB is an open-source database used to deploy scalable servers in the cloud environment. You can deploy MariaDB servers in the cloud environment within a few minutes. The scalable MariaDB server deployment is also cost-effective. MariaDB is also preferred for its management of administrative jobs like scaling, replication, software patching, etc.
Oracle â€“ Oracle is a relational database in AWS RDS that can also scale the respective deployments in the cloud. Just like MariaDB, it also performs the management of various administrative tasks.
SQL server â€“ It is another relational database that can also manage administrative tasks like scaling, backup, replication, etc. Users can deploy multiple versions of SQL servers in the cloud within minutes. The SQL server deployment is also cost-effective in AWS.
18. What do you know about Amazon Redshift?

Redshift is a data warehouse service offered by Amazon that is deployed in the cloud. It is fast and highly scalable as compared to other data warehouses in the cloud. On average, Redshift provides around ten times more performance & speed than different data warehouses in the cloud. It uses new-age technologies like machine learning, columnar storage, etc., that justify its high stability and performance. You can scale up to petabytes and terabytes using AWS Redshift.

Redshift uses OLAP as its analytics processing system and comprises two nodes for storing data/information. Its advanced compression and parallel processing offers high speed during AWS operations in the cloud. One can easily add new nodes in the warehouse using AWS Redshift. Developers can answer a query faster and can also solve complex problems using Redshift.

19. What do you know about AMI?

AMI (Amazon Machine Image) is used to create a virtual machine within the EC2 environment. The services that are delivered via EC2 are deployed with the help of AMI only. The main part of AMI is its read-only filesystem image that also comprises an operating system. AMI also consists of launch permission that decides which AWS account is permitted to launch instances using AMI. The volumes are attached to an instance while the launching process is decided by block device mapping in AMI. The AMI consists of three different types of images.

A Public image is an AMI that any user/client can use, while users can also opt for a â€˜Paidâ€™ AMI. You can also use a â€˜Sharedâ€™ AMI that provides more flexibility to the developer. Users can access A shared AMI which is allowed as per the developerâ€™s orders.

20. Explain horizontal and vertical scaling in AWS?

This question is among the AWS basic interview questions asked to a candidate. It is also one of the important AWS interview questions for freshers. Read on to know the answer to this AWS interview question.

When RDS/EC2 servers alter the instance size for scaling purposes, it is called vertical scaling. A larger instance size is picked for scaling up in vertical scaling, while a smaller instance size is picked for scaling down. The size of the instance is altered on-demand via vertical scaling in AWS. 

Unlike vertical scaling, an instanceâ€™s size is altered per the requirements of horizontal scaling. A systemâ€™s number of nodes/instances is changed without altering their size via horizontal scaling. The horizontal auto-scaling is based on the number of connections between an instance and the integrated ELB (Elastic Load Balancer).

21. What are the main differences between AWS and OpenStack?

Both AWS and OpenStack are indulged in providing cloud computing services to their users. AWS is owned and distributed by Amazon, whereas OpenStack is an open-source cloud computing platform. AWS offers various cloud computing services and IaaS, PaaS, etc., whereas OpenStack is an IaaS cloud computing platform. You can use OpenStack for free as it is open source, but you have to pay for AWS services as you use it.

Another significant difference between AWS and OpenStack is in terms of performing repeatable operations. While AWS performs repeatable functions via templates, OpenStack does it via text files. OpenStack is good for understanding and learning cloud computing, but AWS is better and equipped for businesses. AWS also offers business development tools that OpenStack does not offer.

22. What do you know about AWS CloudTrail?

People using an AWS account can audit it using the AWS CloudTrail. It also helps in ensuring compliance and governance of the AWS account. As soon as an AWS account is activated, CloudTrail also starts working and records every AWS activity as an event. One can visit the CloudTrail console anytime and can view recent events/actions. All the efforts by a user or a role are recorded in the CloudTrail. The actions taken by various AWS services are also recorded in CloudTrail.

With CloudTrail, you will have enhanced visibility of your AWS account and the associated actions. In an AWS infrastructure in any organization, you can quickly get to know any particular activity and gain control over the AWS infrastructure.

23. What do you know about AWS Lambda?

AWS Lambda is a computing platform provided as a part of the AWS services that do not need servers to perform activities. Any code compiled on AWS Lambda will run in response to events, and it identifies the resources required for code compilation automatically. AWS Lambda supports various coding languages like Node.js, Python, Java, Ruby, etc. With AWS Lambda, you will pay only for the time your code is being executed. You will not be charged any amount when you are not using any computer time.

Besides running your code in response to events, you can also run your code in response to HTTP requests via AWS Lambda. AWS Lambda will automatically manage various resources like memory, network, CPU, etc., while you run a code on it.

24. Your firm has been using AWS services for a year now. You are a senior developer in your company and have been asked to analyze your firmâ€™s amount for AWS services. How will you analyze the cost spent on AWS services to ensure that you are not paying more than you use?

Cost management can be an important topic of discussion in AWS interview questions. Also, this question is an example of AWS scenario-based interview questions.

I will refer to the â€˜Top Services Table,â€™ which is visible in the cost management console of AWS. It will let me know about the top five services being used by our firm and how much money we are spending on those services. I will also take the aid of cost explorer services offered by AWS that will let me analyze the last 13 monthsâ€™ usage and associated costs.

One can use the cost allocation tags to identify the AWS resource that has cost more than other services in any particular month.

25. You have to upload a file of around 120 megabytes in Amazon S3. How will you approach the uploading of this file?

A file that has a size of more than 100 megabytes can be uploaded in Amazon S3 using the multipart upload utility offered by AWS. Multipart upload utility will allow me to upload the 120 megabytes file into multiple parts. All the parts of the large file will be uploaded individually using the multipart upload utility. Once all the original files are uploaded, one can merge to get the original file with 120 megabytes.

Using a multipart upload utility will help me in decreasing the upload time significantly. AWS S3 commands can be used for multipart uploading and downloading. AWS S3 commands are also capable of automatically performing multipart uploading/downloading after evaluating the file size.

26. Your firm has an application that runs on AWS, and the management decides that they want to inculcate email functionality in their application. How will you approach this scenario as part of your firmâ€™s management team?

Amazon offers various services for a diverse range of use cases that work well with AWS-based applications. You should know about other Amazon services that go well with AWS, as AWS interview questions can be based on them. 

I recommend using the Amazon SES (Simple Email Service) to integrate email functionality with our AWS-based application. SES can help us set up various types of mail forwarding services like mass mailing, transactional mailing, marketing mailing, etc. SES is a cost-effective solution for integrating email functionality within multiple applications. The scalable SES service is highly secure and can help my firm send emails globally.

27. Explain an AWS service that one can use to protect the AWS infrastructure from DDoS attacks.

For safeguarding the applications running on AWS from any kind of DDoS (Distributed Denial of Service) attacks, we can use AWS Shield. AWS Shield can automatically identify a DDoS attack and will reduce application downtime and latency. A firm doesnâ€™t have to contact Amazon tech support as all the protective measures can be automated via AWS Shield. All AWS users are subjected to automatic protection against DDoS attacks via AWS Shield Standard. However, for protection against large/organized DDoS attacks, one can use the AWS Shield Advanced services. 

AWS Shield Advanced protects AWS-based applications against various sophisticated DDoS attacks on the network and transport layer. It also provides real-time visibility and monitoring at the time of any DDoS attack on the AWS applications.

28. What do you know about Amazon CloudWatch? Explain its benefits in brief.

Amazon CloudWatch helps monitor the AWS services and resources being used in real-time. CloudWatch uses various metrics that help understand the AWS resources and services being used. Via CloudWatch can also view the metrics related to customized AWS applications as the CloudWatch dashboard is also customizable. By default, CloudWatch displays various metrics associated with AWS services being used. One can customize and choose a set of metrics to be shown by CloudWatch.

One can access CloudWatch services via various means like CloudWatch console, AWS CLI, CloudWatch API, and AWS SDKs. Besides resource utilization, we can also monitor the operational health of AWS services via CloudWatch.

29. Explain the various types of virtualization in AWS in brief.

There are three types of virtualization in AWS that are as follows:

HVM â€“ HVM (Hardware Virtual Machine) helps in the full virtualization of hardware where all the virtual hardware machines act as an individual unit. Once AWS AMI virtualization is done, the virtual machines execute the master boot record to boot themselves. The root block device of the created AWS machine image contains the master boot record executed by virtual machines.
PV â€“ PV (Paravirtualization) is virtualization to a lighter degree as compared to HVM. The guest OS in PV will require some modifications before performing anything. These modifications help users export a scalable and modified hardware version to the virtual machines.
PV on HVM â€“ Paravirtualization on HVM can also be done for increased functionality. Operating systems can get access to storage and network I/O through the host via PV on HVM.
30. For encrypting the AWS data in the US region, a key was created from the company headquarters in Asia. Various users and a substitute AWS account were also added to the key. However, the key was not listed while encrypting an object in S3 in the US. What is the problem which the officials in the US arenâ€™t able to list the key?

This question is an example of AWS interview questions for freshers. Scenario-based AWS interview questions define the industry-oriented approach of the candidates.

The AWS data that needs to be encrypted should be in the same region where one creates the key. In the given scenario, the data is encrypted in the USA region. But the key was created in the Asia region. It doesnâ€™t matter if you link an external AWS account in another region while the data encryption is to be done in another region.

31. What do you know about the cross-region replication service offered by AWS?

Cross-region replication is used when one needs to copy data from one bucket to another. The main benefit of cross-region replication is that it allows you to replicate data from one bucket to another while both buckets are in different regions. One can do Asynchronous copying of data across buckets in the same AWS management console via cross-region replication.

The bucket from which the data/object is being copied is called the Source Bucket, while the other is called the Destination Bucket. Versioning should be enabled in both the source and destination buckets for availing of cross-region replication. Once you have uploaded a set of data in the destination bucket, you cannot upload/replicate the same data from the source bucket.

32. Explain what you know about CloudFront CDN.

CloudFront CDN (Computer Delivery Network) is a group of distributed servers used to deliver web content like webpages, etc. The delivery done by CloudFront CDN is based on the geographic region of the user, webpage origin, and the server being used for content delivery. The origin of all the files that are to be distributed by the CDN needs to be defined. An origin for CDN can be an S3 bucket, an AWS instance, or an elastic load balancer.

Two types of distribution are done by CloudFront CDN, web distribution and RTMP. Web distribution is used for websites, whereas RTMP is used for media streaming. There are around 50 edge locations distributed in various parts of the world. Edge locations are sites where the web content is cached during delivery.

33. What do you know about AWS Web Application Firewall (WSF)?

AWS WAF is a firewall service that protects web applications from being exploited. They protect web applications against bots that may reduce the applicationsâ€™ performance or unnecessarily consume resources. Users can control the incoming traffic on their web applications with the help of AWS WAF. Besides bot traffic, we can also prevent various common attacks on the web application via AWS WAF.

Users can create their traffic rule via AWS WAF to restrict any particular traffic pattern affecting the web applicationsâ€™ performance. AWS WAF offers an API used to define the set of rules for governing the incoming traffic and automate the creation of security rules for web applications.

34. What is the Simple Notification Service offered by AWS?

Simple Notification Service (SNS) offered by AWS is a means of sending messages from one application to another. It is a cost-effective solution that helps users publish messages from any particular application and forward them to other applications. SNS can also send push notifications to various mobile devices like Apple, Google, Windows phones, etc. One can also send an email/SMS to an HTTP endpoint using AWS SNS.

The best feature of SNS is that multiple types of endpoints can be grouped. SNS also supports various types of endpoints under one topic. For example, one can group Apple and Android recipients using SNS and send messages to all subscribers. SNS stores the messages already published in various availability zones to prevent any type of data loss.

35. Your firm has offices in various parts of the world and is involved in multi-regional deployment on AWS. For data persistence, your firm uses MYSQL 5.6. Your firm has recently announced that it needs to regularly collect batch process data from each region and generate regional reports. The reports will then be forwarded to various branch offices. What course of action will you suggest to perform this task in the shortest possible time?

AWS interview questions can also be based on server deployment and database-related issues. This question is an example of AWS interview questions for experienced posts. 

I will suggest creating an RDS instance as a master for managing the firmâ€™s database. For collecting/reading reports from various locations, we can create a read replica of the RDS instance in various regional headquarters. Installing a read replica at multiple locations will help us in reading reports in less time.

36. Your firmâ€™s application is responsible for retrieving data from your subscriberâ€™s/userâ€™s mobile devices every 10 minutes. The retrieved data is stored in DynamoDB. The information is extracted into S3 for each user. Once the data is extracted, the application helps in data visualization on the user end. As a senior architect in your firm, you are asked to optimize the backend architecture so that the firm can slash costs. What are your recommendations?

AWS interview questions can change according to the different job roles applied for. This question is an example of AWS architect interview questions.

I would recommend using Amazon Elasticache to cache the data stored in DynamoDB. Using Elasticache will reduce the provisioned read throughput without affecting the performance of the system. Using Elasticache will also help our firm slash the cost as it is cheaper than any other provisioned IO.

37. What do you know about Amazon EMR?

Amazon EMR (Elastic MapReduce) is a web service that is widely used for data processing. Amazon EMR consists of a group of EC2 instances that are known as clusters. Cluster is the central component of Amazon EMR with a group of EC2 instances. A single EC2 instance in a cluster is called a node, and each node has a specific role attached to it. Node type defines the particular role connected to any node in a cluster. 

Amazon EMR also consists of a master node responsible for defining the roles of other nodes in a cluster. The master node is also responsible for monitoring the performance of various nodes and their overall health.

38. What do you know about the S3 transfer acceleration service offered by Amazon?

S3 transfer acceleration is used to make uploads to S3 quickly. S3 transfer acceleration does not upload directly to an S3 bucket as it uploads the file to the nearest edge location. A distinct URL is used by S3 transfer acceleration to upload the file to the nearest edge location and then transfer it to the required S3 bucket.

The cloudFront edge network is utilized by S3 transfer acceleration to make uploads quickly and optimizes the transfer process. The edge location to which the file is uploaded will automatically transfer the file to the S3 bucket in less time. The data between clients and S3 buckets can be securely transferred using Amazonâ€™s S3 transfer acceleration service. 

39. Describe the core services of Amazon Kinesis in brief.

Kinesis is a data streaming platform offered by Amazon. There are three core services of Amazon kinesis that are as follows:

Kinesis Streams â€“ While data streaming, the produced data is stored in shards containing the storage sections of Kinesis Streams. The consumers can then access the stored data in shards and turn it into useful data. Once the customers/consumers are done with the data stored in shards, it is moved to other AWS storage like DynamoDB, S3, etc.
Kinesis Firehose â€“ Kinesis Firehose is used to deliver streaming data to various AWS destinations like S3, Redshift, Elasticsearch, etc.
Kinesis Analytics â€“ One can analyze the streaming data, and rich insights can be collected using Kinesis Analytics. You can run SQL queries on the data stored within Kinesis Firehose via Kinesis Analytics.
40. Explain some of the advantages of using AWS RDS.

AWS interview questions are likely to be framed around AWS RDS as it is one of the most widely used database services in the world.

The benefits of using AWS RDS are as follows:

While using AWS RDS, you can individually control/tweak various database services like CPU, storage, etc..
AWS RDS helps enable automatic backup and update your database servers to the latest configuration.
AWS RDS also creates a backup instance that can be used at the time of failover and prevents data loss.
You can distribute the read traffic by creating RDS read replicas from the source database.
41. State the differences between AWS CloudFormation and AWS Elastic Beanstalk.

AWS CloudFormation is responsible for provisioning all the resources that are available within a cloud environment. It is also used to describe all the infrastructural resources in a cloud environment. Contrary to AWS CloudFormation, AWS Elastic Beanstalk provides a suitable environment to deploy and operate applications within the cloud. 

The infrastructural need of applications running in the cloud is fulfilled by AWS CloudFormation, whereas AWS Elastic Beanstalk manages the lifecycle of applications deployed in the cloud. You can fulfill various infrastructural needs of various types of applications deployed in the cloud via AWS CloudFormation like enterprise applications, legacy applications, etc. AWS Elastic Beanstalk is not concerned with the types of applications as it is combined with the developer tolls to govern the lifecycle of deployed applications.

42. Explain the working of AWS config with AWS CloudTrail.

AWS CloudTrail is widely used for recording the user API activity associated with a particular AWS account. One can monitor various API activities using AWS CloudTrail, like response element, caller identity, call duration, etc. When you use AWS Config with CloudTrail, you know the configuration details associated with the AWS resources used. If something is wrong with your AWS resources, both AWS config and CloudTrail can help you identify them.

AWS config is more concerned with the changes that have been made to the AWS resources, whereas CloudTrail is concerned with the user that has made the changes. You can use both of them simultaneously for enhanced governance, compliance, and security policies.

43. What to do so I never lose my connectivity even if my AWS Direct Connect fails?

One needs to configure a backup AWS Direct Connect for situations where the original one fails. Configuring a backup will help you shift connectivity to the second one if the original one fails. You can do BFD (Bidirectional Forwarding Detection) to detect failure conditions faster and generate backup accordingly.

One can also configure backup on an IPsec VPN connection so that the traffic can be automatically backed up. While using an IPsec VPN connection backup, all the traffic will be directed to the internet in case of a failure. If you havenâ€™t ensured any of these backup methods, you will lose your connectivity whenever a failure occurs.

44. Suppose a request for any particular content is made in CloudFront, but the content is not present in the nearest edge location. What will happen in this scenario?

CloudFront always caches data to the nearest edge location before delivering the data to various users. If one requests a particular content via CloudFront and the content is not stored in the nearest edge location, it will be delivered from the original server. The userâ€™s request will not go in vain as the content will be delivered. However, we may increase the latency as the content is being delivered from the original server and not from the nearest edge location.

In this case, a cached version of the data will also be stored in the nearest edge location. So we can reduce the latency if a request for the same data is made again. Only for the first time will it be delivered from the original server.

It is another example of â€˜AWS interview questions that are scenario-based. It is also a type of AWS cloud architect interview question.

Yes, one should launch the EC2 instances in a VPC. VPC is the best way of connecting the EC2 instances to our firmâ€™s data center. Once each instance is connected to the VPC, we can easily assign a predetermined IP address to each EC2 instance. It will help to access the public cloud resources easily, like they are stored in a private network.

45. What do you understand by volume & snapshot in AWS 

In AWS, volume is block-level storage that we can assign to an EC2 instance. We can compare this to a hard disk from where the user can read or write the data. You pay for the data used by volumes as it is a way of measuring the storage section.

A snapshot is formed when we have a volume as it is a single point in time view of a volume. A snapshot is formed when the data stored in a volume is copied to another location at a single point in time.

46. If a failure during event processing via AWS Lambda occurs, how will it be handled?

If event processing via AWS Lambda is done in synchronous mode, then an exception will be displayed on the application used to call the function during failure. However, if an event is being processed in asynchronous mode, then a function will be called a minimum of three times in case of failure.

47. What do you know about Amazon WorkSpaces? 

Amazon WorkSpaces provides virtual and cloud-based desktops to work on, also known as workspaces. You do not need to deploy physical hardware and software by using Amazon WorkSpaces. You can install Microsoft Windows or Linux virtual desktops with the aid of Amazon WorkSpaces. Users can access virtual desktops via various devices or web browsers.

WorkSpaces allows users to choose from a wide range of available software/hardware configurations. It also provides a persistent desktop feature so that you can start working from where you had left off. Amazon also provides a WAM (WorkSpaces Application Manager) for deploying and managing applications on virtual desktops. 

48. What do you know about AWS IAM?

The key to cracking an AWS interview is to know about Amazonâ€™s wide range of services. This question is a type of basic AWS interview question asked.

AWS IAM (Identity and Access Management) allows users to securely access AWS resources/services. One can create groups of users using AWS IAM and can assign them a customized set of permissions. Access to AWS resources can be allowed to any particular group/user via AWS IAM. One can access the IAM features under the â€˜AWS Management Consoleâ€™ section of your AWS account.

49. Mention the differences between security groups and a network access control list.

AWS interview questions can be related to cloud access, security, customer service, and many more topics. One should practice AWS interview questions from diverse topics related to AWS services to crack the interview.

Security groups are used to control access to instances, while the network access control list is concerned with controlling access at the subnet level. Network access control lists can add rules for both â€˜allowâ€™ and â€˜deny,â€™ whereas security groups can add only rules for â€˜allow.â€™

AWS S3 INTERVIEW QUESTIONS
50. What is AWS S3?

AWSâ€™s cloud-based object storage service with unparalleled scalability, data availability, security, and performance is known as Amazon S3. On Amazon Web Services, the service can be used for online backup and archiving of data and applications (AWS).

51. Is Amazon S3 a global service?

Yes, Amazon S3 is a worldwide service. It offers object storage via a web interface and runs its global e-commerce network on Amazonâ€™s scalable storage infrastructure.

52. How does AWS S3 work?

Amazon S3 (Amazon Simple Storage Service) is a service for storing objects. Amazon S3 enables users to store and retrieve any amount of data at any time from anywhere on the internet.

53. What do you understand by â€˜Bucketâ€™ in AWS S3?

A bucket in AWS Simple Storage Service (S3) is a public object storage service such as file folders, which store objects containing data and descriptive metadata.

54. Why would you connect an instance to an S3 bucket?

You do not wish to connect an instance to an S3 bucket, as Block storage is not the same as object storage, which has serious consequences.

55. What do you understand by Versioning in S3?

S3 buckets support the feature of versioning. The bucketâ€™s versioning is enabled globally. Versioning allows one to track various changes made to a file over time. If versioning is enabled, each uploaded file receives a unique Version ID. Consider a bucket that contains a file, and a user uploads a new modified copy of the same file to the bucket; both files had a unique Version ID and timestamps from when they were uploaded. So, if one needs to go back in time to an earlier state of the file, versioning makes it simple.




References
------------
https://www.interviewbit.com/aws-interview-questions/
https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions
https://www.javatpoint.com/aws-interview-questions
https://intellipaat.com/blog/interview-question/amazon-aws-interview-questions/
https://mindmajix.com/aws-interview-questions
https://www.fita.in/aws-interview-questions-and-answers/
https://career.guru99.com/top-15-aws-interview-questions/
https://www.softwaretestinghelp.com/aws-interview-questions/
https://www.jigsawacademy.com/blogs/cloud-computing/aws-interview-questions/
